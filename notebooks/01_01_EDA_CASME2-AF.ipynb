{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPN0jM93dGH1mvH1q+M+Um3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"LAM_82kZmay5","executionInfo":{"status":"ok","timestamp":1758691994785,"user_tz":-420,"elapsed":201209,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"c1c1a35e-1d1c-4635-a2d6-4f22fcb3b315"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CASME II ROBUST ZIP EXTRACTION\n","============================================================\n","\n","[1] Mounting Google Drive...\n","Mounted at /content/drive\n","✓ Google Drive mounted successfully\n","\n","[2] Verification and cleanup...\n","ZIP file location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw/CASME2_RAW_selected.zip\n","Extract destination: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw\n","✓ ZIP file found (Size: 967.34 MB)\n","\n","[3] Cleanup previous extraction attempts...\n","- No existing directory: CASME2\n","- No existing directory: CASME2_RAW_selected\n","\n","[4] Analyzing ZIP file structure...\n","✓ ZIP analysis complete:\n","  - Total files: 17406\n","  - Root directories: 1\n","  - Subject folders detected: 26\n","  - Root structure: ['CASME2_RAW_selected']\n","  - Subject range: sub01 to sub26 (26 total)\n","\n","[5] Starting robust extraction...\n","  Progress: 1000/17406 (5.7%) | Rate: 88.0 files/sec | ETA: 3.1 min\n","  Progress: 2000/17406 (11.5%) | Rate: 95.3 files/sec | ETA: 2.7 min\n","  Progress: 3000/17406 (17.2%) | Rate: 95.7 files/sec | ETA: 2.5 min\n","  Progress: 4000/17406 (23.0%) | Rate: 96.3 files/sec | ETA: 2.3 min\n","  Progress: 5000/17406 (28.7%) | Rate: 98.2 files/sec | ETA: 2.1 min\n","  Progress: 6000/17406 (34.5%) | Rate: 99.9 files/sec | ETA: 1.9 min\n","  Progress: 7000/17406 (40.2%) | Rate: 99.2 files/sec | ETA: 1.7 min\n","  Progress: 8000/17406 (46.0%) | Rate: 96.8 files/sec | ETA: 1.6 min\n","  Progress: 9000/17406 (51.7%) | Rate: 97.5 files/sec | ETA: 1.4 min\n","  Progress: 10000/17406 (57.5%) | Rate: 97.9 files/sec | ETA: 1.3 min\n","  Progress: 11000/17406 (63.2%) | Rate: 97.7 files/sec | ETA: 1.1 min\n","  Progress: 12000/17406 (68.9%) | Rate: 96.4 files/sec | ETA: 0.9 min\n","  Progress: 13000/17406 (74.7%) | Rate: 96.1 files/sec | ETA: 0.8 min\n","  Progress: 14000/17406 (80.4%) | Rate: 96.2 files/sec | ETA: 0.6 min\n","  Progress: 15000/17406 (86.2%) | Rate: 96.6 files/sec | ETA: 0.4 min\n","  Progress: 16000/17406 (91.9%) | Rate: 96.9 files/sec | ETA: 0.2 min\n","  Progress: 17000/17406 (97.7%) | Rate: 97.3 files/sec | ETA: 0.1 min\n","\n","✓ Extraction completed:\n","  - Files extracted: 17406/17406\n","  - Errors encountered: 0\n","  - Total time: 178.91 seconds\n","  - Average rate: 97.3 files/second\n","\n","[6] Verifying extraction results...\n","✓ Extracted directory structure:\n","  CASME2_RAW_selected/: 17124 files, 26 subject directories\n","\n","============================================================\n","EXTRACTION SUMMARY\n","============================================================\n","Status: SUCCESS\n","Files processed: 17406/17406\n","Error rate: 0.00%\n","Extraction time: 3.0 minutes\n","✓ Ready for Cell 2: Structure validation and analysis\n","============================================================\n"]}],"source":["# @title Cell 1: CASME II ZIP Extraction\n","\n","import os\n","import zipfile\n","import time\n","from google.colab import drive\n","\n","# Mount Google Drive\n","print(\"=\" * 60)\n","print(\"CASME II ROBUST ZIP EXTRACTION\")\n","print(\"=\" * 60)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths - extract directly to raw directory\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw\"\n","zip_file_path = f\"{raw_path}/CASME2_RAW_selected.zip\"\n","\n","print(f\"\\n[2] Verification and cleanup...\")\n","print(f\"ZIP file location: {zip_file_path}\")\n","print(f\"Extract destination: {raw_path}\")\n","\n","# Check ZIP file existence and size\n","if not os.path.exists(zip_file_path):\n","    print(\"✗ ERROR: CASME2_RAW_selected.zip not found\")\n","    print(\"Please ensure ZIP file is uploaded to datasets/raw/ directory\")\n","    exit()\n","\n","zip_size_mb = round(os.path.getsize(zip_file_path) / (1024 * 1024), 2)\n","print(f\"✓ ZIP file found (Size: {zip_size_mb} MB)\")\n","\n","# Clean up any partial extraction\n","casme2_folder = os.path.join(raw_path, \"CASME2\")\n","casme2_raw_selected = os.path.join(raw_path, \"CASME2_RAW_selected\")\n","\n","print(f\"\\n[3] Cleanup previous extraction attempts...\")\n","\n","# Remove any existing partial extractions\n","cleanup_paths = [casme2_folder, casme2_raw_selected]\n","for path in cleanup_paths:\n","    if os.path.exists(path):\n","        import shutil\n","        shutil.rmtree(path)\n","        print(f\"✓ Removed existing directory: {os.path.basename(path)}\")\n","    else:\n","        print(f\"- No existing directory: {os.path.basename(path)}\")\n","\n","# Inspect ZIP contents first\n","print(f\"\\n[4] Analyzing ZIP file structure...\")\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        file_list = zip_ref.namelist()\n","        total_files = len(file_list)\n","\n","        # Analyze directory structure in ZIP\n","        directories = set()\n","        subject_folders = set()\n","\n","        for file_path in file_list:\n","            # Get all directory components\n","            parts = file_path.split('/')\n","            if len(parts) > 1:\n","                directories.add(parts[0])  # Root level folders\n","                if len(parts) > 2 and parts[1].startswith('sub'):\n","                    subject_folders.add(parts[1])\n","\n","        print(f\"✓ ZIP analysis complete:\")\n","        print(f\"  - Total files: {total_files}\")\n","        print(f\"  - Root directories: {len(directories)}\")\n","        print(f\"  - Subject folders detected: {len(subject_folders)}\")\n","        print(f\"  - Root structure: {sorted(list(directories))}\")\n","\n","        if subject_folders:\n","            sorted_subjects = sorted(list(subject_folders))\n","            if len(sorted_subjects) <= 10:\n","                print(f\"  - Subject folders: {sorted_subjects}\")\n","            else:\n","                print(f\"  - Subject range: {sorted_subjects[0]} to {sorted_subjects[-1]} ({len(sorted_subjects)} total)\")\n","\n","except Exception as e:\n","    print(f\"✗ ERROR analyzing ZIP: {str(e)}\")\n","    exit()\n","\n","# Robust extraction with progress tracking\n","print(f\"\\n[5] Starting robust extraction...\")\n","start_time = time.time()\n","\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        extracted_count = 0\n","        error_count = 0\n","\n","        for file_info in zip_ref.infolist():\n","            try:\n","                # Extract individual file\n","                zip_ref.extract(file_info, raw_path)\n","                extracted_count += 1\n","\n","                # Progress tracking every 1000 files\n","                if extracted_count % 1000 == 0:\n","                    elapsed = time.time() - start_time\n","                    rate = extracted_count / elapsed\n","                    remaining = total_files - extracted_count\n","                    eta = remaining / rate if rate > 0 else 0\n","\n","                    print(f\"  Progress: {extracted_count}/{total_files} ({(extracted_count/total_files)*100:.1f}%) | \"\n","                          f\"Rate: {rate:.1f} files/sec | ETA: {eta/60:.1f} min\")\n","\n","            except Exception as file_error:\n","                error_count += 1\n","                if error_count <= 5:  # Show first 5 errors only\n","                    print(f\"  ⚠ Error extracting {file_info.filename}: {str(file_error)}\")\n","\n","    extraction_time = time.time() - start_time\n","    print(f\"\\n✓ Extraction completed:\")\n","    print(f\"  - Files extracted: {extracted_count}/{total_files}\")\n","    print(f\"  - Errors encountered: {error_count}\")\n","    print(f\"  - Total time: {extraction_time:.2f} seconds\")\n","    print(f\"  - Average rate: {extracted_count/extraction_time:.1f} files/second\")\n","\n","except Exception as e:\n","    print(f\"✗ EXTRACTION FAILED: {str(e)}\")\n","    exit()\n","\n","# Verify extraction results\n","print(f\"\\n[6] Verifying extraction results...\")\n","\n","# Find the actual extracted structure\n","extracted_items = []\n","for item in os.listdir(raw_path):\n","    if item != \"CASME2_RAW_selected.zip\":  # Skip the ZIP file\n","        item_path = os.path.join(raw_path, item)\n","        if os.path.isdir(item_path):\n","            extracted_items.append(item)\n","\n","print(f\"✓ Extracted directory structure:\")\n","for item in sorted(extracted_items):\n","    item_path = os.path.join(raw_path, item)\n","\n","    # Count contents\n","    total_contents = 0\n","    subject_dirs = 0\n","\n","    if os.path.exists(item_path):\n","        for root, dirs, files in os.walk(item_path):\n","            total_contents += len(files)\n","            # Count directories that look like subjects\n","            for d in dirs:\n","                if d.startswith('sub') and len(d) >= 4:\n","                    subject_dirs += 1\n","\n","    print(f\"  {item}/: {total_contents} files, {subject_dirs} subject directories\")\n","\n","# Final status\n","extraction_success = extracted_count > 0 and error_count < (total_files * 0.1)\n","\n","print(f\"\\n\" + \"=\" * 60)\n","print(\"EXTRACTION SUMMARY\")\n","print(\"=\" * 60)\n","print(f\"Status: {'SUCCESS' if extraction_success else 'PARTIAL/FAILED'}\")\n","print(f\"Files processed: {extracted_count}/{total_files}\")\n","print(f\"Error rate: {(error_count/total_files)*100:.2f}%\" if total_files > 0 else \"N/A\")\n","print(f\"Extraction time: {extraction_time/60:.1f} minutes\")\n","\n","if extraction_success:\n","    print(f\"✓ Ready for Cell 2: Structure validation and analysis\")\n","else:\n","    print(f\"⚠ Partial extraction - may need to retry or investigate ZIP file integrity\")\n","\n","print(\"=\" * 60)"]},{"cell_type":"code","source":["# @title Cell 2: CASME II Metadata Analysis and Structure Mapping\n","\n","import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","from collections import Counter\n","import os\n","\n","# Mount Google Drive\n","print(\"=\" * 70)\n","print(\"CASME II METADATA ANALYSIS AND STRUCTURE MAPPING\")\n","print(\"=\" * 70)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define metadata path\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","\n","print(f\"\\n[2] Loading metadata file...\")\n","print(f\"File path: {metadata_path}\")\n","\n","# Load metadata with comprehensive error handling\n","try:\n","    if os.path.exists(metadata_path):\n","        file_size_mb = round(os.path.getsize(metadata_path) / (1024 * 1024), 3)\n","        print(f\"✓ Metadata file found (Size: {file_size_mb} MB)\")\n","\n","        # Load Excel file\n","        df = pd.read_excel(metadata_path)\n","        print(f\"✓ Excel file loaded successfully\")\n","        print(f\"  - Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n","\n","    else:\n","        print(\"✗ Metadata file not found\")\n","        print(\"Please ensure CASME2-coding-20140508.xlsx is in datasets/metadata/\")\n","        exit()\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","# Column structure analysis\n","print(f\"\\n[3] Column structure analysis...\")\n","print(f\"Raw column names:\")\n","for i, col in enumerate(df.columns):\n","    print(f\"  [{i}] '{col}' - {df[col].dtype}\")\n","\n","# Handle unnamed columns and clean column names\n","print(f\"\\n[4] Column cleaning and mapping...\")\n","cleaned_columns = []\n","column_mapping = {}\n","\n","for i, col in enumerate(df.columns):\n","    if 'Unnamed' in str(col):\n","        # Try to infer content from first few non-null values\n","        sample_values = df[col].dropna().head(3).tolist()\n","        print(f\"  Unnamed column [{i}]: Sample values = {sample_values}\")\n","        cleaned_name = f\"Unknown_Col_{i}\"\n","    else:\n","        cleaned_name = str(col).strip()\n","\n","    cleaned_columns.append(cleaned_name)\n","    column_mapping[col] = cleaned_name\n","\n","# Update dataframe with cleaned columns\n","df_clean = df.copy()\n","df_clean.columns = cleaned_columns\n","\n","print(f\"\\n✓ Cleaned column mapping:\")\n","for orig, clean in column_mapping.items():\n","    non_null_count = df[orig].count()\n","    print(f\"  '{orig}' → '{clean}' ({non_null_count} non-null values)\")\n","\n","# Data type and completeness analysis\n","print(f\"\\n[5] Data completeness analysis...\")\n","completeness_stats = []\n","\n","for col in df_clean.columns:\n","    total_values = len(df_clean)\n","    non_null_values = df_clean[col].count()\n","    null_values = df_clean[col].isnull().sum()\n","    completeness_pct = (non_null_values / total_values) * 100\n","\n","    completeness_stats.append({\n","        'Column': col,\n","        'Non_Null': non_null_values,\n","        'Null': null_values,\n","        'Completeness': f\"{completeness_pct:.1f}%\",\n","        'Data_Type': str(df_clean[col].dtype)\n","    })\n","\n","# Display completeness table\n","completeness_df = pd.DataFrame(completeness_stats)\n","print(f\"\\n✓ Data completeness summary:\")\n","print(completeness_df.to_string(index=False))\n","\n","# Core field identification for MER\n","print(f\"\\n[6] Core field identification for micro-expression recognition...\")\n","\n","# Identify key columns based on common MER naming patterns\n","key_fields = {}\n","potential_mappings = {\n","    'subject': ['subject', 'participant', 'person', 'id'],\n","    'filename': ['filename', 'file', 'video', 'clip'],\n","    'onset_frame': ['onset', 'start', 'begin'],\n","    'apex_frame': ['apex', 'peak', 'max'],\n","    'offset_frame': ['offset', 'end', 'finish'],\n","    'emotion': ['emotion', 'expression', 'feeling', 'estimated'],\n","    'action_units': ['action', 'au', 'units', 'facs']\n","}\n","\n","for field_type, keywords in potential_mappings.items():\n","    for col in df_clean.columns:\n","        col_lower = col.lower()\n","        if any(keyword in col_lower for keyword in keywords):\n","            key_fields[field_type] = col\n","            break\n","\n","print(f\"✓ Identified key fields:\")\n","for field_type, column_name in key_fields.items():\n","    print(f\"  {field_type.upper()}: '{column_name}'\")\n","\n","# Missing critical fields check\n","required_fields = ['subject', 'filename', 'onset_frame', 'apex_frame', 'offset_frame', 'emotion']\n","missing_fields = [field for field in required_fields if field not in key_fields]\n","\n","if missing_fields:\n","    print(f\"\\n⚠ Missing critical fields: {missing_fields}\")\n","    print(\"Manual column inspection may be required\")\n","\n","# Subject analysis for LOSO preparation\n","print(f\"\\n[7] Subject analysis for LOSO cross-validation...\")\n","\n","if 'subject' in key_fields:\n","    subject_col = key_fields['subject']\n","    subject_analysis = df_clean[subject_col].describe()\n","\n","    print(f\"✓ Subject statistics:\")\n","    print(f\"  Total unique subjects: {df_clean[subject_col].nunique()}\")\n","    print(f\"  Subject range: {df_clean[subject_col].min()} to {df_clean[subject_col].max()}\")\n","    print(f\"  Mean samples per subject: {len(df_clean) / df_clean[subject_col].nunique():.1f}\")\n","\n","    # Samples per subject distribution\n","    samples_per_subject = df_clean[subject_col].value_counts().sort_index()\n","\n","    print(f\"\\n✓ Samples per subject distribution:\")\n","    print(f\"  Min samples: {samples_per_subject.min()}\")\n","    print(f\"  Max samples: {samples_per_subject.max()}\")\n","    print(f\"  Median samples: {samples_per_subject.median()}\")\n","\n","    # Show subjects with extreme sample counts\n","    low_sample_subjects = samples_per_subject[samples_per_subject < 5]\n","    high_sample_subjects = samples_per_subject[samples_per_subject > 20]\n","\n","    if len(low_sample_subjects) > 0:\n","        print(f\"  ⚠ Subjects with <5 samples: {len(low_sample_subjects)}\")\n","        print(f\"    {dict(low_sample_subjects)}\")\n","\n","    if len(high_sample_subjects) > 0:\n","        print(f\"  ✓ Subjects with >20 samples: {len(high_sample_subjects)}\")\n","        print(f\"    Top 3: {dict(high_sample_subjects.head(3))}\")\n","\n","# Emotion class analysis\n","print(f\"\\n[8] Emotion class distribution analysis...\")\n","\n","if 'emotion' in key_fields:\n","    emotion_col = key_fields['emotion']\n","    emotion_counts = df_clean[emotion_col].value_counts()\n","    total_samples = len(df_clean)\n","\n","    print(f\"✓ Emotion class distribution:\")\n","    print(f\"  Total classes: {len(emotion_counts)}\")\n","    print(f\"  Class distribution:\")\n","\n","    for emotion, count in emotion_counts.items():\n","        percentage = (count / total_samples) * 100\n","        print(f\"    {emotion}: {count} samples ({percentage:.1f}%)\")\n","\n","    # Class balance analysis\n","    max_samples = emotion_counts.max()\n","    min_samples = emotion_counts.min()\n","    imbalance_ratio = max_samples / min_samples\n","\n","    print(f\"\\n✓ Class balance metrics:\")\n","    print(f\"  Most frequent class: {emotion_counts.index[0]} ({emotion_counts.iloc[0]} samples)\")\n","    print(f\"  Least frequent class: {emotion_counts.index[-1]} ({emotion_counts.iloc[-1]} samples)\")\n","    print(f\"  Imbalance ratio: {imbalance_ratio:.2f}:1\")\n","\n","    if imbalance_ratio > 3:\n","        print(f\"  ⚠ Significant class imbalance detected - focal loss recommended\")\n","    else:\n","        print(f\"  ✓ Moderate class balance - standard loss functions applicable\")\n","\n","# Frame sequence analysis\n","print(f\"\\n[9] Frame sequence analysis...\")\n","\n","frame_fields = ['onset_frame', 'apex_frame', 'offset_frame']\n","available_frame_fields = [field for field in frame_fields if field in key_fields]\n","\n","if len(available_frame_fields) >= 2:\n","    print(f\"✓ Frame sequence fields available: {available_frame_fields}\")\n","\n","    # Calculate sequence lengths and statistics\n","    if all(field in key_fields for field in ['onset_frame', 'offset_frame']):\n","        onset_col = key_fields['onset_frame']\n","        offset_col = key_fields['offset_frame']\n","\n","        sequence_lengths = df_clean[offset_col] - df_clean[onset_col] + 1\n","\n","        print(f\"\\n✓ Sequence length statistics:\")\n","        print(f\"  Mean length: {sequence_lengths.mean():.1f} frames\")\n","        print(f\"  Median length: {sequence_lengths.median():.1f} frames\")\n","        print(f\"  Min length: {sequence_lengths.min()} frames\")\n","        print(f\"  Max length: {sequence_lengths.max()} frames\")\n","        print(f\"  Standard deviation: {sequence_lengths.std():.1f} frames\")\n","\n","# Sample data display\n","print(f\"\\n[10] Sample metadata records...\")\n","\n","if len(key_fields) >= 3:\n","    # Select most relevant columns for display\n","    display_cols = [col for col in [key_fields.get('subject'),\n","                                   key_fields.get('filename'),\n","                                   key_fields.get('onset_frame'),\n","                                   key_fields.get('apex_frame'),\n","                                   key_fields.get('offset_frame'),\n","                                   key_fields.get('emotion')] if col]\n","\n","    sample_df = df_clean[display_cols].head(5)\n","    print(f\"✓ Sample records (first 5 rows):\")\n","    print(sample_df.to_string(index=False))\n","\n","# Key information summary for next cells\n","print(f\"\\n[11] Key information for Cell 3 cross-validation...\")\n","\n","print(f\"✓ Critical metadata summary:\")\n","print(f\"  - Total records: {len(df_clean)}\")\n","print(f\"  - Unique subjects: {df_clean[key_fields['subject']].nunique() if 'subject' in key_fields else 'Unknown'}\")\n","print(f\"  - Emotion classes: {df_clean[key_fields['emotion']].nunique() if 'emotion' in key_fields else 'Unknown'}\")\n","print(f\"  - Key columns identified: {len(key_fields)}/{len(required_fields)} required fields\")\n","\n","# Export summary for next cells\n","field_summary = {\n","    'subject_column': key_fields.get('subject'),\n","    'filename_column': key_fields.get('filename'),\n","    'emotion_column': key_fields.get('emotion'),\n","    'total_subjects': df_clean[key_fields['subject']].nunique() if 'subject' in key_fields else 0,\n","    'total_samples': len(df_clean),\n","    'emotion_classes': df_clean[key_fields['emotion']].nunique() if 'emotion' in key_fields else 0\n","}\n","\n","print(f\"\\n✓ Field mapping for Cell 3:\")\n","for key, value in field_summary.items():\n","    print(f\"  {key}: {value}\")\n","\n","# Final summary\n","print(f\"\\n\" + \"=\" * 70)\n","print(\"METADATA ANALYSIS SUMMARY\")\n","print(\"=\" * 70)\n","\n","analysis_status = \"COMPLETE\" if len(key_fields) >= 5 else \"PARTIAL\"\n","print(f\"Analysis Status: {analysis_status}\")\n","print(f\"Records processed: {len(df_clean)}\")\n","print(f\"Key fields identified: {len(key_fields)}\")\n","print(f\"Ready for cross-validation: {'Yes' if analysis_status == 'COMPLETE' else 'Needs manual review'}\")\n","\n","if analysis_status == \"COMPLETE\":\n","    print(f\"✓ Metadata structure fully mapped - proceed to Cell 3 for dataset cross-validation\")\n","else:\n","    print(f\"⚠ Some fields require manual identification - review column mappings before Cell 3\")\n","\n","print(\"=\" * 70)"],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"CEszfGagrYxr","executionInfo":{"status":"ok","timestamp":1758692648138,"user_tz":-420,"elapsed":4503,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"4cb0748d-b7d1-4100-b633-596a73d5133b","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CASME II METADATA ANALYSIS AND STRUCTURE MAPPING\n","======================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Loading metadata file...\n","File path: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/metadata/CASME2-coding-20140508.xlsx\n","✓ Metadata file found (Size: 0.024 MB)\n","✓ Excel file loaded successfully\n","  - Shape: 255 rows × 9 columns\n","\n","[3] Column structure analysis...\n","Raw column names:\n","  [0] 'Subject' - int64\n","  [1] 'Filename' - object\n","  [2] 'Unnamed: 2' - float64\n","  [3] 'OnsetFrame' - int64\n","  [4] 'ApexFrame' - object\n","  [5] 'OffsetFrame' - int64\n","  [6] 'Unnamed: 6' - float64\n","  [7] 'Action Units' - object\n","  [8] 'Estimated Emotion' - object\n","\n","[4] Column cleaning and mapping...\n","  Unnamed column [2]: Sample values = []\n","  Unnamed column [6]: Sample values = []\n","\n","✓ Cleaned column mapping:\n","  'Subject' → 'Subject' (255 non-null values)\n","  'Filename' → 'Filename' (255 non-null values)\n","  'Unnamed: 2' → 'Unknown_Col_2' (0 non-null values)\n","  'OnsetFrame' → 'OnsetFrame' (255 non-null values)\n","  'ApexFrame' → 'ApexFrame' (255 non-null values)\n","  'OffsetFrame' → 'OffsetFrame' (255 non-null values)\n","  'Unnamed: 6' → 'Unknown_Col_6' (0 non-null values)\n","  'Action Units' → 'Action Units' (255 non-null values)\n","  'Estimated Emotion' → 'Estimated Emotion' (255 non-null values)\n","\n","[5] Data completeness analysis...\n","\n","✓ Data completeness summary:\n","           Column  Non_Null  Null Completeness Data_Type\n","          Subject       255     0       100.0%     int64\n","         Filename       255     0       100.0%    object\n","    Unknown_Col_2         0   255         0.0%   float64\n","       OnsetFrame       255     0       100.0%     int64\n","        ApexFrame       255     0       100.0%    object\n","      OffsetFrame       255     0       100.0%     int64\n","    Unknown_Col_6         0   255         0.0%   float64\n","     Action Units       255     0       100.0%    object\n","Estimated Emotion       255     0       100.0%    object\n","\n","[6] Core field identification for micro-expression recognition...\n","✓ Identified key fields:\n","  SUBJECT: 'Subject'\n","  FILENAME: 'Filename'\n","  ONSET_FRAME: 'OnsetFrame'\n","  APEX_FRAME: 'ApexFrame'\n","  OFFSET_FRAME: 'OffsetFrame'\n","  EMOTION: 'Estimated Emotion'\n","  ACTION_UNITS: 'Action Units'\n","\n","[7] Subject analysis for LOSO cross-validation...\n","✓ Subject statistics:\n","  Total unique subjects: 26\n","  Subject range: 1 to 26\n","  Mean samples per subject: 9.8\n","\n","✓ Samples per subject distribution:\n","  Min samples: 2\n","  Max samples: 36\n","  Median samples: 9.0\n","  ⚠ Subjects with <5 samples: 7\n","    {8: np.int64(3), 14: np.int64(4), 15: np.int64(3), 16: np.int64(4), 18: np.int64(3), 21: np.int64(2), 22: np.int64(2)}\n","  ✓ Subjects with >20 samples: 1\n","    Top 3: {17: np.int64(36)}\n","\n","[8] Emotion class distribution analysis...\n","✓ Emotion class distribution:\n","  Total classes: 7\n","  Class distribution:\n","    others: 99 samples (38.8%)\n","    disgust: 63 samples (24.7%)\n","    happiness: 32 samples (12.5%)\n","    repression: 27 samples (10.6%)\n","    surprise: 25 samples (9.8%)\n","    sadness: 7 samples (2.7%)\n","    fear: 2 samples (0.8%)\n","\n","✓ Class balance metrics:\n","  Most frequent class: others (99 samples)\n","  Least frequent class: fear (2 samples)\n","  Imbalance ratio: 49.50:1\n","  ⚠ Significant class imbalance detected - focal loss recommended\n","\n","[9] Frame sequence analysis...\n","✓ Frame sequence fields available: ['onset_frame', 'apex_frame', 'offset_frame']\n","\n","✓ Sequence length statistics:\n","  Mean length: 67.2 frames\n","  Median length: 61.0 frames\n","  Min length: 24 frames\n","  Max length: 141 frames\n","  Standard deviation: 22.6 frames\n","\n","[10] Sample metadata records...\n","✓ Sample records (first 5 rows):\n"," Subject Filename  OnsetFrame ApexFrame  OffsetFrame Estimated Emotion\n","       1 EP02_01f          46        59           86         happiness\n","       1  EP03_02         131       139          161            others\n","       1  EP04_02          21        54           76            others\n","       1  EP04_03          31        41           56            others\n","       1  EP04_04          23        49           66            others\n","\n","[11] Key information for Cell 3 cross-validation...\n","✓ Critical metadata summary:\n","  - Total records: 255\n","  - Unique subjects: 26\n","  - Emotion classes: 7\n","  - Key columns identified: 7/6 required fields\n","\n","✓ Field mapping for Cell 3:\n","  subject_column: Subject\n","  filename_column: Filename\n","  emotion_column: Estimated Emotion\n","  total_subjects: 26\n","  total_samples: 255\n","  emotion_classes: 7\n","\n","======================================================================\n","METADATA ANALYSIS SUMMARY\n","======================================================================\n","Analysis Status: COMPLETE\n","Records processed: 255\n","Key fields identified: 7\n","Ready for cross-validation: Yes\n","✓ Metadata structure fully mapped - proceed to Cell 3 for dataset cross-validation\n","======================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 3: CASME II Dataset-Metadata Cross-Validation\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","from collections import defaultdict\n","import glob\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II DATASET-METADATA CROSS-VALIDATION\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","\n","# Find dataset root path\n","dataset_paths = [\n","    f\"{raw_path}/CASME2_RAW_selected\",  # Direct extraction\n","    f\"{raw_path}/CASME2/CASME2_RAW_selected\",  # Nested extraction\n","]\n","\n","dataset_root = None\n","for path in dataset_paths:\n","    if os.path.exists(path):\n","        dataset_root = path\n","        break\n","\n","print(f\"\\n[2] Locating dataset structure...\")\n","print(f\"Dataset root: {dataset_root}\")\n","\n","if dataset_root is None:\n","    print(\"✗ Dataset not found in expected locations\")\n","    print(\"Available paths:\")\n","    for item in os.listdir(raw_path):\n","        if os.path.isdir(os.path.join(raw_path, item)):\n","            print(f\"  - {item}/\")\n","    exit()\n","\n","print(f\"✓ Dataset found at: {dataset_root}\")\n","\n","# Load metadata with key field mappings from Cell 2\n","print(f\"\\n[3] Loading metadata with field mappings...\")\n","\n","try:\n","    df = pd.read_excel(metadata_path)\n","\n","    # Key field mappings from Cell 2 analysis\n","    field_mapping = {\n","        'subject': 'Subject',\n","        'filename': 'Filename',\n","        'onset_frame': 'OnsetFrame',\n","        'apex_frame': 'ApexFrame',\n","        'offset_frame': 'OffsetFrame',\n","        'emotion': 'Estimated Emotion'\n","    }\n","\n","    print(f\"✓ Metadata loaded: {len(df)} records\")\n","    print(f\"✓ Field mappings applied:\")\n","    for key, col in field_mapping.items():\n","        print(f\"  {key} → '{col}'\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","# Analyze dataset directory structure\n","print(f\"\\n[4] Analyzing dataset directory structure...\")\n","\n","subject_folders = []\n","dataset_structure = {}\n","\n","for item in sorted(os.listdir(dataset_root)):\n","    item_path = os.path.join(dataset_root, item)\n","\n","    if os.path.isdir(item_path):\n","        # Check if this is a subject folder\n","        if item.startswith('sub') or (item.startswith('s') and len(item) <= 4) or item.isdigit():\n","            subject_folders.append(item)\n","\n","            # Analyze contents of subject folder\n","            video_folders = []\n","            total_images = 0\n","\n","            for root, dirs, files in os.walk(item_path):\n","                # Count image files\n","                image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n","                total_images += len(image_files)\n","\n","                # Track video/sequence folders\n","                if root != item_path:  # Subdirectories\n","                    rel_path = os.path.relpath(root, item_path)\n","                    video_folders.append(rel_path)\n","\n","            dataset_structure[item] = {\n","                'path': item_path,\n","                'video_folders': sorted(video_folders),\n","                'total_images': total_images,\n","                'video_count': len(video_folders)\n","            }\n","\n","print(f\"✓ Found {len(subject_folders)} subject folders in dataset\")\n","\n","# Display dataset structure summary\n","if subject_folders:\n","    print(f\"\\n[5] Dataset structure analysis:\")\n","    total_images_all = 0\n","    total_videos_all = 0\n","\n","    for subject in sorted(subject_folders[:15]):  # Show first 15\n","        data = dataset_structure[subject]\n","        total_images_all += data['total_images']\n","        total_videos_all += data['video_count']\n","\n","        print(f\"  {subject}: {data['total_images']} images, {data['video_count']} video sequences\")\n","\n","    if len(subject_folders) > 15:\n","        remaining = subject_folders[15:]\n","        remaining_images = sum(dataset_structure[s]['total_images'] for s in remaining)\n","        remaining_videos = sum(dataset_structure[s]['video_count'] for s in remaining)\n","        total_images_all += remaining_images\n","        total_videos_all += remaining_videos\n","        print(f\"  ... and {len(remaining)} more subjects ({remaining_images} images, {remaining_videos} videos)\")\n","\n","    print(f\"\\n✓ Dataset totals: {total_images_all} images, {total_videos_all} video sequences\")\n","\n","# Subject mapping between metadata and dataset\n","print(f\"\\n[6] Cross-validation: Subject mapping...\")\n","\n","# Extract subjects from metadata\n","metadata_subjects = sorted(df[field_mapping['subject']].unique())\n","metadata_subject_folders = [f\"sub{str(s).zfill(2)}\" for s in metadata_subjects]\n","\n","# Normalize dataset subject folder names\n","normalized_dataset_subjects = []\n","subject_name_mapping = {}\n","\n","for folder in subject_folders:\n","    if folder.startswith('sub'):\n","        normalized_name = folder\n","    elif folder.startswith('s') and folder[1:].isdigit():\n","        num = int(folder[1:])\n","        normalized_name = f\"sub{str(num).zfill(2)}\"\n","    elif folder.isdigit():\n","        num = int(folder)\n","        normalized_name = f\"sub{str(num).zfill(2)}\"\n","    else:\n","        normalized_name = folder\n","\n","    normalized_dataset_subjects.append(normalized_name)\n","    subject_name_mapping[normalized_name] = folder\n","\n","normalized_dataset_subjects = sorted(set(normalized_dataset_subjects))\n","\n","# Compare subject sets\n","missing_in_dataset = set(metadata_subject_folders) - set(normalized_dataset_subjects)\n","extra_in_dataset = set(normalized_dataset_subjects) - set(metadata_subject_folders)\n","matched_subjects = set(metadata_subject_folders) & set(normalized_dataset_subjects)\n","\n","print(f\"✓ Subject mapping analysis:\")\n","print(f\"  Metadata subjects: {len(metadata_subject_folders)} ({min(metadata_subjects)} to {max(metadata_subjects)})\")\n","print(f\"  Dataset subjects: {len(normalized_dataset_subjects)}\")\n","print(f\"  Matched subjects: {len(matched_subjects)}\")\n","\n","if missing_in_dataset:\n","    print(f\"  ⚠ Missing in dataset: {len(missing_in_dataset)}\")\n","    print(f\"    {sorted(list(missing_in_dataset))}\")\n","\n","if extra_in_dataset:\n","    print(f\"  ⚠ Extra in dataset: {len(extra_in_dataset)}\")\n","    print(f\"    {sorted(list(extra_in_dataset))}\")\n","\n","subject_coverage = (len(matched_subjects) / len(metadata_subject_folders)) * 100\n","print(f\"  Coverage: {subject_coverage:.1f}%\")\n","\n","# Video sequence validation\n","print(f\"\\n[7] Cross-validation: Video sequence mapping...\")\n","\n","sequence_validation = {}\n","total_matched_sequences = 0\n","total_metadata_sequences = len(df)\n","\n","for subject_num in metadata_subjects:\n","    subject_folder = f\"sub{str(subject_num).zfill(2)}\"\n","\n","    if subject_folder in matched_subjects:\n","        # Get metadata sequences for this subject\n","        subject_metadata = df[df[field_mapping['subject']] == subject_num]\n","        metadata_filenames = set(subject_metadata[field_mapping['filename']].values)\n","\n","        # Get actual sequences in dataset\n","        actual_folder = subject_name_mapping[subject_folder]\n","        dataset_sequences = set(dataset_structure[actual_folder]['video_folders'])\n","\n","        # Compare sequences\n","        matched_sequences = metadata_filenames & dataset_sequences\n","        missing_sequences = metadata_filenames - dataset_sequences\n","        extra_sequences = dataset_sequences - metadata_filenames\n","\n","        sequence_validation[subject_folder] = {\n","            'metadata_count': len(metadata_filenames),\n","            'dataset_count': len(dataset_sequences),\n","            'matched_count': len(matched_sequences),\n","            'missing_in_dataset': list(missing_sequences),\n","            'extra_in_dataset': list(extra_sequences)\n","        }\n","\n","        total_matched_sequences += len(matched_sequences)\n","\n","print(f\"✓ Sequence validation results:\")\n","print(f\"  Total metadata sequences: {total_metadata_sequences}\")\n","print(f\"  Total matched sequences: {total_matched_sequences}\")\n","print(f\"  Sequence coverage: {(total_matched_sequences/total_metadata_sequences)*100:.1f}%\")\n","\n","# Show detailed validation for subjects with issues\n","problematic_subjects = 0\n","for subject, validation in sequence_validation.items():\n","    if validation['missing_in_dataset'] or len(validation['missing_in_dataset']) > 2:\n","        problematic_subjects += 1\n","\n","if problematic_subjects > 0:\n","    print(f\"  ⚠ Subjects with sequence mismatches: {problematic_subjects}\")\n","\n","    # Show first few problematic subjects\n","    shown_count = 0\n","    for subject, validation in sequence_validation.items():\n","        if validation['missing_in_dataset'] and shown_count < 3:\n","            print(f\"    {subject}: {len(validation['missing_in_dataset'])} missing sequences\")\n","            shown_count += 1\n","\n","# Sample file validation\n","print(f\"\\n[8] Sample file structure validation...\")\n","\n","if matched_subjects:\n","    # Pick a sample subject for detailed file analysis\n","    sample_subject = sorted(list(matched_subjects))[0]\n","    actual_folder = subject_name_mapping[sample_subject]\n","    sample_metadata = df[df[field_mapping['subject']] == int(sample_subject[3:])].iloc[0]\n","\n","    print(f\"✓ Sample validation using {sample_subject}:\")\n","    print(f\"  Subject folder: {actual_folder}\")\n","    print(f\"  Sample sequence: {sample_metadata[field_mapping['filename']]}\")\n","    print(f\"  Expected frames: {sample_metadata[field_mapping['onset_frame']]} to {sample_metadata[field_mapping['offset_frame']]}\")\n","\n","    # Check if sample sequence exists\n","    sequence_path = os.path.join(dataset_structure[actual_folder]['path'], sample_metadata[field_mapping['filename']])\n","\n","    if os.path.exists(sequence_path):\n","        # Count actual image files\n","        image_files = [f for f in os.listdir(sequence_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n","        image_count = len(image_files)\n","\n","        # Sample a few filenames to check naming pattern\n","        sample_files = sorted(image_files)[:5]\n","\n","        print(f\"  ✓ Sequence exists with {image_count} images\")\n","        print(f\"  ✓ Sample filenames: {sample_files}\")\n","\n","        # Check if frame range matches approximately\n","        expected_frames = sample_metadata[field_mapping['offset_frame']] - sample_metadata[field_mapping['onset_frame']] + 1\n","        frame_match = abs(image_count - expected_frames) <= 5  # Allow some tolerance\n","\n","        print(f\"  Frame count match: {'✓' if frame_match else '⚠'} (expected ~{expected_frames}, found {image_count})\")\n","\n","    else:\n","        print(f\"  ✗ Sample sequence not found at expected path\")\n","\n","# Data integrity summary\n","print(f\"\\n[9] Data integrity assessment...\")\n","\n","integrity_score = 0\n","max_score = 4\n","\n","# Subject coverage score\n","if subject_coverage >= 95:\n","    integrity_score += 1\n","    subject_status = \"✓\"\n","else:\n","    subject_status = \"⚠\"\n","\n","# Sequence coverage score\n","sequence_coverage = (total_matched_sequences/total_metadata_sequences)*100\n","if sequence_coverage >= 90:\n","    integrity_score += 1\n","    sequence_status = \"✓\"\n","else:\n","    sequence_status = \"⚠\"\n","\n","# File structure score\n","if 'image_count' in locals() and image_count > 0:\n","    integrity_score += 1\n","    file_status = \"✓\"\n","else:\n","    file_status = \"⚠\"\n","\n","# Overall completeness\n","if missing_in_dataset == set() and extra_in_dataset == set():\n","    integrity_score += 1\n","    completeness_status = \"✓\"\n","else:\n","    completeness_status = \"⚠\"\n","\n","print(f\"✓ Data integrity summary:\")\n","print(f\"  {subject_status} Subject coverage: {subject_coverage:.1f}%\")\n","print(f\"  {sequence_status} Sequence coverage: {sequence_coverage:.1f}%\")\n","print(f\"  {file_status} File structure: {'Valid' if 'image_count' in locals() else 'Needs validation'}\")\n","print(f\"  {completeness_status} Data completeness: {'Complete' if integrity_score == 4 else 'Partial'}\")\n","\n","integrity_percentage = (integrity_score / max_score) * 100\n","print(f\"  Overall integrity: {integrity_percentage:.0f}% ({integrity_score}/{max_score} checks passed)\")\n","\n","# LOSO readiness assessment\n","print(f\"\\n[10] LOSO cross-validation readiness...\")\n","\n","loso_ready_subjects = 0\n","loso_issues = []\n","\n","for subject_num in metadata_subjects:\n","    subject_folder = f\"sub{str(subject_num).zfill(2)}\"\n","\n","    if subject_folder in matched_subjects:\n","        subject_metadata = df[df[field_mapping['subject']] == subject_num]\n","        sample_count = len(subject_metadata)\n","\n","        if sample_count >= 3:  # Minimum for meaningful validation\n","            loso_ready_subjects += 1\n","        else:\n","            loso_issues.append(f\"{subject_folder}({sample_count} samples)\")\n","\n","print(f\"✓ LOSO readiness assessment:\")\n","print(f\"  Total subjects: {len(metadata_subjects)}\")\n","print(f\"  LOSO-ready subjects: {loso_ready_subjects}\")\n","print(f\"  Subjects with issues: {len(loso_issues)}\")\n","\n","if loso_issues:\n","    print(f\"  ⚠ Low-sample subjects: {', '.join(loso_issues)}\")\n","    print(f\"  Recommendation: Consider excluding subjects with <3 samples\")\n","\n","loso_readiness = (loso_ready_subjects / len(metadata_subjects)) * 100\n","print(f\"  LOSO readiness: {loso_readiness:.1f}%\")\n","\n","# Final summary and recommendations\n","print(f\"\\n\" + \"=\" * 75)\n","print(\"CROSS-VALIDATION SUMMARY\")\n","print(\"=\" * 75)\n","\n","overall_status = \"READY\" if integrity_score >= 3 and loso_readiness >= 80 else \"NEEDS_ATTENTION\"\n","print(f\"Overall Status: {overall_status}\")\n","print(f\"Data Integrity: {integrity_percentage:.0f}%\")\n","print(f\"Subject Coverage: {subject_coverage:.1f}%\")\n","print(f\"LOSO Readiness: {loso_readiness:.1f}%\")\n","\n","print(f\"\\n✓ Next steps:\")\n","if overall_status == \"READY\":\n","    print(f\"  - Dataset validated and ready for preprocessing\")\n","    print(f\"  - Proceed to Cell 4: Data preprocessing pipeline\")\n","    print(f\"  - Consider focal loss for class imbalance (49.5:1 ratio)\")\n","else:\n","    print(f\"  - Resolve missing sequences and subjects\")\n","    print(f\"  - Manual verification of problematic subjects recommended\")\n","    print(f\"  - Consider subset analysis if full dataset unavailable\")\n","\n","print(\"=\" * 75)"],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"cthXqzsqRhIj","executionInfo":{"status":"ok","timestamp":1758693398148,"user_tz":-420,"elapsed":3440,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"6df80fa2-0cdf-483d-d19a-f97237f91cfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II DATASET-METADATA CROSS-VALIDATION\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Locating dataset structure...\n","Dataset root: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw/CASME2_RAW_selected\n","✓ Dataset found at: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw/CASME2_RAW_selected\n","\n","[3] Loading metadata with field mappings...\n","✓ Metadata loaded: 255 records\n","✓ Field mappings applied:\n","  subject → 'Subject'\n","  filename → 'Filename'\n","  onset_frame → 'OnsetFrame'\n","  apex_frame → 'ApexFrame'\n","  offset_frame → 'OffsetFrame'\n","  emotion → 'Estimated Emotion'\n","\n","[4] Analyzing dataset directory structure...\n","✓ Found 26 subject folders in dataset\n","\n","[5] Dataset structure analysis:\n","  sub01: 497 images, 9 video sequences\n","  sub02: 1096 images, 13 video sequences\n","  sub03: 472 images, 7 video sequences\n","  sub04: 300 images, 5 video sequences\n","  sub05: 1226 images, 19 video sequences\n","  sub06: 261 images, 5 video sequences\n","  sub07: 574 images, 9 video sequences\n","  sub08: 271 images, 3 video sequences\n","  sub09: 1154 images, 14 video sequences\n","  sub10: 1000 images, 14 video sequences\n","  sub11: 764 images, 10 video sequences\n","  sub12: 956 images, 12 video sequences\n","  sub13: 462 images, 8 video sequences\n","  sub14: 279 images, 4 video sequences\n","  sub15: 210 images, 3 video sequences\n","  ... and 11 more subjects (7602 images, 120 videos)\n","\n","✓ Dataset totals: 17124 images, 255 video sequences\n","\n","[6] Cross-validation: Subject mapping...\n","✓ Subject mapping analysis:\n","  Metadata subjects: 26 (1 to 26)\n","  Dataset subjects: 26\n","  Matched subjects: 26\n","  Coverage: 100.0%\n","\n","[7] Cross-validation: Video sequence mapping...\n","✓ Sequence validation results:\n","  Total metadata sequences: 255\n","  Total matched sequences: 255\n","  Sequence coverage: 100.0%\n","\n","[8] Sample file structure validation...\n","✓ Sample validation using sub01:\n","  Subject folder: sub01\n","  Sample sequence: EP02_01f\n","  Expected frames: 46 to 86\n","  ✓ Sequence exists with 41 images\n","  ✓ Sample filenames: ['img46.jpg', 'img47.jpg', 'img48.jpg', 'img49.jpg', 'img50.jpg']\n","  Frame count match: ✓ (expected ~41, found 41)\n","\n","[9] Data integrity assessment...\n","✓ Data integrity summary:\n","  ✓ Subject coverage: 100.0%\n","  ✓ Sequence coverage: 100.0%\n","  ✓ File structure: Valid\n","  ✓ Data completeness: Complete\n","  Overall integrity: 100% (4/4 checks passed)\n","\n","[10] LOSO cross-validation readiness...\n","✓ LOSO readiness assessment:\n","  Total subjects: 26\n","  LOSO-ready subjects: 24\n","  Subjects with issues: 2\n","  ⚠ Low-sample subjects: sub21(2 samples), sub22(2 samples)\n","  Recommendation: Consider excluding subjects with <3 samples\n","  LOSO readiness: 92.3%\n","\n","===========================================================================\n","CROSS-VALIDATION SUMMARY\n","===========================================================================\n","Overall Status: READY\n","Data Integrity: 100%\n","Subject Coverage: 100.0%\n","LOSO Readiness: 92.3%\n","\n","✓ Next steps:\n","  - Dataset validated and ready for preprocessing\n","  - Proceed to Cell 4: Data preprocessing pipeline\n","  - Consider focal loss for class imbalance (49.5:1 ratio)\n","===========================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 4: CASME II Data Preprocessing with Fixed JSON Serialization\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import shutil\n","from google.colab import drive\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","import json\n","from pathlib import Path\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II DATA PREPROCESSING AND STRATIFIED SPLIT\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw/CASME2_RAW_selected\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","processed_path = f\"{base_path}/datasets/processed_casme2\"\n","\n","print(f\"\\n[2] Setting up processed dataset structure...\")\n","print(f\"Raw data source: {raw_path}\")\n","print(f\"Processed destination: {processed_path}\")\n","\n","# Create processed directory structure\n","data_split_path = f\"{processed_path}/data_split_v1\"\n","directories = [\n","    f\"{data_split_path}/train\",\n","    f\"{data_split_path}/val\",\n","    f\"{data_split_path}/test\"\n","]\n","\n","for directory in directories:\n","    os.makedirs(directory, exist_ok=True)\n","    print(f\"✓ Created directory: {directory}\")\n","\n","# Load metadata with emotion class focus\n","print(f\"\\n[3] Loading metadata and analyzing class distribution...\")\n","\n","try:\n","    df = pd.read_excel(metadata_path)\n","\n","    # Clean ApexFrame column if it contains non-numeric values\n","    if df['ApexFrame'].dtype == 'object':\n","        # Convert to numeric, handle any text values\n","        df['ApexFrame'] = pd.to_numeric(df['ApexFrame'], errors='coerce')\n","        print(f\"⚠ ApexFrame column contained non-numeric values, converted to numeric\")\n","\n","    print(f\"✓ Metadata loaded: {len(df)} records\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","# Analyze emotion class distribution for stratification\n","emotion_distribution = df['Estimated Emotion'].value_counts()\n","total_samples = len(df)\n","\n","print(f\"\\n[4] Emotion class analysis for stratification:\")\n","print(f\"Total classes: {len(emotion_distribution)}\")\n","\n","stratification_feasible = {}\n","for emotion, count in emotion_distribution.items():\n","    min_for_split = 3  # Minimum 1 per train/val/test\n","    feasible = count >= min_for_split\n","    stratification_feasible[emotion] = feasible\n","\n","    percentage = (count / total_samples) * 100\n","    status = \"✓\" if feasible else \"⚠\"\n","    print(f\"  {status} {emotion}: {count} samples ({percentage:.1f}%)\")\n","\n","problematic_classes = [k for k, v in stratification_feasible.items() if not v]\n","if problematic_classes:\n","    print(f\"\\n⚠ Classes with <3 samples: {problematic_classes}\")\n","    print(f\"  Strategy: Use random assignment for these classes\")\n","\n","# Create sample inventory for processing\n","print(f\"\\n[5] Creating sample inventory for apex frame extraction...\")\n","\n","sample_inventory = []\n","processing_errors = []\n","\n","for idx, row in df.iterrows():\n","    try:\n","        subject = f\"sub{str(row['Subject']).zfill(2)}\"\n","        sequence = row['Filename']\n","\n","        # Frame information\n","        onset_frame = int(row['OnsetFrame'])\n","        apex_frame = int(row['ApexFrame']) if pd.notna(row['ApexFrame']) else None\n","        offset_frame = int(row['OffsetFrame'])\n","        emotion = row['Estimated Emotion']\n","\n","        # Source path for sequence\n","        source_sequence_path = os.path.join(raw_path, subject, sequence)\n","\n","        # Check if source exists\n","        if os.path.exists(source_sequence_path):\n","            # List image files in sequence\n","            image_files = sorted([f for f in os.listdir(source_sequence_path)\n","                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n","\n","            if image_files:\n","                # Determine apex image file\n","                if apex_frame is not None:\n","                    # Find image file corresponding to apex frame\n","                    apex_img = f\"img{apex_frame}.jpg\"\n","                    if apex_img in image_files:\n","                        apex_image_path = os.path.join(source_sequence_path, apex_img)\n","                    else:\n","                        # Fallback to middle frame\n","                        middle_idx = len(image_files) // 2\n","                        apex_image_path = os.path.join(source_sequence_path, image_files[middle_idx])\n","                        apex_frame = \"middle_frame\"\n","                else:\n","                    # Use middle frame as apex\n","                    middle_idx = len(image_files) // 2\n","                    apex_image_path = os.path.join(source_sequence_path, image_files[middle_idx])\n","                    apex_frame = \"middle_frame\"\n","\n","                sample_inventory.append({\n","                    'sample_id': f\"{subject}_{sequence}\",\n","                    'subject': subject,\n","                    'sequence': sequence,\n","                    'emotion': emotion,\n","                    'apex_frame_num': apex_frame,\n","                    'source_apex_path': apex_image_path,\n","                    'total_frames': len(image_files),\n","                    'onset_frame': onset_frame,\n","                    'offset_frame': offset_frame\n","                })\n","            else:\n","                processing_errors.append(f\"No images in {source_sequence_path}\")\n","        else:\n","            processing_errors.append(f\"Sequence not found: {source_sequence_path}\")\n","\n","    except Exception as e:\n","        processing_errors.append(f\"Row {idx}: {str(e)}\")\n","\n","print(f\"✓ Sample inventory created:\")\n","print(f\"  Valid samples: {len(sample_inventory)}\")\n","print(f\"  Processing errors: {len(processing_errors)}\")\n","\n","if processing_errors and len(processing_errors) <= 5:\n","    print(f\"  Sample errors: {processing_errors}\")\n","\n","# Convert to DataFrame for easier manipulation\n","inventory_df = pd.DataFrame(sample_inventory)\n","\n","# Stratified splitting with special handling for minority classes\n","print(f\"\\n[6] Performing stratified dataset splitting...\")\n","\n","train_samples = []\n","val_samples = []\n","test_samples = []\n","\n","# Handle each emotion class separately\n","for emotion in emotion_distribution.index:\n","    emotion_samples = inventory_df[inventory_df['emotion'] == emotion].copy()\n","    n_samples = len(emotion_samples)\n","\n","    print(f\"\\n  Processing {emotion} class ({n_samples} samples):\")\n","\n","    if n_samples >= 3:\n","        # Standard stratified split: 80% train, 10% val, 10% test\n","        # First split: 80% train, 20% temp\n","        train_data, temp_data = train_test_split(\n","            emotion_samples,\n","            test_size=0.2,\n","            random_state=42,\n","            stratify=None  # Can't stratify single class\n","        )\n","\n","        # Second split: 50% val, 50% test from temp (10% each of original)\n","        if len(temp_data) >= 2:\n","            val_data, test_data = train_test_split(\n","                temp_data,\n","                test_size=0.5,\n","                random_state=42,\n","                stratify=None\n","            )\n","        else:\n","            # If only 1 sample in temp, assign to val\n","            val_data = temp_data\n","            test_data = pd.DataFrame()  # Empty\n","\n","        train_count = len(train_data)\n","        val_count = len(val_data)\n","        test_count = len(test_data)\n","\n","        print(f\"    ✓ Split: {train_count} train, {val_count} val, {test_count} test\")\n","\n","    else:\n","        # For very small classes, distribute manually\n","        if n_samples == 2:\n","            train_data = emotion_samples.iloc[:1]\n","            val_data = emotion_samples.iloc[1:2]\n","            test_data = pd.DataFrame()\n","            print(f\"    ⚠ Manual split: 1 train, 1 val, 0 test\")\n","        elif n_samples == 1:\n","            train_data = emotion_samples\n","            val_data = pd.DataFrame()\n","            test_data = pd.DataFrame()\n","            print(f\"    ⚠ Single sample: 1 train, 0 val, 0 test\")\n","        else:\n","            # No samples\n","            train_data = val_data = test_data = pd.DataFrame()\n","            print(f\"    ✗ No samples available\")\n","\n","    # Add to respective lists\n","    if not train_data.empty:\n","        train_samples.append(train_data)\n","    if not val_data.empty:\n","        val_samples.append(val_data)\n","    if not test_data.empty:\n","        test_samples.append(test_data)\n","\n","# Combine all splits\n","train_df = pd.concat(train_samples, ignore_index=True) if train_samples else pd.DataFrame()\n","val_df = pd.concat(val_samples, ignore_index=True) if val_samples else pd.DataFrame()\n","test_df = pd.concat(test_samples, ignore_index=True) if test_samples else pd.DataFrame()\n","\n","print(f\"\\n✓ Final split summary:\")\n","print(f\"  Training set: {len(train_df)} samples\")\n","print(f\"  Validation set: {len(val_df)} samples\")\n","print(f\"  Test set: {len(test_df)} samples\")\n","print(f\"  Total: {len(train_df) + len(val_df) + len(test_df)} samples\")\n","\n","# Display class distribution per split\n","print(f\"\\n[7] Class distribution verification:\")\n","\n","splits = {'train': train_df, 'val': val_df, 'test': test_df}\n","split_stats = {}\n","\n","for split_name, split_data in splits.items():\n","    if not split_data.empty:\n","        class_counts = split_data['emotion'].value_counts()\n","        split_stats[split_name] = dict(class_counts)\n","\n","        print(f\"\\n  {split_name.upper()} set distribution:\")\n","        for emotion, count in class_counts.items():\n","            percentage = (count / len(split_data)) * 100\n","            print(f\"    {emotion}: {count} ({percentage:.1f}%)\")\n","\n","# Copy apex frames to respective directories\n","print(f\"\\n[8] Copying apex frames to split directories...\")\n","\n","copy_stats = {'train': 0, 'val': 0, 'test': 0}\n","copy_errors = []\n","\n","for split_name, split_data in splits.items():\n","    if split_data.empty:\n","        continue\n","\n","    split_dir = f\"{data_split_path}/{split_name}\"\n","\n","    for idx, row in split_data.iterrows():\n","        try:\n","            source_path = row['source_apex_path']\n","\n","            # Create destination filename: subject_sequence_emotion.jpg\n","            dest_filename = f\"{row['sample_id']}_{row['emotion']}.jpg\"\n","            dest_path = os.path.join(split_dir, dest_filename)\n","\n","            # Copy apex frame\n","            if os.path.exists(source_path):\n","                shutil.copy2(source_path, dest_path)\n","                copy_stats[split_name] += 1\n","            else:\n","                copy_errors.append(f\"Source not found: {source_path}\")\n","\n","        except Exception as e:\n","            copy_errors.append(f\"Copy error for {row['sample_id']}: {str(e)}\")\n","\n","print(f\"✓ Apex frame copying completed:\")\n","for split_name, count in copy_stats.items():\n","    print(f\"  {split_name}: {count} images copied\")\n","\n","if copy_errors:\n","    print(f\"  ⚠ Copy errors: {len(copy_errors)} (showing first 3)\")\n","    for error in copy_errors[:3]:\n","        print(f\"    {error}\")\n","\n","# JSON Serialization Helper Function\n","def make_json_serializable(obj):\n","    \"\"\"Recursively convert numpy/pandas types to Python built-ins for json.\"\"\"\n","    # dict -> convert keys/values\n","    if isinstance(obj, dict):\n","        return {make_json_serializable(k): make_json_serializable(v) for k, v in obj.items()}\n","    # list/tuple -> convert items\n","    if isinstance(obj, (list, tuple)):\n","        return [make_json_serializable(x) for x in obj]\n","    # pandas timestamp\n","    if isinstance(obj, pd.Timestamp):\n","        return obj.isoformat()\n","    # numpy / pandas integer types\n","    if isinstance(obj, (np.integer,)):\n","        return int(obj)\n","    # numpy / pandas floating types\n","    if isinstance(obj, (np.floating,)):\n","        return float(obj)\n","    # pandas / numpy booleans\n","    if isinstance(obj, (np.bool_,)):\n","        return bool(obj)\n","    # fallback: return as-is (strings, ints, floats are fine)\n","    return obj\n","\n","# Save split metadata and statistics\n","print(f\"\\n[9] Saving split metadata and statistics...\")\n","\n","# Create metadata for each split\n","metadata_export = {}\n","\n","for split_name, split_data in splits.items():\n","    if not split_data.empty:\n","        # Convert to serializable format\n","        split_metadata = []\n","        for idx, row in split_data.iterrows():\n","            split_metadata.append({\n","                'sample_id': str(row['sample_id']),\n","                'subject': str(row['subject']),\n","                'sequence': str(row['sequence']),\n","                'emotion': str(row['emotion']),\n","                'apex_frame_num': str(row['apex_frame_num']),\n","                'total_frames': int(row['total_frames']),\n","                'onset_frame': int(row['onset_frame']),\n","                'offset_frame': int(row['offset_frame']),\n","                'image_filename': f\"{row['sample_id']}_{row['emotion']}.jpg\"\n","            })\n","\n","        # Convert class distribution to JSON-serializable format\n","        class_dist = {}\n","        for emotion, count in split_data['emotion'].value_counts().items():\n","            class_dist[str(emotion)] = int(count)\n","\n","        metadata_export[split_name] = {\n","            'count': int(len(split_data)),\n","            'class_distribution': class_dist,\n","            'samples': split_metadata\n","        }\n","\n","# Save comprehensive metadata using serialization helper\n","metadata_file = f\"{processed_path}/split_metadata.json\"\n","metadata_serializable = make_json_serializable(metadata_export)\n","\n","with open(metadata_file, 'w') as f:\n","    json.dump(metadata_serializable, f, indent=2)\n","\n","print(f\"✓ Split metadata saved to: split_metadata.json\")\n","\n","# Save processing summary\n","processing_summary = {\n","    'dataset': 'CASME2',\n","    'total_samples': len(inventory_df),\n","    'processing_date': pd.Timestamp.now().isoformat(),\n","    'split_strategy': 'stratified_80_10_10',\n","    'problematic_classes': problematic_classes,\n","    'split_statistics': split_stats,\n","    'copy_statistics': copy_stats,\n","    'processing_errors': len(processing_errors) + len(copy_errors)\n","}\n","\n","# Convert the whole structure to JSON-serializable Python built-ins\n","processing_summary_serializable = make_json_serializable(processing_summary)\n","\n","# Write to file\n","summary_file = f\"{processed_path}/processing_summary.json\"\n","with open(summary_file, 'w') as f:\n","    json.dump(processing_summary_serializable, f, indent=2)\n","\n","print(f\"✓ Processing summary saved to: processing_summary.json\")\n","\n","# Validate processed structure\n","print(f\"\\n[10] Final validation of processed structure...\")\n","\n","validation_results = {}\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_path}/{split_name}\"\n","\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","        validation_results[split_name] = {\n","            'directory_exists': True,\n","            'image_count': len(image_files),\n","            'sample_files': image_files[:3]  # Show first 3 as sample\n","        }\n","    else:\n","        validation_results[split_name] = {\n","            'directory_exists': False,\n","            'image_count': 0,\n","            'sample_files': []\n","        }\n","\n","print(f\"✓ Structure validation:\")\n","for split_name, results in validation_results.items():\n","    status = \"✓\" if results['directory_exists'] and results['image_count'] > 0 else \"⚠\"\n","    print(f\"  {status} {split_name}: {results['image_count']} images\")\n","    if results['sample_files']:\n","        print(f\"    Sample files: {results['sample_files']}\")\n","\n","# Final summary\n","total_processed = sum(copy_stats.values())\n","success_rate = (total_processed / len(inventory_df)) * 100 if inventory_df is not None and len(inventory_df) > 0 else 0\n","\n","print(f\"\\n\" + \"=\" * 75)\n","print(\"PREPROCESSING SUMMARY\")\n","print(\"=\" * 75)\n","print(f\"Processing Status: {'SUCCESS' if success_rate >= 95 else 'PARTIAL'}\")\n","print(f\"Total samples processed: {total_processed}/{len(inventory_df)} ({success_rate:.1f}%)\")\n","print(f\"Split distribution: {len(train_df)} train, {len(val_df)} val, {len(test_df)} test\")\n","print(f\"Class balance handling: {'Applied' if problematic_classes else 'Standard stratification'}\")\n","print(f\"Apex frames extracted: {sum(copy_stats.values())}\")\n","\n","print(f\"\\n✓ Next steps:\")\n","print(f\"  - Processed data ready in: processed_casme2/data_split/\")\n","print(f\"  - Metadata available in: split_metadata.json\")\n","print(f\"  - Proceed to Cell 5: Model baseline implementation\")\n","print(f\"  - Or proceed to Cell 5: LOSO split generation (optional)\")\n","\n","if problematic_classes:\n","    print(f\"\\n⚠ Note: Classes {problematic_classes} have limited samples\")\n","    print(f\"  Consider focal loss for class imbalance mitigation\")\n","\n","print(\"=\" * 75)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"cellView":"form","id":"-_gYkeANVTmH","executionInfo":{"status":"ok","timestamp":1758694591097,"user_tz":-420,"elapsed":7629,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"043453bf-79fb-456e-9f10-6ff740026d0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II DATA PREPROCESSING AND STRATIFIED SPLIT\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Setting up processed dataset structure...\n","Raw data source: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw/CASME2_RAW_selected\n","Processed destination: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/train\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/val\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/test\n","\n","[3] Loading metadata and analyzing class distribution...\n","⚠ ApexFrame column contained non-numeric values, converted to numeric\n","✓ Metadata loaded: 255 records\n","\n","[4] Emotion class analysis for stratification:\n","Total classes: 7\n","  ✓ others: 99 samples (38.8%)\n","  ✓ disgust: 63 samples (24.7%)\n","  ✓ happiness: 32 samples (12.5%)\n","  ✓ repression: 27 samples (10.6%)\n","  ✓ surprise: 25 samples (9.8%)\n","  ✓ sadness: 7 samples (2.7%)\n","  ⚠ fear: 2 samples (0.8%)\n","\n","⚠ Classes with <3 samples: ['fear']\n","  Strategy: Use random assignment for these classes\n","\n","[5] Creating sample inventory for apex frame extraction...\n","✓ Sample inventory created:\n","  Valid samples: 255\n","  Processing errors: 0\n","\n","[6] Performing stratified dataset splitting...\n","\n","  Processing others class (99 samples):\n","    ✓ Split: 79 train, 10 val, 10 test\n","\n","  Processing disgust class (63 samples):\n","    ✓ Split: 50 train, 6 val, 7 test\n","\n","  Processing happiness class (32 samples):\n","    ✓ Split: 25 train, 3 val, 4 test\n","\n","  Processing repression class (27 samples):\n","    ✓ Split: 21 train, 3 val, 3 test\n","\n","  Processing surprise class (25 samples):\n","    ✓ Split: 20 train, 2 val, 3 test\n","\n","  Processing sadness class (7 samples):\n","    ✓ Split: 5 train, 1 val, 1 test\n","\n","  Processing fear class (2 samples):\n","    ⚠ Manual split: 1 train, 1 val, 0 test\n","\n","✓ Final split summary:\n","  Training set: 201 samples\n","  Validation set: 26 samples\n","  Test set: 28 samples\n","  Total: 255 samples\n","\n","[7] Class distribution verification:\n","\n","  TRAIN set distribution:\n","    others: 79 (39.3%)\n","    disgust: 50 (24.9%)\n","    happiness: 25 (12.4%)\n","    repression: 21 (10.4%)\n","    surprise: 20 (10.0%)\n","    sadness: 5 (2.5%)\n","    fear: 1 (0.5%)\n","\n","  VAL set distribution:\n","    others: 10 (38.5%)\n","    disgust: 6 (23.1%)\n","    happiness: 3 (11.5%)\n","    repression: 3 (11.5%)\n","    surprise: 2 (7.7%)\n","    sadness: 1 (3.8%)\n","    fear: 1 (3.8%)\n","\n","  TEST set distribution:\n","    others: 10 (35.7%)\n","    disgust: 7 (25.0%)\n","    happiness: 4 (14.3%)\n","    repression: 3 (10.7%)\n","    surprise: 3 (10.7%)\n","    sadness: 1 (3.6%)\n","\n","[8] Copying apex frames to split directories...\n","✓ Apex frame copying completed:\n","  train: 201 images copied\n","  val: 26 images copied\n","  test: 28 images copied\n","\n","[9] Saving split metadata and statistics...\n","✓ Split metadata saved to: split_metadata.json\n","✓ Processing summary saved to: processing_summary.json\n","\n","[10] Final validation of processed structure...\n","✓ Structure validation:\n","  ✓ train: 201 images\n","    Sample files: ['sub11_EP02_06f_others.jpg', 'sub19_EP06_02f_others.jpg', 'sub18_EP18_01_others.jpg']\n","  ✓ val: 26 images\n","    Sample files: ['sub06_EP10_08_others.jpg', 'sub26_EP07_37_others.jpg', 'sub01_EP03_02_others.jpg']\n","  ✓ test: 28 images\n","    Sample files: ['sub14_EP04_04f_others.jpg', 'sub04_EP13_02f_others.jpg', 'sub01_EP19_01_others.jpg']\n","\n","===========================================================================\n","PREPROCESSING SUMMARY\n","===========================================================================\n","Processing Status: SUCCESS\n","Total samples processed: 255/255 (100.0%)\n","Split distribution: 201 train, 26 val, 28 test\n","Class balance handling: Applied\n","Apex frames extracted: 255\n","\n","✓ Next steps:\n","  - Processed data ready in: processed_casme2/data_split/\n","  - Metadata available in: split_metadata.json\n","  - Proceed to Cell 5: Model baseline implementation\n","  - Or proceed to Cell 5: LOSO split generation (optional)\n","\n","⚠ Note: Classes ['fear'] have limited samples\n","  Consider focal loss for class imbalance mitigation\n","===========================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 5: CASME II Visualization\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Professional visualization setup - clean medical standard\n","plt.style.use('default')\n","plt.rcParams.update({\n","    'font.family': 'DejaVu Sans',\n","    'font.size': 12,\n","    'axes.titlesize': 16,\n","    'axes.labelsize': 14,\n","    'xtick.labelsize': 12,\n","    'ytick.labelsize': 12,\n","    'legend.fontsize': 12,\n","    'figure.titlesize': 18,\n","    'axes.spines.top': False,\n","    'axes.spines.right': False,\n","    'axes.grid': False,\n","    'figure.facecolor': 'white',\n","    'axes.facecolor': 'white'\n","})\n","\n","def convert_to_serializable(obj):\n","    \"\"\"Convert numpy/pandas types to native Python types for JSON serialization\"\"\"\n","    if isinstance(obj, dict):\n","        return {key: convert_to_serializable(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_serializable(item) for item in obj]\n","    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif pd.isna(obj):\n","        return None\n","    else:\n","        return obj\n","\n","# Enhanced medical visualization color palette - consistent across all charts\n","EMOTION_COLORS = {\n","    'others': '#1f77b4',      # Standard blue\n","    'disgust': '#d62728',     # Clear red\n","    'happiness': '#2ca02c',   # Clear green\n","    'repression': '#9467bd',  # Purple\n","    'surprise': '#ff7f0e',    # Orange\n","    'sadness': '#8c564b',     # Brown - distinct from purple\n","    'fear': '#e377c2'         # Pink - highly distinct\n","}\n","\n","# Split colors for comparison\n","SPLIT_COLORS = {\n","    'raw': '#1f77b4',\n","    'train': '#ff7f0e',\n","    'val': '#d62728',\n","    'test': '#2ca02c'\n","}\n","\n","print(\"=\" * 80)\n","print(\"CASME II PROFESSIONAL VISUALIZATION - MULTI-FILE CLEAN GENERATION\")\n","print(\"=\" * 80)\n","\n","print(\"\\n[1] Environment setup and drive mounting...\")\n","drive.mount('/content/drive')\n","print(\"Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","data_split_path = f\"{base_path}/datasets/processed_casme2/data_split\"\n","split_metadata_path = f\"{data_split_path}/split_metadata.json\"\n","visualization_path = f\"{base_path}/datasets/visualization/01_casme2-af\"\n","\n","os.makedirs(visualization_path, exist_ok=True)\n","print(f\"Output directory: {visualization_path}\")\n","\n","print(\"\\n[2] Loading and processing metadata...\")\n","\n","# Load original metadata\n","try:\n","    raw_metadata = pd.read_excel(metadata_path)\n","    print(f\"Raw metadata loaded: {len(raw_metadata)} records\")\n","\n","    if raw_metadata['ApexFrame'].dtype == 'object':\n","        raw_metadata['ApexFrame'] = pd.to_numeric(raw_metadata['ApexFrame'], errors='coerce')\n","        print(\"ApexFrame column normalized to numeric\")\n","\n","except Exception as e:\n","    print(f\"Error loading raw metadata: {str(e)}\")\n","    exit()\n","\n","# Load split metadata\n","try:\n","    with open(split_metadata_path, 'r') as f:\n","        split_metadata = json.load(f)\n","    print(\"Split metadata loaded successfully\")\n","\n","    splits_info = {}\n","    for split_name in ['train', 'val', 'test']:\n","        if split_name in split_metadata:\n","            splits_info[split_name] = split_metadata[split_name]\n","\n","except Exception as e:\n","    print(f\"Error loading split metadata: {str(e)}\")\n","    exit()\n","\n","print(\"\\n[3] File integrity validation...\")\n","\n","total_actual_files = 0\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_path}/{split_name}\"\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","        actual_count = len(image_files)\n","        expected_count = splits_info.get(split_name, {}).get('count', 0)\n","        total_actual_files += actual_count\n","        status = 'PASS' if actual_count == expected_count else 'FAIL'\n","        print(f\"  {split_name.upper()}: {status} ({actual_count}/{expected_count})\")\n","\n","print(f\"Total validated files: {total_actual_files}\")\n","\n","print(\"\\n[4] Preparing visualization data...\")\n","\n","# Raw distribution data - sorted from highest to lowest\n","raw_emotion_dist = raw_metadata['Estimated Emotion'].value_counts().sort_values(ascending=False)\n","raw_total = len(raw_metadata)\n","\n","# Split distribution data\n","split_data = {}\n","for split_name in ['train', 'val', 'test']:\n","    if split_name in splits_info:\n","        split_data[split_name] = splits_info[split_name]['class_distribution']\n","\n","print(\"Data preparation complete\")\n","\n","print(\"\\n[5] Generating File 1: Raw Distribution Bar Chart...\")\n","\n","# FILE 1: Raw Distribution Bar Chart Only\n","fig1, ax1 = plt.subplots(1, 1, figsize=(14, 8))\n","\n","colors_ordered = [EMOTION_COLORS.get(emotion, '#666666') for emotion in raw_emotion_dist.index]\n","bars = ax1.bar(raw_emotion_dist.index, raw_emotion_dist.values,\n","               color=colors_ordered, alpha=0.8, edgecolor='white', linewidth=1.2, width=0.7)\n","\n","ax1.set_title('CASME II Raw Dataset Distribution',\n","              fontsize=18, fontweight='bold', pad=25)\n","ax1.set_xlabel('Emotion Classes', fontsize=16, labelpad=15)\n","ax1.set_ylabel('Sample Count', fontsize=16, labelpad=15)\n","\n","# Add value labels on all bars\n","for bar, value in zip(bars, raw_emotion_dist.values):\n","    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n","             str(value), ha='center', va='bottom', fontsize=13, fontweight='bold')\n","\n","ax1.set_ylim(0, max(raw_emotion_dist.values) * 1.2)\n","ax1.grid(False)\n","\n","plt.tight_layout()\n","file1_path = f\"{visualization_path}/1_raw_distribution_bar.png\"\n","plt.savefig(file1_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"File 1 saved: 1_raw_distribution_bar.png\")\n","\n","print(\"\\n[6] Generating File 2: Raw Distribution Pie Chart...\")\n","\n","# FILE 2: Raw Distribution Pie Chart Only - Larger with better spacing\n","fig2, ax2 = plt.subplots(1, 1, figsize=(12, 12))\n","\n","percentages = [(count/raw_total)*100 for count in raw_emotion_dist.values]\n","pie_colors = [EMOTION_COLORS.get(emotion, '#666666') for emotion in raw_emotion_dist.index]\n","\n","# Create pie chart with better spacing for small percentages\n","wedges, texts, autotexts = ax2.pie(percentages, labels=raw_emotion_dist.index,\n","                                   autopct='%1.1f%%', colors=pie_colors,\n","                                   startangle=90, textprops={'fontsize': 12},\n","                                   pctdistance=0.75, labeldistance=1.15)\n","\n","ax2.set_title('CASME II Raw Dataset Percentage Distribution',\n","              fontsize=18, fontweight='bold', pad=30)\n","\n","# Enhanced handling - only fear percentage gets pulled out, keep text labels normal\n","for i, (autotext, pct, text, emotion) in enumerate(zip(autotexts, percentages, texts, raw_emotion_dist.index)):\n","    autotext.set_color('white')\n","    autotext.set_fontweight('bold')\n","    autotext.set_fontsize(12)  # Increased font size\n","\n","    # Only pull out fear percentage (smallest), keep all text labels in normal position\n","    if emotion == 'fear':\n","        # Move only percentage label further out, not the class name\n","        current_pos = autotext.get_position()\n","        autotext.set_position((current_pos[0] * 1.35, current_pos[1] * 1.35))\n","        autotext.set_color('black')\n","        # Keep text label in normal position - no adjustment needed\n","\n","plt.tight_layout()\n","file2_path = f\"{visualization_path}/2_raw_distribution_pie.png\"\n","plt.savefig(file2_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"File 2 saved: 2_raw_distribution_pie.png\")\n","\n","print(\"\\n[7] Generating File 3: Split Distribution Comparison...\")\n","\n","# FILE 3: Split Distribution Comparison Only\n","fig3, ax_main = plt.subplots(1, 1, figsize=(16, 8))\n","\n","# Main comparison chart - sorted by raw distribution order\n","all_emotions = raw_emotion_dist.index.tolist()\n","raw_counts = [raw_emotion_dist.get(emotion, 0) for emotion in all_emotions]\n","train_counts = [split_data.get('train', {}).get(emotion, 0) for emotion in all_emotions]\n","val_counts = [split_data.get('val', {}).get(emotion, 0) for emotion in all_emotions]\n","test_counts = [split_data.get('test', {}).get(emotion, 0) for emotion in all_emotions]\n","\n","x = np.arange(len(all_emotions))\n","width = 0.2\n","\n","# Create adjacent bars\n","bars1 = ax_main.bar(x - width*1.5, raw_counts, width, label='Raw Dataset (Apex Frame)',\n","                    color=SPLIT_COLORS['raw'], alpha=0.85)\n","bars2 = ax_main.bar(x - width/2, train_counts, width, label='Train Split (Apex Frame)',\n","                    color=SPLIT_COLORS['train'], alpha=0.85)\n","bars3 = ax_main.bar(x + width/2, val_counts, width, label='Validation Split (Apex Frame)',\n","                    color=SPLIT_COLORS['val'], alpha=0.85)\n","bars4 = ax_main.bar(x + width*1.5, test_counts, width, label='Test Split (Apex Frame)',\n","                    color=SPLIT_COLORS['test'], alpha=0.85)\n","\n","ax_main.set_title('CASME II Dataset Split Distribution Comparison',\n","                  fontsize=18, fontweight='bold', pad=25)\n","ax_main.set_xlabel('Emotion Classes (Sorted by Frequency)', fontsize=16, labelpad=20)\n","ax_main.set_ylabel('Image Count', fontsize=16, labelpad=20)\n","ax_main.set_xticks(x)\n","ax_main.set_xticklabels(all_emotions, rotation=0)\n","ax_main.legend(loc='upper right', fontsize=13)\n","ax_main.grid(False)\n","\n","# Add all value labels\n","all_bars_data = [(bars1, raw_counts), (bars2, train_counts), (bars3, val_counts), (bars4, test_counts)]\n","for bars, values in all_bars_data:\n","    for bar, value in zip(bars, values):\n","        if value > 0:\n","            ax_main.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n","                        str(value), ha='center', va='bottom', fontsize=9,\n","                        fontweight='bold')\n","\n","plt.tight_layout()\n","file3_path = f\"{visualization_path}/3_split_distribution_comparison.png\"\n","plt.savefig(file3_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"File 3 saved: 3_split_distribution_comparison.png\")\n","\n","print(\"\\n[8] Generating File 4: Dataset Split Ratios...\")\n","\n","# FILE 4: Dataset Split Ratios - Large pie chart\n","fig4, ax_ratio = plt.subplots(1, 1, figsize=(10, 10))\n","\n","split_totals = [sum(train_counts), sum(val_counts), sum(test_counts)]\n","split_labels = ['Train (80%)', 'Validation (20%)', 'Test (Holdout)']\n","split_colors_pie = [SPLIT_COLORS['train'], SPLIT_COLORS['val'], SPLIT_COLORS['test']]\n","\n","wedges, texts, autotexts = ax_ratio.pie(split_totals, labels=split_labels,\n","                                        autopct=lambda pct: f'{pct:.1f}%\\n({int(pct/100*sum(split_totals))} samples)',\n","                                        colors=split_colors_pie, startangle=90,\n","                                        textprops={'fontsize': 13},\n","                                        labeldistance=1.1, pctdistance=0.8)\n","\n","ax_ratio.set_title('CASME II Final Dataset Split Ratios',\n","                   fontsize=18, fontweight='bold', pad=30)\n","\n","# Enhanced autotext for better readability\n","for autotext in autotexts:\n","    autotext.set_color('white')\n","    autotext.set_fontweight('bold')\n","    autotext.set_fontsize(12)\n","\n","plt.tight_layout()\n","file4_path = f\"{visualization_path}/4_dataset_split_ratios.png\"\n","plt.savefig(file4_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"File 4 saved: 4_dataset_split_ratios.png\")\n","\n","print(\"\\n[9] Generating File 5: Statistical Analysis Table...\")\n","\n","# FILE 5: Clean Statistical Table Only\n","fig5 = plt.figure(figsize=(16, 8))\n","ax_table = fig5.add_subplot(1, 1, 1)\n","ax_table.axis('off')\n","\n","# Prepare table data with proper calculations\n","table_data = []\n","total_raw_count = 0\n","total_train_count = 0\n","total_val_count = 0\n","total_test_count = 0\n","\n","for emotion in all_emotions:\n","    raw_count = raw_emotion_dist.get(emotion, 0)\n","    train_count = split_data.get('train', {}).get(emotion, 0)\n","    val_count = split_data.get('val', {}).get(emotion, 0)\n","    test_count = split_data.get('test', {}).get(emotion, 0)\n","    split_total = train_count + val_count + test_count\n","\n","    raw_pct = f\"{(raw_count/raw_total)*100:.1f}%\" if raw_total > 0 else \"0%\"\n","    preservation_rate = f\"{(split_total/raw_count)*100:.1f}%\" if raw_count > 0 else \"0%\"\n","\n","    max_raw = raw_emotion_dist.max()\n","    imbalance_ratio = f\"{max_raw/raw_count:.1f}:1\" if raw_count > 0 else \"∞:1\"\n","\n","    table_data.append([\n","        emotion.title(),\n","        raw_count,\n","        raw_pct,\n","        train_count,\n","        val_count,\n","        test_count,\n","        split_total,\n","        preservation_rate,\n","        imbalance_ratio\n","    ])\n","\n","    total_raw_count += raw_count\n","    total_train_count += train_count\n","    total_val_count += val_count\n","    total_test_count += test_count\n","\n","# Add total row\n","total_split_count = total_train_count + total_val_count + total_test_count\n","table_data.append([\n","    'TOTAL',\n","    total_raw_count,\n","    '100.0%',\n","    total_train_count,\n","    total_val_count,\n","    total_test_count,\n","    total_split_count,\n","    f\"{(total_split_count/total_raw_count)*100:.1f}%\",\n","    '1.0:1'\n","])\n","\n","# Convert to display format\n","table_display_data = []\n","for row in table_data:\n","    display_row = [\n","        row[0],  # emotion name\n","        f\"{row[1]:,}\",  # raw count formatted\n","        row[2],  # raw percentage\n","        f\"{row[3]:,}\",  # train count formatted\n","        f\"{row[4]:,}\",  # val count formatted\n","        f\"{row[5]:,}\",  # test count formatted\n","        f\"{row[6]:,}\",  # split total formatted\n","        row[7],  # preservation rate\n","        row[8]   # imbalance ratio\n","    ]\n","    table_display_data.append(display_row)\n","\n","# Create table\n","table = ax_table.table(\n","    cellText=table_display_data,\n","    colLabels=['Emotion Class', 'Raw Count', 'Raw %', 'Train', 'Val', 'Test', 'Split Total', 'Preserved', 'Imbalance'],\n","    cellLoc='center',\n","    loc='center',\n","    colWidths=[0.15, 0.10, 0.08, 0.08, 0.08, 0.08, 0.10, 0.10, 0.10]\n",")\n","\n","table.auto_set_font_size(False)\n","table.set_fontsize(12)\n","table.scale(1, 2.8)\n","\n","# Professional table styling\n","num_rows = len(table_display_data)\n","for i in range(num_rows + 1):\n","    for j in range(9):\n","        cell = table[(i, j)]\n","        if i == 0:  # Header\n","            cell.set_facecolor('#1f77b4')\n","            cell.set_text_props(weight='bold', color='white')\n","        elif i == num_rows:  # Total row\n","            cell.set_facecolor('#f0f0f0')\n","            cell.set_text_props(weight='bold')\n","        else:\n","            emotion = table_display_data[i-1][0].lower()\n","            if emotion in ['fear', 'sadness']:\n","                cell.set_facecolor('#ffe6e6')\n","            else:\n","                cell.set_facecolor('#ffffff')\n","\n","# Single clean title\n","ax_table.set_title('CASME II Dataset Statistical Analysis Summary',\n","                   fontsize=18, fontweight='bold', pad=40)\n","\n","plt.tight_layout()\n","file5_path = f\"{visualization_path}/5_statistical_analysis_table.png\"\n","plt.savefig(file5_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"File 5 saved: 5_statistical_analysis_table.png\")\n","\n","print(\"\\n[10] Generating comprehensive JSON metadata...\")\n","\n","# Generate metadata\n","analysis_metadata = {\n","    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n","    'dataset_info': {\n","        'name': 'CASME II Micro-Expression Dataset',\n","        'total_subjects': 26,\n","        'total_original_samples': int(raw_total),\n","        'emotion_classes': len(raw_emotion_dist),\n","        'severe_imbalance_ratio': f\"{raw_emotion_dist.max()}:{raw_emotion_dist.min()}\"\n","    },\n","    'raw_distribution': convert_to_serializable({\n","        'emotion_counts': {k: int(v) for k, v in raw_emotion_dist.items()},\n","        'emotion_percentages': {k: round((v/raw_total)*100, 2) for k, v in raw_emotion_dist.items()}\n","    }),\n","    'split_distribution': convert_to_serializable({\n","        'train': {\n","            'total_samples': sum(split_data.get('train', {}).values()),\n","            'class_distribution': split_data.get('train', {})\n","        },\n","        'validation': {\n","            'total_samples': sum(split_data.get('val', {}).values()),\n","            'class_distribution': split_data.get('val', {})\n","        },\n","        'test': {\n","            'total_samples': sum(split_data.get('test', {}).values()),\n","            'class_distribution': split_data.get('test', {})\n","        }\n","    }),\n","    'visualization_files': {\n","        'raw_distribution_bar': '1_raw_distribution_bar.png',\n","        'raw_distribution_pie': '2_raw_distribution_pie.png',\n","        'split_comparison': '3_split_distribution_comparison.png',\n","        'split_ratios': '4_dataset_split_ratios.png',\n","        'statistical_table': '5_statistical_analysis_table.png'\n","    },\n","    'color_scheme': {\n","        'emotion_psychology_mapping': EMOTION_COLORS,\n","        'split_comparison_colors': SPLIT_COLORS,\n","        'design_principle': 'Medical visualization with consistent color psychology'\n","    }\n","}\n","\n","metadata_file = f\"{visualization_path}/professional_analysis_metadata.json\"\n","with open(metadata_file, 'w') as f:\n","    json.dump(analysis_metadata, f, indent=2)\n","\n","print(f\"Comprehensive metadata saved: professional_analysis_metadata.json\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"MULTI-FILE PROFESSIONAL VISUALIZATION COMPLETE\")\n","print(\"=\" * 80)\n","print(f\"Status: SUCCESS - 5 separate publication-ready files generated\")\n","print(f\"Total samples validated: {total_actual_files} files\")\n","print(f\"Output location: {visualization_path}\")\n","print(\"\\nGenerated files:\")\n","print(\"  • 1_raw_distribution_bar.png - Clean bar chart only\")\n","print(\"  • 2_raw_distribution_pie.png - Large pie chart with proper spacing\")\n","print(\"  • 3_split_distribution_comparison.png - Split comparison chart\")\n","print(\"  • 4_dataset_split_ratios.png - Large ratio pie chart\")\n","print(\"  • 5_statistical_analysis_table.png - Clean table without extras\")\n","print(\"  • professional_analysis_metadata.json - Comprehensive metadata\")\n","print(\"\\nKey improvements:\")\n","print(\"  • Consistent color scheme across all charts\")\n","print(\"  • Proper spacing for small percentages in pie charts\")\n","print(\"  • Separated files for optimal sizing\")\n","print(\"  • Clean single titles without overlap\")\n","print(\"  • Focused content without extra text boxes\")\n","print(\"=\" * 80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"BKXCnreBaRmc","executionInfo":{"status":"ok","timestamp":1759154298804,"user_tz":-420,"elapsed":8448,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"42b45f22-d017-44e0-8d9a-5c70b7672b62","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CASME II PROFESSIONAL VISUALIZATION - MULTI-FILE CLEAN GENERATION\n","================================================================================\n","\n","[1] Environment setup and drive mounting...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive mounted successfully\n","Output directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/01_casme2-af\n","\n","[2] Loading and processing metadata...\n","Raw metadata loaded: 255 records\n","ApexFrame column normalized to numeric\n","Split metadata loaded successfully\n","\n","[3] File integrity validation...\n","  TRAIN: PASS (201/201)\n","  VAL: PASS (26/26)\n","  TEST: PASS (28/28)\n","Total validated files: 255\n","\n","[4] Preparing visualization data...\n","Data preparation complete\n","\n","[5] Generating File 1: Raw Distribution Bar Chart...\n","File 1 saved: 1_raw_distribution_bar.png\n","\n","[6] Generating File 2: Raw Distribution Pie Chart...\n","File 2 saved: 2_raw_distribution_pie.png\n","\n","[7] Generating File 3: Split Distribution Comparison...\n","File 3 saved: 3_split_distribution_comparison.png\n","\n","[8] Generating File 4: Dataset Split Ratios...\n","File 4 saved: 4_dataset_split_ratios.png\n","\n","[9] Generating File 5: Statistical Analysis Table...\n","File 5 saved: 5_statistical_analysis_table.png\n","\n","[10] Generating comprehensive JSON metadata...\n","Comprehensive metadata saved: professional_analysis_metadata.json\n","\n","================================================================================\n","MULTI-FILE PROFESSIONAL VISUALIZATION COMPLETE\n","================================================================================\n","Status: SUCCESS - 5 separate publication-ready files generated\n","Total samples validated: 255 files\n","Output location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/01_casme2-af\n","\n","Generated files:\n","  • 1_raw_distribution_bar.png - Clean bar chart only\n","  • 2_raw_distribution_pie.png - Large pie chart with proper spacing\n","  • 3_split_distribution_comparison.png - Split comparison chart\n","  • 4_dataset_split_ratios.png - Large ratio pie chart\n","  • 5_statistical_analysis_table.png - Clean table without extras\n","  • professional_analysis_metadata.json - Comprehensive metadata\n","\n","Key improvements:\n","  • Consistent color scheme across all charts\n","  • Proper spacing for small percentages in pie charts\n","  • Separated files for optimal sizing\n","  • Clean single titles without overlap\n","  • Focused content without extra text boxes\n","================================================================================\n"]}]}]}