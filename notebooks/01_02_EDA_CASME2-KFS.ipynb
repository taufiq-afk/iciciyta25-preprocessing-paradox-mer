{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOY5cXRxaop6/Iqie9nDP6q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"cellView":"form","id":"odHaIqcvwPTr","executionInfo":{"status":"ok","timestamp":1759139167760,"user_tz":-420,"elapsed":3315,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"7a5867c3-ff10-48cb-bb4b-ec190ec7887a"},"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II KEY FRAMES DATASET VERIFICATION - PHASE 2\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Loading Phase 1 split metadata for consistency...\n","Phase 1 metadata: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/split_metadata.json\n","✓ Phase 1 metadata loaded: 255 total samples\n","  Train: 201 samples\n","  Val: 26 samples\n","  Test: 28 samples\n","\n","[3] Loading CASME II metadata...\n","⚠ ApexFrame column contained non-numeric values, converted to numeric\n","✓ Metadata loaded: 255 records\n","  Columns: Subject, Filename, OnsetFrame, ApexFrame, OffsetFrame, Estimated Emotion\n","\n","[4] Creating comprehensive sample mapping from metadata...\n","✓ Sample mapping created: 255 samples indexed\n","\n","[5] Verifying key frames availability (onset, apex, offset)...\n","Strategy: Use nearest frame if exact frame not available\n","\n","  Verifying TRAIN set (201 samples)...\n","  ✓ TRAIN verification completed\n","\n","  Verifying VAL set (26 samples)...\n","  ✓ VAL verification completed\n","\n","  Verifying TEST set (28 samples)...\n","  ✓ TEST verification completed\n","\n","[6] Frame Availability Statistics:\n","===========================================================================\n","\n","Sample Status Summary:\n","  Total samples verified: 255\n","  ✓ Perfect (all exact): 254 (99.6%)\n","  ⚠ Fallback needed: 1 (0.4%)\n","  ✗ Problematic (missing): 0 (0.0%)\n","\n","Frame-wise Availability:\n","  ONSET frame:\n","    Exact match: 255 (100.0%)\n","    Fallback used: 0 (0.0%)\n","    Missing: 0 (0.0%)\n","  APEX frame:\n","    Exact match: 255 (100.0%)\n","    Fallback used: 0 (0.0%)\n","    Missing: 0 (0.0%)\n","  OFFSET frame:\n","    Exact match: 254 (99.6%)\n","    Fallback used: 1 (0.4%)\n","    Missing: 0 (0.0%)\n","\n","[8] Exporting verification results...\n","✓ Verification results saved to: key_frames_verification.json\n","\n","[9] Phase 2 Dataset Readiness Assessment:\n","===========================================================================\n","Readiness Status: READY\n","Readiness Score: 100.0%\n","Assessment: All samples have complete key frames (exact or fallback)\n","\n","✓ Expected Phase 2 dataset size:\n","  Train: 201 samples × 3 frames = 603 images\n","  Val: 26 samples × 3 frames = 78 images\n","  Test: 28 samples × 3 frames = 84 images\n","  Total: 255 samples × 3 frames = 765 images\n","\n","✓ Next steps:\n","  - Review verification results in key_frames_verification.json\n","  - Proceed to Cell 2: Key frames extraction and dataset preparation\n","  - Fallback strategy will be applied automatically for missing frames\n","===========================================================================\n"]}],"source":["# @title Cell 1: CASME II Key Frames Availability Verification\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","from google.colab import drive\n","from pathlib import Path\n","from collections import defaultdict\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II KEY FRAMES DATASET VERIFICATION - PHASE 2\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw/CASME2_RAW_selected\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","phase1_split_metadata = f\"{base_path}/datasets/processed_casme2/data_split/split_metadata.json\"\n","\n","print(f\"\\n[2] Loading Phase 1 split metadata for consistency...\")\n","print(f\"Phase 1 metadata: {phase1_split_metadata}\")\n","\n","try:\n","    with open(phase1_split_metadata, 'r') as f:\n","        phase1_splits = json.load(f)\n","\n","    total_phase1_samples = sum(split['count'] for split in phase1_splits.values())\n","    print(f\"✓ Phase 1 metadata loaded: {total_phase1_samples} total samples\")\n","    print(f\"  Train: {phase1_splits['train']['count']} samples\")\n","    print(f\"  Val: {phase1_splits['val']['count']} samples\")\n","    print(f\"  Test: {phase1_splits['test']['count']} samples\")\n","except Exception as e:\n","    print(f\"✗ Error loading Phase 1 metadata: {str(e)}\")\n","    exit()\n","\n","# Load CASME II metadata\n","print(f\"\\n[3] Loading CASME II metadata...\")\n","\n","try:\n","    df = pd.read_excel(metadata_path)\n","\n","    # Clean ApexFrame column if needed\n","    if df['ApexFrame'].dtype == 'object':\n","        df['ApexFrame'] = pd.to_numeric(df['ApexFrame'], errors='coerce')\n","        print(f\"⚠ ApexFrame column contained non-numeric values, converted to numeric\")\n","\n","    print(f\"✓ Metadata loaded: {len(df)} records\")\n","    print(f\"  Columns: Subject, Filename, OnsetFrame, ApexFrame, OffsetFrame, Estimated Emotion\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","# Create comprehensive sample mapping\n","print(f\"\\n[4] Creating comprehensive sample mapping from metadata...\")\n","\n","metadata_map = {}\n","for idx, row in df.iterrows():\n","    subject = f\"sub{str(row['Subject']).zfill(2)}\"\n","    sequence = row['Filename']\n","    sample_id = f\"{subject}_{sequence}\"\n","\n","    metadata_map[sample_id] = {\n","        'subject': subject,\n","        'sequence': sequence,\n","        'emotion': row['Estimated Emotion'],\n","        'onset_frame': int(row['OnsetFrame']),\n","        'apex_frame': int(row['ApexFrame']) if pd.notna(row['ApexFrame']) else None,\n","        'offset_frame': int(row['OffsetFrame'])\n","    }\n","\n","print(f\"✓ Sample mapping created: {len(metadata_map)} samples indexed\")\n","\n","# Frame availability verification function\n","def find_nearest_frame(sequence_path, target_frame, frame_type):\n","    \"\"\"\n","    Find the nearest available frame to target frame.\n","    Returns tuple: (actual_frame_path, frame_number, status)\n","    status: 'exact', 'fallback_before', 'fallback_after', 'missing'\n","    \"\"\"\n","    if not os.path.exists(sequence_path):\n","        return None, None, 'missing'\n","\n","    # List all image files\n","    image_files = sorted([f for f in os.listdir(sequence_path)\n","                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n","\n","    if not image_files:\n","        return None, None, 'missing'\n","\n","    # Extract frame numbers\n","    frame_numbers = []\n","    frame_map = {}\n","    for img_file in image_files:\n","        try:\n","            # Extract number from filename (e.g., img46.jpg -> 46)\n","            frame_num = int(''.join(filter(str.isdigit, img_file.split('.')[0])))\n","            frame_numbers.append(frame_num)\n","            frame_map[frame_num] = os.path.join(sequence_path, img_file)\n","        except ValueError:\n","            continue\n","\n","    if not frame_numbers:\n","        return None, None, 'missing'\n","\n","    frame_numbers.sort()\n","\n","    # Check exact match\n","    if target_frame in frame_map:\n","        return frame_map[target_frame], target_frame, 'exact'\n","\n","    # Find nearest frame\n","    # Try frames before target\n","    before_frames = [f for f in frame_numbers if f < target_frame]\n","    # Try frames after target\n","    after_frames = [f for f in frame_numbers if f > target_frame]\n","\n","    # Prefer closest frame (before or after)\n","    candidates = []\n","    if before_frames:\n","        closest_before = max(before_frames)\n","        candidates.append((closest_before, abs(target_frame - closest_before), 'fallback_before'))\n","    if after_frames:\n","        closest_after = min(after_frames)\n","        candidates.append((closest_after, abs(target_frame - closest_after), 'fallback_after'))\n","\n","    if candidates:\n","        # Choose the closest one\n","        candidates.sort(key=lambda x: x[1])\n","        best_frame, distance, status = candidates[0]\n","        return frame_map[best_frame], best_frame, status\n","\n","    # If no suitable frame found, return None\n","    return None, None, 'missing'\n","\n","# Verify frame availability for all Phase 1 samples\n","print(f\"\\n[5] Verifying key frames availability (onset, apex, offset)...\")\n","print(f\"Strategy: Use nearest frame if exact frame not available\")\n","\n","verification_results = {\n","    'train': [],\n","    'val': [],\n","    'test': []\n","}\n","\n","statistics = {\n","    'total_samples': 0,\n","    'perfect_samples': 0,  # All 3 frames exact match\n","    'fallback_samples': 0,  # At least 1 frame needs fallback\n","    'problematic_samples': 0,  # Missing frames even with fallback\n","    'frame_statistics': {\n","        'onset': {'exact': 0, 'fallback': 0, 'missing': 0},\n","        'apex': {'exact': 0, 'fallback': 0, 'missing': 0},\n","        'offset': {'exact': 0, 'fallback': 0, 'missing': 0}\n","    }\n","}\n","\n","for split_name, split_data in phase1_splits.items():\n","    print(f\"\\n  Verifying {split_name.upper()} set ({split_data['count']} samples)...\")\n","\n","    for sample in split_data['samples']:\n","        sample_id = sample['sample_id']\n","\n","        # Skip if sample not in metadata\n","        if sample_id not in metadata_map:\n","            print(f\"  ✗ Sample {sample_id} not found in metadata\")\n","            continue\n","\n","        meta = metadata_map[sample_id]\n","        sequence_path = os.path.join(raw_path, meta['subject'], meta['sequence'])\n","\n","        # Verify each frame type\n","        onset_path, onset_num, onset_status = find_nearest_frame(\n","            sequence_path, meta['onset_frame'], 'onset'\n","        )\n","\n","        apex_frame = meta['apex_frame'] if meta['apex_frame'] is not None else meta['onset_frame']\n","        apex_path, apex_num, apex_status = find_nearest_frame(\n","            sequence_path, apex_frame, 'apex'\n","        )\n","\n","        offset_path, offset_num, offset_status = find_nearest_frame(\n","            sequence_path, meta['offset_frame'], 'offset'\n","        )\n","\n","        # Normalize status for statistics (fallback_before/fallback_after -> fallback)\n","        onset_stat = 'fallback' if 'fallback' in onset_status else onset_status\n","        apex_stat = 'fallback' if 'fallback' in apex_status else apex_status\n","        offset_stat = 'fallback' if 'fallback' in offset_status else offset_status\n","\n","        # Update statistics\n","        statistics['total_samples'] += 1\n","        statistics['frame_statistics']['onset'][onset_stat] += 1\n","        statistics['frame_statistics']['apex'][apex_stat] += 1\n","        statistics['frame_statistics']['offset'][offset_stat] += 1\n","\n","        # Determine sample status\n","        all_exact = (onset_status == 'exact' and apex_status == 'exact' and offset_status == 'exact')\n","        has_fallback = ('fallback' in onset_status or 'fallback' in apex_status or 'fallback' in offset_status)\n","        has_missing = (onset_status == 'missing' or apex_status == 'missing' or offset_status == 'missing')\n","\n","        if all_exact:\n","            statistics['perfect_samples'] += 1\n","        elif has_fallback and not has_missing:\n","            statistics['fallback_samples'] += 1\n","        elif has_missing:\n","            statistics['problematic_samples'] += 1\n","\n","        # Store verification result\n","        verification_results[split_name].append({\n","            'sample_id': sample_id,\n","            'subject': meta['subject'],\n","            'sequence': meta['sequence'],\n","            'emotion': meta['emotion'],\n","            'frames': {\n","                'onset': {\n","                    'target_frame': meta['onset_frame'],\n","                    'actual_frame': onset_num,\n","                    'path': onset_path,\n","                    'status': onset_status\n","                },\n","                'apex': {\n","                    'target_frame': apex_frame,\n","                    'actual_frame': apex_num,\n","                    'path': apex_path,\n","                    'status': apex_status\n","                },\n","                'offset': {\n","                    'target_frame': meta['offset_frame'],\n","                    'actual_frame': offset_num,\n","                    'path': offset_path,\n","                    'status': offset_status\n","                }\n","            },\n","            'sample_status': 'perfect' if all_exact else ('fallback' if has_fallback else 'problematic')\n","        })\n","\n","    print(f\"  ✓ {split_name.upper()} verification completed\")\n","\n","# Display comprehensive statistics\n","print(f\"\\n[6] Frame Availability Statistics:\")\n","print(f\"=\" * 75)\n","\n","print(f\"\\nSample Status Summary:\")\n","print(f\"  Total samples verified: {statistics['total_samples']}\")\n","print(f\"  ✓ Perfect (all exact): {statistics['perfect_samples']} ({statistics['perfect_samples']/statistics['total_samples']*100:.1f}%)\")\n","print(f\"  ⚠ Fallback needed: {statistics['fallback_samples']} ({statistics['fallback_samples']/statistics['total_samples']*100:.1f}%)\")\n","print(f\"  ✗ Problematic (missing): {statistics['problematic_samples']} ({statistics['problematic_samples']/statistics['total_samples']*100:.1f}%)\")\n","\n","print(f\"\\nFrame-wise Availability:\")\n","for frame_type, stats in statistics['frame_statistics'].items():\n","    total = sum(stats.values())\n","    print(f\"  {frame_type.upper()} frame:\")\n","    print(f\"    Exact match: {stats['exact']} ({stats['exact']/total*100:.1f}%)\")\n","    print(f\"    Fallback used: {stats['fallback']} ({stats['fallback']/total*100:.1f}%)\")\n","    print(f\"    Missing: {stats['missing']} ({stats['missing']/total*100:.1f}%)\")\n","\n","# Show sample problematic cases\n","if statistics['problematic_samples'] > 0:\n","    print(f\"\\n[7] Problematic Samples Analysis:\")\n","    problematic_found = 0\n","    for split_name, samples in verification_results.items():\n","        for sample in samples:\n","            if sample['sample_status'] == 'problematic':\n","                if problematic_found < 5:  # Show first 5\n","                    print(f\"  Sample: {sample['sample_id']}\")\n","                    print(f\"    Onset: {sample['frames']['onset']['status']}\")\n","                    print(f\"    Apex: {sample['frames']['apex']['status']}\")\n","                    print(f\"    Offset: {sample['frames']['offset']['status']}\")\n","                    problematic_found += 1\n","\n","    if statistics['problematic_samples'] > 5:\n","        print(f\"  ... and {statistics['problematic_samples'] - 5} more problematic samples\")\n","\n","# Export verification results\n","print(f\"\\n[8] Exporting verification results...\")\n","\n","output_path = f\"{base_path}/datasets/processed_casme2\"\n","verification_file = f\"{output_path}/key_frames_verification.json\"\n","\n","verification_export = {\n","    'verification_date': pd.Timestamp.now().isoformat(),\n","    'phase': 'Phase 2 - Key Frames Dataset',\n","    'strategy': 'nearest_frame_fallback',\n","    'statistics': statistics,\n","    'split_results': verification_results\n","}\n","\n","with open(verification_file, 'w') as f:\n","    json.dump(verification_export, f, indent=2)\n","\n","print(f\"✓ Verification results saved to: key_frames_verification.json\")\n","\n","# Final readiness assessment\n","print(f\"\\n[9] Phase 2 Dataset Readiness Assessment:\")\n","print(f\"=\" * 75)\n","\n","readiness_score = (statistics['perfect_samples'] + statistics['fallback_samples']) / statistics['total_samples'] * 100\n","\n","if readiness_score == 100:\n","    status = \"READY\"\n","    message = \"All samples have complete key frames (exact or fallback)\"\n","elif readiness_score >= 95:\n","    status = \"READY WITH CAUTION\"\n","    message = f\"{statistics['problematic_samples']} samples may need manual review\"\n","else:\n","    status = \"NEEDS ATTENTION\"\n","    message = f\"{statistics['problematic_samples']} problematic samples require investigation\"\n","\n","print(f\"Readiness Status: {status}\")\n","print(f\"Readiness Score: {readiness_score:.1f}%\")\n","print(f\"Assessment: {message}\")\n","\n","print(f\"\\n✓ Expected Phase 2 dataset size:\")\n","print(f\"  Train: {phase1_splits['train']['count']} samples × 3 frames = {phase1_splits['train']['count']*3} images\")\n","print(f\"  Val: {phase1_splits['val']['count']} samples × 3 frames = {phase1_splits['val']['count']*3} images\")\n","print(f\"  Test: {phase1_splits['test']['count']} samples × 3 frames = {phase1_splits['test']['count']*3} images\")\n","print(f\"  Total: {statistics['total_samples']} samples × 3 frames = {statistics['total_samples']*3} images\")\n","\n","print(f\"\\n✓ Next steps:\")\n","print(f\"  - Review verification results in key_frames_verification.json\")\n","print(f\"  - Proceed to Cell 2: Key frames extraction and dataset preparation\")\n","print(f\"  - Fallback strategy will be applied automatically for missing frames\")\n","\n","print(\"=\" * 75)"]},{"cell_type":"code","source":["# @title Cell 2: CASME II Key Frames Extraction and Dataset Preparation\n","\n","import os\n","import shutil\n","import json\n","import pandas as pd\n","from google.colab import drive\n","from pathlib import Path\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II KEY FRAMES DATASET PREPARATION - PHASE 2\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","processed_path = f\"{base_path}/datasets/processed_casme2\"\n","verification_file = f\"{processed_path}/key_frames_verification.json\"\n","\n","print(f\"\\n[2] Setting up Phase 2 directory structure...\")\n","print(f\"Target: data_split_v2 (key frames: onset + apex + offset)\")\n","\n","# Create data_split_v2 directory structure\n","data_split_v2_path = f\"{processed_path}/data_split_v2\"\n","directories = [\n","    f\"{data_split_v2_path}/train\",\n","    f\"{data_split_v2_path}/val\",\n","    f\"{data_split_v2_path}/test\"\n","]\n","\n","for directory in directories:\n","    os.makedirs(directory, exist_ok=True)\n","    print(f\"✓ Created directory: {directory}\")\n","\n","# Load verification results\n","print(f\"\\n[3] Loading verification results from Cell 1...\")\n","\n","try:\n","    with open(verification_file, 'r') as f:\n","        verification_data = json.load(f)\n","\n","    print(f\"✓ Verification data loaded\")\n","    print(f\"  Strategy: {verification_data['strategy']}\")\n","    print(f\"  Total samples: {verification_data['statistics']['total_samples']}\")\n","    print(f\"  Perfect samples: {verification_data['statistics']['perfect_samples']}\")\n","    print(f\"  Fallback samples: {verification_data['statistics']['fallback_samples']}\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading verification data: {str(e)}\")\n","    exit()\n","\n","# Extract key frames and copy to split directories\n","print(f\"\\n[4] Extracting and copying key frames to data_split_v2...\")\n","\n","copy_stats = {\n","    'train': {'onset': 0, 'apex': 0, 'offset': 0},\n","    'val': {'onset': 0, 'apex': 0, 'offset': 0},\n","    'test': {'onset': 0, 'apex': 0, 'offset': 0}\n","}\n","\n","copy_errors = []\n","metadata_v2 = {\n","    'train': {'count': 0, 'samples': [], 'class_distribution': {}},\n","    'val': {'count': 0, 'samples': [], 'class_distribution': {}},\n","    'test': {'count': 0, 'samples': [], 'class_distribution': {}}\n","}\n","\n","frame_types = ['onset', 'apex', 'offset']\n","\n","for split_name, samples in verification_data['split_results'].items():\n","    print(f\"\\n  Processing {split_name.upper()} set ({len(samples)} samples × 3 frames)...\")\n","\n","    split_dir = f\"{data_split_v2_path}/{split_name}\"\n","\n","    for sample in samples:\n","        sample_id = sample['sample_id']\n","        emotion = sample['emotion']\n","        subject = sample['subject']\n","        sequence = sample['sequence']\n","\n","        # Process each frame type\n","        for frame_type in frame_types:\n","            frame_info = sample['frames'][frame_type]\n","            source_path = frame_info['path']\n","\n","            if source_path is None:\n","                copy_errors.append(f\"Missing {frame_type} frame for {sample_id}\")\n","                continue\n","\n","            # Create destination filename: {sample_id}_{frame_type}_{emotion}.jpg\n","            dest_filename = f\"{sample_id}_{frame_type}_{emotion}.jpg\"\n","            dest_path = os.path.join(split_dir, dest_filename)\n","\n","            try:\n","                if os.path.exists(source_path):\n","                    shutil.copy2(source_path, dest_path)\n","                    copy_stats[split_name][frame_type] += 1\n","\n","                    # Add to metadata\n","                    metadata_v2[split_name]['samples'].append({\n","                        'sample_id': f\"{sample_id}_{frame_type}\",\n","                        'original_sample_id': sample_id,\n","                        'frame_type': frame_type,\n","                        'subject': subject,\n","                        'sequence': sequence,\n","                        'emotion': emotion,\n","                        'image_filename': dest_filename,\n","                        'target_frame': frame_info['target_frame'],\n","                        'actual_frame': frame_info['actual_frame'],\n","                        'frame_status': frame_info['status']\n","                    })\n","\n","                else:\n","                    copy_errors.append(f\"Source not found: {source_path}\")\n","\n","            except Exception as e:\n","                copy_errors.append(f\"Copy error for {sample_id} {frame_type}: {str(e)}\")\n","\n","    # Update split statistics\n","    total_frames = sum(copy_stats[split_name].values())\n","    metadata_v2[split_name]['count'] = total_frames\n","\n","    print(f\"  ✓ {split_name.upper()} extraction completed:\")\n","    print(f\"    Onset frames: {copy_stats[split_name]['onset']}\")\n","    print(f\"    Apex frames: {copy_stats[split_name]['apex']}\")\n","    print(f\"    Offset frames: {copy_stats[split_name]['offset']}\")\n","    print(f\"    Total: {total_frames} images\")\n","\n","# Calculate class distribution per split\n","print(f\"\\n[5] Calculating class distribution for each split...\")\n","\n","for split_name in ['train', 'val', 'test']:\n","    emotion_counts = {}\n","    for sample in metadata_v2[split_name]['samples']:\n","        emotion = sample['emotion']\n","        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n","\n","    metadata_v2[split_name]['class_distribution'] = emotion_counts\n","\n","    print(f\"\\n  {split_name.upper()} set distribution ({metadata_v2[split_name]['count']} images):\")\n","    for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):\n","        percentage = (count / metadata_v2[split_name]['count']) * 100\n","        print(f\"    {emotion}: {count} images ({percentage:.1f}%)\")\n","\n","# Display copy errors if any\n","if copy_errors:\n","    print(f\"\\n[6] Copy Errors Summary:\")\n","    print(f\"  Total errors: {len(copy_errors)}\")\n","    if len(copy_errors) <= 5:\n","        for error in copy_errors:\n","            print(f\"    {error}\")\n","    else:\n","        for error in copy_errors[:5]:\n","            print(f\"    {error}\")\n","        print(f\"    ... and {len(copy_errors) - 5} more errors\")\n","\n","# Save enhanced metadata\n","print(f\"\\n[7] Saving enhanced metadata with frame type tracking...\")\n","\n","metadata_file_v2 = f\"{data_split_v2_path}/split_metadata_v2.json\"\n","\n","metadata_export = {\n","    'dataset': 'CASME2_KeyFrames',\n","    'phase': 'Phase 2',\n","    'frame_types': ['onset', 'apex', 'offset'],\n","    'expansion_factor': 3,\n","    'creation_date': pd.Timestamp.now().isoformat(),\n","    'splits': metadata_v2\n","}\n","\n","with open(metadata_file_v2, 'w') as f:\n","    json.dump(metadata_export, f, indent=2)\n","\n","print(f\"✓ Enhanced metadata saved to: data_split_v2/split_metadata_v2.json\")\n","\n","# Save processing summary\n","print(f\"\\n[8] Generating processing summary...\")\n","\n","total_copied = sum(sum(stats.values()) for stats in copy_stats.values())\n","expected_total = verification_data['statistics']['total_samples'] * 3\n","\n","processing_summary_v2 = {\n","    'dataset': 'CASME2_KeyFrames',\n","    'phase': 'Phase 2',\n","    'processing_date': pd.Timestamp.now().isoformat(),\n","    'source_phase1_samples': verification_data['statistics']['total_samples'],\n","    'expansion_strategy': 'onset_apex_offset_extraction',\n","    'frame_types': ['onset', 'apex', 'offset'],\n","    'copy_statistics': {\n","        'train': {\n","            'total_images': sum(copy_stats['train'].values()),\n","            'frame_breakdown': copy_stats['train']\n","        },\n","        'val': {\n","            'total_images': sum(copy_stats['val'].values()),\n","            'frame_breakdown': copy_stats['val']\n","        },\n","        'test': {\n","            'total_images': sum(copy_stats['test'].values()),\n","            'frame_breakdown': copy_stats['test']\n","        }\n","    },\n","    'total_images_copied': total_copied,\n","    'expected_images': expected_total,\n","    'success_rate': (total_copied / expected_total * 100) if expected_total > 0 else 0,\n","    'copy_errors': len(copy_errors),\n","    'fallback_frames_used': verification_data['statistics']['fallback_samples'],\n","    'class_preservation': {\n","        'train': metadata_v2['train']['class_distribution'],\n","        'val': metadata_v2['val']['class_distribution'],\n","        'test': metadata_v2['test']['class_distribution']\n","    }\n","}\n","\n","summary_file_v2 = f\"{data_split_v2_path}/processing_summary_v2.json\"\n","\n","with open(summary_file_v2, 'w') as f:\n","    json.dump(processing_summary_v2, f, indent=2)\n","\n","print(f\"✓ Processing summary saved to: data_split_v2/processing_summary_v2.json\")\n","\n","# Final validation\n","print(f\"\\n[9] Final validation of data_split_v2 structure...\")\n","\n","validation_results = {}\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_v2_path}/{split_name}\"\n","\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir)\n","                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","        # Count by frame type\n","        frame_counts = {'onset': 0, 'apex': 0, 'offset': 0}\n","        for img_file in image_files:\n","            for frame_type in frame_types:\n","                if f\"_{frame_type}_\" in img_file:\n","                    frame_counts[frame_type] += 1\n","                    break\n","\n","        validation_results[split_name] = {\n","            'directory_exists': True,\n","            'total_images': len(image_files),\n","            'frame_breakdown': frame_counts,\n","            'sample_files': image_files[:3]\n","        }\n","    else:\n","        validation_results[split_name] = {\n","            'directory_exists': False,\n","            'total_images': 0,\n","            'frame_breakdown': {},\n","            'sample_files': []\n","        }\n","\n","print(f\"✓ Structure validation:\")\n","for split_name, results in validation_results.items():\n","    status = \"✓\" if results['directory_exists'] and results['total_images'] > 0 else \"✗\"\n","    print(f\"  {status} {split_name}: {results['total_images']} images\")\n","    if results['frame_breakdown']:\n","        print(f\"    Onset: {results['frame_breakdown']['onset']}, \"\n","              f\"Apex: {results['frame_breakdown']['apex']}, \"\n","              f\"Offset: {results['frame_breakdown']['offset']}\")\n","    if results['sample_files']:\n","        print(f\"    Sample: {results['sample_files'][0]}\")\n","\n","# Final summary\n","print(f\"\\n\" + \"=\" * 75)\n","print(\"PHASE 2 DATASET PREPARATION SUMMARY\")\n","print(\"=\" * 75)\n","\n","success_rate = processing_summary_v2['success_rate']\n","status = \"SUCCESS\" if success_rate >= 99 else \"PARTIAL\"\n","\n","print(f\"Processing Status: {status}\")\n","print(f\"Total images copied: {total_copied}/{expected_total} ({success_rate:.1f}%)\")\n","print(f\"Dataset expansion: {verification_data['statistics']['total_samples']} samples → {total_copied} images (3x)\")\n","print(f\"Frame distribution: {copy_stats['train']['onset']+copy_stats['val']['onset']+copy_stats['test']['onset']} onset, \"\n","      f\"{copy_stats['train']['apex']+copy_stats['val']['apex']+copy_stats['test']['apex']} apex, \"\n","      f\"{copy_stats['train']['offset']+copy_stats['val']['offset']+copy_stats['test']['offset']} offset\")\n","\n","print(f\"\\n✓ Split distribution:\")\n","print(f\"  Train: {sum(copy_stats['train'].values())} images (201 samples × 3)\")\n","print(f\"  Val: {sum(copy_stats['val'].values())} images (26 samples × 3)\")\n","print(f\"  Test: {sum(copy_stats['test'].values())} images (28 samples × 3)\")\n","\n","print(f\"\\n✓ Data quality:\")\n","print(f\"  Fallback frames used: {verification_data['statistics']['fallback_samples']}\")\n","print(f\"  Copy errors: {len(copy_errors)}\")\n","print(f\"  Split consistency: Maintained from Phase 1\")\n","\n","print(f\"\\n✓ Output files:\")\n","print(f\"  - Dataset: data_split_v2/train|val|test/\")\n","print(f\"  - Metadata: data_split_v2/split_metadata_v2.json\")\n","print(f\"  - Summary: data_split_v2/processing_summary_v2.json\")\n","\n","print(f\"\\n✓ Next steps:\")\n","print(f\"  - Phase 2 dataset ready for model training\")\n","print(f\"  - Each sample now represented by 3 temporal frames\")\n","print(f\"  - Proceed to model experiments with key frames approach\")\n","\n","print(\"=\" * 75)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"WFxPwDqu4Dos","executionInfo":{"status":"ok","timestamp":1759139556837,"user_tz":-420,"elapsed":156567,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"308cf8c5-30c7-4ffc-fb54-c03c5558a811"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II KEY FRAMES DATASET PREPARATION - PHASE 2\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Setting up Phase 2 directory structure...\n","Target: data_split_v2 (key frames: onset + apex + offset)\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v2/train\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v2/val\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v2/test\n","\n","[3] Loading verification results from Cell 1...\n","✓ Verification data loaded\n","  Strategy: nearest_frame_fallback\n","  Total samples: 255\n","  Perfect samples: 254\n","  Fallback samples: 1\n","\n","[4] Extracting and copying key frames to data_split_v2...\n","\n","  Processing TRAIN set (201 samples × 3 frames)...\n","  ✓ TRAIN extraction completed:\n","    Onset frames: 201\n","    Apex frames: 201\n","    Offset frames: 201\n","    Total: 603 images\n","\n","  Processing VAL set (26 samples × 3 frames)...\n","  ✓ VAL extraction completed:\n","    Onset frames: 26\n","    Apex frames: 26\n","    Offset frames: 26\n","    Total: 78 images\n","\n","  Processing TEST set (28 samples × 3 frames)...\n","  ✓ TEST extraction completed:\n","    Onset frames: 28\n","    Apex frames: 28\n","    Offset frames: 28\n","    Total: 84 images\n","\n","[5] Calculating class distribution for each split...\n","\n","  TRAIN set distribution (603 images):\n","    others: 237 images (39.3%)\n","    disgust: 150 images (24.9%)\n","    happiness: 75 images (12.4%)\n","    repression: 63 images (10.4%)\n","    surprise: 60 images (10.0%)\n","    sadness: 15 images (2.5%)\n","    fear: 3 images (0.5%)\n","\n","  VAL set distribution (78 images):\n","    others: 30 images (38.5%)\n","    disgust: 18 images (23.1%)\n","    happiness: 9 images (11.5%)\n","    repression: 9 images (11.5%)\n","    surprise: 6 images (7.7%)\n","    sadness: 3 images (3.8%)\n","    fear: 3 images (3.8%)\n","\n","  TEST set distribution (84 images):\n","    others: 30 images (35.7%)\n","    disgust: 21 images (25.0%)\n","    happiness: 12 images (14.3%)\n","    repression: 9 images (10.7%)\n","    surprise: 9 images (10.7%)\n","    sadness: 3 images (3.6%)\n","\n","[7] Saving enhanced metadata with frame type tracking...\n","✓ Enhanced metadata saved to: data_split_v2/split_metadata_v2.json\n","\n","[8] Generating processing summary...\n","✓ Processing summary saved to: data_split_v2/processing_summary_v2.json\n","\n","[9] Final validation of data_split_v2 structure...\n","✓ Structure validation:\n","  ✓ train: 603 images\n","    Onset: 201, Apex: 201, Offset: 201\n","    Sample: sub11_EP02_06f_onset_others.jpg\n","  ✓ val: 78 images\n","    Onset: 26, Apex: 26, Offset: 26\n","    Sample: sub06_EP10_08_onset_others.jpg\n","  ✓ test: 84 images\n","    Onset: 28, Apex: 28, Offset: 28\n","    Sample: sub14_EP04_04f_onset_others.jpg\n","\n","===========================================================================\n","PHASE 2 DATASET PREPARATION SUMMARY\n","===========================================================================\n","Processing Status: SUCCESS\n","Total images copied: 765/765 (100.0%)\n","Dataset expansion: 255 samples → 765 images (3x)\n","Frame distribution: 255 onset, 255 apex, 255 offset\n","\n","✓ Split distribution:\n","  Train: 603 images (201 samples × 3)\n","  Val: 78 images (26 samples × 3)\n","  Test: 84 images (28 samples × 3)\n","\n","✓ Data quality:\n","  Fallback frames used: 1\n","  Copy errors: 0\n","  Split consistency: Maintained from Phase 1\n","\n","✓ Output files:\n","  - Dataset: data_split_v2/train|val|test/\n","  - Metadata: data_split_v2/split_metadata_v2.json\n","  - Summary: data_split_v2/processing_summary_v2.json\n","\n","✓ Next steps:\n","  - Phase 2 dataset ready for model training\n","  - Each sample now represented by 3 temporal frames\n","  - Proceed to model experiments with key frames approach\n","===========================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 3: CASME II Key Frames Visualization\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Professional visualization setup\n","plt.style.use('default')\n","plt.rcParams.update({\n","    'font.family': 'DejaVu Sans',\n","    'font.size': 12,\n","    'axes.titlesize': 16,\n","    'axes.labelsize': 14,\n","    'xtick.labelsize': 12,\n","    'ytick.labelsize': 12,\n","    'legend.fontsize': 12,\n","    'figure.titlesize': 18,\n","    'axes.spines.top': False,\n","    'axes.spines.right': False,\n","    'axes.grid': False,\n","    'figure.facecolor': 'white',\n","    'axes.facecolor': 'white'\n","})\n","\n","def convert_to_serializable(obj):\n","    \"\"\"Convert numpy/pandas types to native Python types for JSON serialization\"\"\"\n","    if isinstance(obj, dict):\n","        return {key: convert_to_serializable(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_serializable(item) for item in obj]\n","    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif pd.isna(obj):\n","        return None\n","    else:\n","        return obj\n","\n","# Color palettes\n","EMOTION_COLORS = {\n","    'others': '#1f77b4',\n","    'disgust': '#d62728',\n","    'happiness': '#2ca02c',\n","    'repression': '#9467bd',\n","    'surprise': '#ff7f0e',\n","    'sadness': '#8c564b',\n","    'fear': '#e377c2'\n","}\n","\n","SPLIT_COLORS = {\n","    'raw': '#1f77b4',\n","    'train': '#ff7f0e',\n","    'val': '#d62728',\n","    'test': '#2ca02c'\n","}\n","\n","print(\"=\" * 80)\n","print(\"CASME II KEY FRAMES DATASET VISUALIZATION - PHASE 2\")\n","print(\"=\" * 80)\n","\n","print(\"\\n[1] Environment setup and drive mounting...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","data_split_v2_path = f\"{base_path}/datasets/processed_casme2/data_split_v2\"\n","split_metadata_v2_path = f\"{data_split_v2_path}/split_metadata_v2.json\"\n","visualization_path = f\"{base_path}/datasets/visualization/02_casme2-kfs\"\n","\n","os.makedirs(visualization_path, exist_ok=True)\n","print(f\"✓ Output directory created: {visualization_path}\")\n","\n","print(\"\\n[2] Loading raw metadata and Phase 2 data...\")\n","\n","# Load raw metadata for comparison\n","try:\n","    raw_metadata = pd.read_excel(metadata_path)\n","    if raw_metadata['ApexFrame'].dtype == 'object':\n","        raw_metadata['ApexFrame'] = pd.to_numeric(raw_metadata['ApexFrame'], errors='coerce')\n","    print(f\"✓ Raw metadata loaded: {len(raw_metadata)} samples\")\n","except Exception as e:\n","    print(f\"✗ Error loading raw metadata: {str(e)}\")\n","    exit()\n","\n","# Load Phase 2 metadata\n","\n","try:\n","    with open(split_metadata_v2_path, 'r') as f:\n","        metadata_v2 = json.load(f)\n","\n","    print(f\"✓ Phase 2 metadata loaded\")\n","    print(f\"  Dataset: {metadata_v2['dataset']}\")\n","    print(f\"  Frame types: {', '.join(metadata_v2['frame_types'])}\")\n","    print(f\"  Expansion factor: {metadata_v2['expansion_factor']}x\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","print(\"\\n[3] File integrity validation...\")\n","\n","splits_info = metadata_v2['splits']\n","total_actual_files = 0\n","\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_v2_path}/{split_name}\"\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir)\n","                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","        actual_count = len(image_files)\n","        expected_count = splits_info[split_name]['count']\n","        total_actual_files += actual_count\n","        status = '✓' if actual_count == expected_count else '✗'\n","        print(f\"  {status} {split_name.upper()}: {actual_count}/{expected_count} images\")\n","\n","print(f\"✓ Total validated files: {total_actual_files}\")\n","\n","print(\"\\n[4] Preparing visualization data...\")\n","\n","# Extract raw emotion distribution\n","raw_emotion_dist = raw_metadata['Estimated Emotion'].value_counts()\n","\n","# Extract class distributions per split\n","split_data = {}\n","for split_name in ['train', 'val', 'test']:\n","    split_data[split_name] = splits_info[split_name]['class_distribution']\n","\n","# Get all unique emotions sorted by raw distribution (highest to lowest)\n","all_emotions = raw_emotion_dist.index.tolist()\n","\n","print(f\"✓ Data preparation complete\")\n","print(f\"  Emotion classes: {len(all_emotions)}\")\n","print(f\"  Raw samples: {len(raw_metadata)}\")\n","print(f\"  Total Phase 2 images: {splits_info['train']['count'] + splits_info['val']['count'] + splits_info['test']['count']}\")\n","\n","print(\"\\n[5] Generating File 1: Key Frames vs Raw Distribution Comparison...\")\n","\n","fig1, ax1 = plt.subplots(1, 1, figsize=(16, 8))\n","\n","# Prepare data aligned with emotion order\n","# Raw counts multiplied by 3 to show potential frames (onset+apex+offset)\n","raw_counts = [raw_emotion_dist.get(emotion, 0) * 3 for emotion in all_emotions]\n","train_counts = [split_data['train'].get(emotion, 0) for emotion in all_emotions]\n","val_counts = [split_data['val'].get(emotion, 0) for emotion in all_emotions]\n","test_counts = [split_data['test'].get(emotion, 0) for emotion in all_emotions]\n","\n","x = np.arange(len(all_emotions))\n","width = 0.2\n","\n","# Create grouped bars with raw dataset included\n","bars0 = ax1.bar(x - width*1.5, raw_counts, width, label='Raw Dataset (Key Frames)',\n","                color=SPLIT_COLORS['raw'], alpha=0.85)\n","bars1 = ax1.bar(x - width/2, train_counts, width, label='Train Split (Key Frames)',\n","                color=SPLIT_COLORS['train'], alpha=0.85)\n","bars2 = ax1.bar(x + width/2, val_counts, width, label='Validation Split (Key Frames)',\n","                color=SPLIT_COLORS['val'], alpha=0.85)\n","bars3 = ax1.bar(x + width*1.5, test_counts, width, label='Test Split (Key Frames)',\n","                color=SPLIT_COLORS['test'], alpha=0.85)\n","\n","ax1.set_title('CASME II Key Frames Distribution - Raw vs Split Comparison',\n","              fontsize=18, fontweight='bold', pad=25)\n","ax1.set_xlabel('Emotion Classes (Sorted by Frequency)', fontsize=16, labelpad=20)\n","ax1.set_ylabel('Image Count', fontsize=16, labelpad=20)\n","ax1.set_xticks(x)\n","ax1.set_xticklabels(all_emotions, rotation=0)\n","ax1.legend(loc='upper right', fontsize=13)\n","ax1.grid(False)\n","\n","# Add value labels on bars\n","all_bars_data = [(bars0, raw_counts), (bars1, train_counts), (bars2, val_counts), (bars3, test_counts)]\n","for bars, values in all_bars_data:\n","    for bar, value in zip(bars, values):\n","        if value > 0:\n","            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n","                    str(value), ha='center', va='bottom', fontsize=9,\n","                    fontweight='bold')\n","\n","plt.tight_layout()\n","file1_path = f\"{visualization_path}/1_keyframes_split_distribution.png\"\n","plt.savefig(file1_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"✓ File 1 saved: 1_keyframes_split_distribution.png\")\n","\n","print(\"\\n[6] Generating File 2: Key Frames Statistical Analysis Table...\")\n","\n","fig2 = plt.figure(figsize=(18, 10))\n","ax2 = fig2.add_subplot(1, 1, 1)\n","ax2.axis('off')\n","\n","# Prepare table data\n","table_data = []\n","total_raw = 0\n","total_train = 0\n","total_val = 0\n","total_test = 0\n","\n","for emotion in all_emotions:\n","    raw_count = raw_emotion_dist.get(emotion, 0)\n","    train_count = split_data['train'].get(emotion, 0)\n","    val_count = split_data['val'].get(emotion, 0)\n","    test_count = split_data['test'].get(emotion, 0)\n","    total_images = train_count + val_count + test_count\n","\n","    # Calculate expansion verification (should be 3x)\n","    expansion_check = f\"{total_images // raw_count}x\" if raw_count > 0 else \"N/A\"\n","\n","    # Calculate percentages\n","    raw_percentage = (raw_count / len(raw_metadata)) * 100\n","\n","    # Calculate imbalance ratio\n","    max_count = raw_emotion_dist.max()\n","    imbalance_ratio = f\"{max_count / raw_count:.1f}:1\" if raw_count > 0 else \"∞:1\"\n","\n","    table_data.append([\n","        emotion.title(),\n","        raw_count,\n","        f\"{raw_percentage:.1f}%\",\n","        train_count,\n","        val_count,\n","        test_count,\n","        total_images,\n","        expansion_check,\n","        imbalance_ratio\n","    ])\n","\n","    total_raw += raw_count\n","    total_train += train_count\n","    total_val += val_count\n","    total_test += test_count\n","\n","# Add total row\n","total_images_all = total_train + total_val + total_test\n","\n","table_data.append([\n","    'TOTAL',\n","    total_raw,\n","    '100.0%',\n","    total_train,\n","    total_val,\n","    total_test,\n","    total_images_all,\n","    '3x',\n","    '1.0:1'\n","])\n","\n","# Convert to display format\n","table_display_data = []\n","for row in table_data:\n","    display_row = [\n","        row[0],  # emotion\n","        f\"{row[1]:,}\",  # raw samples\n","        row[2],  # raw percentage\n","        f\"{row[3]:,}\",  # train images\n","        f\"{row[4]:,}\",  # val images\n","        f\"{row[5]:,}\",  # test images\n","        f\"{row[6]:,}\",  # total images\n","        row[7],  # expansion\n","        row[8]   # imbalance\n","    ]\n","    table_display_data.append(display_row)\n","\n","# Create table\n","table = ax2.table(\n","    cellText=table_display_data,\n","    colLabels=['Emotion', 'Raw\\nSamples', 'Raw %', 'Train\\nImages', 'Val\\nImages',\n","               'Test\\nImages', 'Total\\nImages', 'Expansion', 'Imbalance'],\n","    cellLoc='center',\n","    loc='center',\n","    colWidths=[0.11, 0.10, 0.09, 0.10, 0.10, 0.10, 0.10, 0.09, 0.10]\n",")\n","\n","table.auto_set_font_size(False)\n","table.set_fontsize(11)\n","table.scale(1, 2.8)\n","\n","# Professional table styling\n","num_rows = len(table_display_data)\n","for i in range(num_rows + 1):\n","    for j in range(9):\n","        cell = table[(i, j)]\n","        if i == 0:  # Header\n","            cell.set_facecolor('#1f77b4')\n","            cell.set_text_props(weight='bold', color='white')\n","        elif i == num_rows:  # Total row\n","            cell.set_facecolor('#f0f0f0')\n","            cell.set_text_props(weight='bold')\n","        else:\n","            emotion = table_display_data[i-1][0].lower()\n","            if emotion in ['fear', 'sadness']:\n","                cell.set_facecolor('#ffe6e6')\n","            else:\n","                cell.set_facecolor('#ffffff')\n","\n","ax2.set_title('CASME II Key Frames Dataset Statistical Analysis (Phase 2)\\n' +\n","              'Temporal Expansion: Each Sample → 3 Frames (Onset + Apex + Offset)',\n","              fontsize=18, fontweight='bold', pad=40)\n","\n","plt.tight_layout()\n","file2_path = f\"{visualization_path}/2_keyframes_statistical_table.png\"\n","plt.savefig(file2_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"✓ File 2 saved: 2_keyframes_statistical_table.png\")\n","\n","print(\"\\n[7] Generating visualization metadata...\")\n","\n","# Calculate totals for metadata\n","total_samples = len(raw_metadata)\n","total_images_all = total_train + total_val + total_test\n","\n","# Generate comprehensive metadata\n","analysis_metadata = {\n","    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n","    'phase': 'Phase 2 - Key Frames Dataset',\n","    'dataset_info': {\n","        'name': 'CASME II Key Frames Dataset',\n","        'expansion_strategy': 'onset_apex_offset_extraction',\n","        'original_samples': total_samples,\n","        'total_images': total_images_all,\n","        'expansion_factor': 3,\n","        'frame_types': ['onset', 'apex', 'offset'],\n","        'emotion_classes': len(all_emotions)\n","    },\n","    'split_distribution': convert_to_serializable({\n","        'train': {\n","            'total_images': total_train,\n","            'original_samples': total_train // 3,\n","            'class_distribution': split_data['train']\n","        },\n","        'validation': {\n","            'total_images': total_val,\n","            'original_samples': total_val // 3,\n","            'class_distribution': split_data['val']\n","        },\n","        'test': {\n","            'total_images': total_test,\n","            'original_samples': total_test // 3,\n","            'class_distribution': split_data['test']\n","        }\n","    }),\n","    'visualization_files': {\n","        'split_distribution': '1_keyframes_split_distribution.png',\n","        'statistical_table': '2_keyframes_statistical_table.png'\n","    },\n","    'color_scheme': {\n","        'emotion_colors': EMOTION_COLORS,\n","        'split_colors': SPLIT_COLORS\n","    }\n","}\n","\n","metadata_file = f\"{visualization_path}/keyframes_visualization_metadata.json\"\n","with open(metadata_file, 'w') as f:\n","    json.dump(analysis_metadata, f, indent=2)\n","\n","print(f\"✓ Metadata saved: keyframes_visualization_metadata.json\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"KEY FRAMES VISUALIZATION COMPLETE - PHASE 2\")\n","print(\"=\" * 80)\n","print(f\"Status: SUCCESS\")\n","print(f\"Total images validated: {total_actual_files}\")\n","print(f\"Output location: {visualization_path}\")\n","\n","print(\"\\nGenerated files:\")\n","print(\"  • 1_keyframes_split_distribution.png - Split comparison with 3x expansion\")\n","print(\"  • 2_keyframes_statistical_table.png - Statistical analysis table\")\n","print(\"  • keyframes_visualization_metadata.json - Comprehensive metadata\")\n","\n","print(\"\\nDataset Summary:\")\n","print(f\"  Original samples: {total_samples}\")\n","print(f\"  Total images (3x): {total_images_all}\")\n","print(f\"  Train: {total_train} images ({total_train//3} samples × 3)\")\n","print(f\"  Val: {total_val} images ({total_val//3} samples × 3)\")\n","print(f\"  Test: {total_test} images ({total_test//3} samples × 3)\")\n","\n","print(\"\\n✓ Phase 2 visualization ready for thesis documentation\")\n","print(\"=\" * 80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"cellView":"form","id":"kIYpSl-66fr7","executionInfo":{"status":"ok","timestamp":1759153854320,"user_tz":-420,"elapsed":34931,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"f56c628c-1910-4db9-e8e3-3c1d9585a328"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CASME II KEY FRAMES DATASET VISUALIZATION - PHASE 2\n","================================================================================\n","\n","[1] Environment setup and drive mounting...\n","Mounted at /content/drive\n","✓ Google Drive mounted successfully\n","✓ Output directory created: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/02_casme2-kfs\n","\n","[2] Loading raw metadata and Phase 2 data...\n","✓ Raw metadata loaded: 255 samples\n","✓ Phase 2 metadata loaded\n","  Dataset: CASME2_KeyFrames\n","  Frame types: onset, apex, offset\n","  Expansion factor: 3x\n","\n","[3] File integrity validation...\n","  ✓ TRAIN: 603/603 images\n","  ✓ VAL: 78/78 images\n","  ✓ TEST: 84/84 images\n","✓ Total validated files: 765\n","\n","[4] Preparing visualization data...\n","✓ Data preparation complete\n","  Emotion classes: 7\n","  Raw samples: 255\n","  Total Phase 2 images: 765\n","\n","[5] Generating File 1: Key Frames vs Raw Distribution Comparison...\n","✓ File 1 saved: 1_keyframes_split_distribution.png\n","\n","[6] Generating File 2: Key Frames Statistical Analysis Table...\n","✓ File 2 saved: 2_keyframes_statistical_table.png\n","\n","[7] Generating visualization metadata...\n","✓ Metadata saved: keyframes_visualization_metadata.json\n","\n","================================================================================\n","KEY FRAMES VISUALIZATION COMPLETE - PHASE 2\n","================================================================================\n","Status: SUCCESS\n","Total images validated: 765\n","Output location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/02_casme2-kfs\n","\n","Generated files:\n","  • 1_keyframes_split_distribution.png - Split comparison with 3x expansion\n","  • 2_keyframes_statistical_table.png - Statistical analysis table\n","  • keyframes_visualization_metadata.json - Comprehensive metadata\n","\n","Dataset Summary:\n","  Original samples: 255\n","  Total images (3x): 765\n","  Train: 603 images (201 samples × 3)\n","  Val: 78 images (26 samples × 3)\n","  Test: 84 images (28 samples × 3)\n","\n","✓ Phase 2 visualization ready for thesis documentation\n","================================================================================\n"]}]}]}