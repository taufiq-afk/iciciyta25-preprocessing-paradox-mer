{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPuigK5J9h12UUvaN34FC2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"w-kQKuhbfl_N","executionInfo":{"status":"ok","timestamp":1759149826058,"user_tz":-420,"elapsed":77806,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"d188766d-9431-497d-e149-c8ec7fbb5b16"},"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II MULTI-FRAME SAMPLING VERIFICATION - PHASE 3\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Mounted at /content/drive\n","✓ Google Drive mounted successfully\n","\n","[2] Loading Phase 1 split metadata for consistency...\n","Phase 1 metadata: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/split_metadata.json\n","✓ Phase 1 metadata loaded: 255 total samples\n","  Train: 201 samples\n","  Val: 26 samples\n","  Test: 28 samples\n","\n","[3] Loading CASME II metadata...\n","⚠ ApexFrame column contained non-numeric values, converted to numeric\n","✓ Metadata loaded: 255 records\n","  Columns: Subject, Filename, OnsetFrame, ApexFrame, OffsetFrame, Estimated Emotion\n","\n","[4] Creating comprehensive sample mapping from metadata...\n","✓ Sample mapping created: 255 samples indexed\n","\n","[5] Defining multi-frame sampling windows...\n","✓ Window configuration:\n","  ONSET: 4 frames - Forward: N+[0,1,2,3]\n","  APEX: 5 frames - Centered: N+[-2,-1,0,1,2]\n","  OFFSET: 4 frames - Backward: N+[-3,-2,-1,0]\n","  Total frames per sample: 13\n","\n","[6] Verifying multi-frame window availability...\n","Strategy: Train=Multi-frame, Val/Test=Key-frames only\n","\n","  Verifying TRAIN set (201 samples)...\n","  ✓ TRAIN verification completed\n","\n","  Verifying VAL set (26 samples)...\n","  ✓ VAL verification completed\n","\n","  Verifying TEST set (28 samples)...\n","  ✓ TEST verification completed\n","\n","[7] Multi-Frame Sampling Availability Statistics:\n","===========================================================================\n","\n","TRAIN SET (Multi-Frame Sampling):\n","  Total samples verified: 201\n","  ✓ Perfect (all windows 100%): 196 (97.5%)\n","  ⚠ Partial (some windows 75-99%): 5 (2.5%)\n","  ✗ Problematic (windows <75%): 5 (2.5%)\n","\n","  Frame-wise availability (Multi-Frame Windows):\n","    ONSET windows (4 frames each):\n","      Perfect windows: 201/201 (100.0%)\n","      Partial windows: 0/201 (0.0%)\n","      Problematic: 0/201 (0.0%)\n","      Total frames extracted: 804\n","    APEX windows (5 frames each):\n","      Perfect windows: 196/201 (97.5%)\n","      Partial windows: 0/201 (0.0%)\n","      Problematic: 5/201 (2.5%)\n","      Total frames extracted: 995\n","    OFFSET windows (4 frames each):\n","      Perfect windows: 201/201 (100.0%)\n","      Partial windows: 0/201 (0.0%)\n","      Problematic: 0/201 (0.0%)\n","      Total frames extracted: 804\n","\n","VALIDATION SET (Key-Frames Only):\n","  Total samples verified: 26\n","  ✓ Perfect (all key frames available): 26 (100.0%)\n","  ⚠ Partial (some key frames missing): 0\n","\n","  Key-frame availability:\n","    ONSET: 26/26 available (100.0%)\n","    APEX: 26/26 available (100.0%)\n","    OFFSET: 26/26 available (100.0%)\n","\n","TEST SET (Key-Frames Only):\n","  Total samples verified: 28\n","  ✓ Perfect (all key frames available): 27 (96.4%)\n","  ⚠ Partial (some key frames missing): 1\n","\n","  Key-frame availability:\n","    ONSET: 28/28 available (100.0%)\n","    APEX: 28/28 available (100.0%)\n","    OFFSET: 27/28 available (96.4%)\n","\n","[8] Problematic Training Samples Analysis (windows <75% complete):\n","\n","  Sample: sub20_EP16_01\n","    Available frames: 71 to 111 (41 frames)\n","    ONSET: 100% complete - Missing: []\n","    APEX: 60% complete - Missing: [112, 113]\n","    OFFSET: 100% complete - Missing: []\n","\n","  Sample: sub05_EP16_04f\n","    Available frames: 141 to 181 (41 frames)\n","    ONSET: 100% complete - Missing: []\n","    APEX: 60% complete - Missing: [182, 183]\n","    OFFSET: 100% complete - Missing: []\n","\n","  Sample: sub04_EP12_01f\n","    Available frames: 261 to 321 (61 frames)\n","    ONSET: 100% complete - Missing: []\n","    APEX: 60% complete - Missing: [259, 260]\n","    OFFSET: 100% complete - Missing: []\n","\n","  Sample: sub25_EP18_04f\n","    Available frames: 76 to 116 (41 frames)\n","    ONSET: 100% complete - Missing: []\n","    APEX: 60% complete - Missing: [117, 118]\n","    OFFSET: 100% complete - Missing: []\n","\n","  Sample: sub12_EP09_06\n","    Available frames: 66 to 111 (46 frames)\n","    ONSET: 100% complete - Missing: []\n","    APEX: 60% complete - Missing: [112, 113]\n","    OFFSET: 100% complete - Missing: []\n","\n","[9] Exporting verification results...\n","✓ Verification results saved to: multi_frame_verification.json\n","\n","[10] Phase 3 Dataset Readiness Assessment:\n","===========================================================================\n","Readiness Status: READY\n","Overall Readiness: 98.8%\n","Assessment: Dataset ready for multi-frame extraction\n","\n","✓ Expected Phase 3 dataset composition:\n","  TRAIN (Multi-Frame):\n","    Samples: 201\n","    Total frames: 2603\n","    Breakdown: 804 onset + 995 apex + 804 offset\n","\n","  VAL (Key-Frames):\n","    Samples: 26\n","    Total frames: 78 (3 per sample)\n","\n","  TEST (Key-Frames):\n","    Samples: 28\n","    Total frames: 83 (3 per sample)\n","\n","  GRAND TOTAL: 2764 frames\n","\n","✓ Next steps:\n","  - Review verification results in multi_frame_verification.json\n","  - Proceed to Cell 2: Multi-frame extraction and dataset preparation\n","  - Cell 2 will apply fallback strategy for 5 problematic samples\n","===========================================================================\n"]}],"source":["# @title Cell 1: CASME II Multi-Frame Sampling Availability Verification\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","from google.colab import drive\n","from pathlib import Path\n","from collections import defaultdict\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II MULTI-FRAME SAMPLING VERIFICATION - PHASE 3\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw/CASME2_RAW_selected\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","phase1_split_metadata = f\"{base_path}/datasets/processed_casme2/data_split/split_metadata.json\"\n","\n","print(f\"\\n[2] Loading Phase 1 split metadata for consistency...\")\n","print(f\"Phase 1 metadata: {phase1_split_metadata}\")\n","\n","try:\n","    with open(phase1_split_metadata, 'r') as f:\n","        phase1_splits = json.load(f)\n","\n","    total_phase1_samples = sum(split['count'] for split in phase1_splits.values())\n","    print(f\"✓ Phase 1 metadata loaded: {total_phase1_samples} total samples\")\n","    print(f\"  Train: {phase1_splits['train']['count']} samples\")\n","    print(f\"  Val: {phase1_splits['val']['count']} samples\")\n","    print(f\"  Test: {phase1_splits['test']['count']} samples\")\n","except Exception as e:\n","    print(f\"✗ Error loading Phase 1 metadata: {str(e)}\")\n","    exit()\n","\n","# Load CASME II metadata\n","print(f\"\\n[3] Loading CASME II metadata...\")\n","\n","try:\n","    df = pd.read_excel(metadata_path)\n","\n","    # Clean ApexFrame column if needed\n","    if df['ApexFrame'].dtype == 'object':\n","        df['ApexFrame'] = pd.to_numeric(df['ApexFrame'], errors='coerce')\n","        print(f\"⚠ ApexFrame column contained non-numeric values, converted to numeric\")\n","\n","    print(f\"✓ Metadata loaded: {len(df)} records\")\n","    print(f\"  Columns: Subject, Filename, OnsetFrame, ApexFrame, OffsetFrame, Estimated Emotion\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","# Create comprehensive sample mapping\n","print(f\"\\n[4] Creating comprehensive sample mapping from metadata...\")\n","\n","metadata_map = {}\n","for idx, row in df.iterrows():\n","    subject = f\"sub{str(row['Subject']).zfill(2)}\"\n","    sequence = row['Filename']\n","    sample_id = f\"{subject}_{sequence}\"\n","\n","    metadata_map[sample_id] = {\n","        'subject': subject,\n","        'sequence': sequence,\n","        'emotion': row['Estimated Emotion'],\n","        'onset_frame': int(row['OnsetFrame']),\n","        'apex_frame': int(row['ApexFrame']) if pd.notna(row['ApexFrame']) else None,\n","        'offset_frame': int(row['OffsetFrame'])\n","    }\n","\n","print(f\"✓ Sample mapping created: {len(metadata_map)} samples indexed\")\n","\n","# Multi-frame window definition\n","print(f\"\\n[5] Defining multi-frame sampling windows...\")\n","\n","WINDOW_CONFIG = {\n","    'onset': {'offsets': [0, 1, 2, 3], 'description': 'Forward: N+[0,1,2,3]'},\n","    'apex': {'offsets': [-2, -1, 0, 1, 2], 'description': 'Centered: N+[-2,-1,0,1,2]'},\n","    'offset': {'offsets': [-3, -2, -1, 0], 'description': 'Backward: N+[-3,-2,-1,0]'}\n","}\n","\n","print(f\"✓ Window configuration:\")\n","for frame_type, config in WINDOW_CONFIG.items():\n","    print(f\"  {frame_type.upper()}: {len(config['offsets'])} frames - {config['description']}\")\n","\n","total_frames_per_sample = sum(len(config['offsets']) for config in WINDOW_CONFIG.values())\n","print(f\"  Total frames per sample: {total_frames_per_sample}\")\n","\n","# Frame availability verification function\n","def get_available_frames(sequence_path):\n","    \"\"\"Get sorted list of available frame numbers in sequence\"\"\"\n","    if not os.path.exists(sequence_path):\n","        return []\n","\n","    image_files = [f for f in os.listdir(sequence_path)\n","                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    frame_numbers = []\n","    for img_file in image_files:\n","        try:\n","            # Extract number from filename (e.g., img46.jpg -> 46)\n","            frame_num = int(''.join(filter(str.isdigit, img_file.split('.')[0])))\n","            frame_numbers.append(frame_num)\n","        except ValueError:\n","            continue\n","\n","    return sorted(frame_numbers)\n","\n","def verify_window_availability(key_frame, window_offsets, available_frames):\n","    \"\"\"\n","    Verify which frames in window are available\n","    Returns: (available_frames_list, missing_frames_list, completeness_rate)\n","    \"\"\"\n","    requested_frames = [key_frame + offset for offset in window_offsets]\n","    available_in_window = [f for f in requested_frames if f in available_frames]\n","    missing_in_window = [f for f in requested_frames if f not in available_frames]\n","\n","    completeness = len(available_in_window) / len(requested_frames) if requested_frames else 0\n","\n","    return available_in_window, missing_in_window, completeness\n","\n","# Verify multi-frame availability for all splits\n","print(f\"\\n[6] Verifying multi-frame window availability...\")\n","print(f\"Strategy: Train=Multi-frame, Val/Test=Key-frames only\")\n","\n","verification_results = {\n","    'train': [],\n","    'val': [],\n","    'test': []\n","}\n","\n","statistics = {\n","    'train': {\n","        'total_samples': 0,\n","        'perfect_samples': 0,\n","        'partial_samples': 0,\n","        'problematic_samples': 0,\n","        'frame_stats': {\n","            'onset': {'perfect': 0, 'partial': 0, 'missing': 0, 'total_frames': 0},\n","            'apex': {'perfect': 0, 'partial': 0, 'missing': 0, 'total_frames': 0},\n","            'offset': {'perfect': 0, 'partial': 0, 'missing': 0, 'total_frames': 0}\n","        }\n","    },\n","    'val': {\n","        'total_samples': 0,\n","        'perfect_samples': 0,\n","        'partial_samples': 0,\n","        'frame_stats': {\n","            'onset': {'perfect': 0, 'partial': 0},\n","            'apex': {'perfect': 0, 'partial': 0},\n","            'offset': {'perfect': 0, 'partial': 0}\n","        }\n","    },\n","    'test': {\n","        'total_samples': 0,\n","        'perfect_samples': 0,\n","        'partial_samples': 0,\n","        'frame_stats': {\n","            'onset': {'perfect': 0, 'partial': 0},\n","            'apex': {'perfect': 0, 'partial': 0},\n","            'offset': {'perfect': 0, 'partial': 0}\n","        }\n","    }\n","}\n","\n","for split_name, split_data in phase1_splits.items():\n","    print(f\"\\n  Verifying {split_name.upper()} set ({split_data['count']} samples)...\")\n","\n","    is_train = (split_name == 'train')\n","\n","    for sample in split_data['samples']:\n","        sample_id = sample['sample_id']\n","\n","        # Skip if sample not in metadata\n","        if sample_id not in metadata_map:\n","            print(f\"  ✗ Sample {sample_id} not found in metadata\")\n","            continue\n","\n","        meta = metadata_map[sample_id]\n","        sequence_path = os.path.join(raw_path, meta['subject'], meta['sequence'])\n","\n","        # Get available frames in sequence\n","        available_frames = get_available_frames(sequence_path)\n","\n","        if not available_frames:\n","            print(f\"  ✗ No frames found for {sample_id}\")\n","            continue\n","\n","        statistics[split_name]['total_samples'] += 1\n","\n","        # Prepare sample verification result\n","        sample_result = {\n","            'sample_id': sample_id,\n","            'subject': meta['subject'],\n","            'sequence': meta['sequence'],\n","            'emotion': meta['emotion'],\n","            'available_frame_range': [min(available_frames), max(available_frames)],\n","            'total_available_frames': len(available_frames),\n","            'windows': {}\n","        }\n","\n","        # Verify each frame type window\n","        sample_all_perfect = True\n","        sample_has_partial = False\n","\n","        for frame_type in ['onset', 'apex', 'offset']:\n","            key_frame_map = {\n","                'onset': meta['onset_frame'],\n","                'apex': meta['apex_frame'] if meta['apex_frame'] else meta['onset_frame'],\n","                'offset': meta['offset_frame']\n","            }\n","\n","            key_frame = key_frame_map[frame_type]\n","            window_offsets = WINDOW_CONFIG[frame_type]['offsets']\n","\n","            if is_train:\n","                # Multi-frame verification for training\n","                available_list, missing_list, completeness = verify_window_availability(\n","                    key_frame, window_offsets, available_frames\n","                )\n","\n","                window_status = 'perfect' if completeness == 1.0 else ('partial' if completeness >= 0.75 else 'problematic')\n","\n","                sample_result['windows'][frame_type] = {\n","                    'key_frame': key_frame,\n","                    'window_offsets': window_offsets,\n","                    'requested_frames': [key_frame + offset for offset in window_offsets],\n","                    'available_frames': available_list,\n","                    'missing_frames': missing_list,\n","                    'completeness': completeness,\n","                    'status': window_status\n","                }\n","\n","                # Update statistics\n","                if completeness == 1.0:\n","                    statistics[split_name]['frame_stats'][frame_type]['perfect'] += 1\n","                elif completeness >= 0.75:\n","                    statistics[split_name]['frame_stats'][frame_type]['partial'] += 1\n","                    sample_has_partial = True\n","                    sample_all_perfect = False\n","                else:\n","                    statistics[split_name]['frame_stats'][frame_type]['missing'] += 1\n","                    sample_all_perfect = False\n","\n","                statistics[split_name]['frame_stats'][frame_type]['total_frames'] += len(available_list)\n","\n","            else:\n","                # Key-frame only verification for val/test\n","                is_available = key_frame in available_frames\n","\n","                sample_result['windows'][frame_type] = {\n","                    'key_frame': key_frame,\n","                    'is_available': is_available,\n","                    'status': 'perfect' if is_available else 'missing'\n","                }\n","\n","                if is_available:\n","                    statistics[split_name]['frame_stats'][frame_type]['perfect'] += 1\n","                else:\n","                    statistics[split_name]['frame_stats'][frame_type]['partial'] += 1\n","                    sample_all_perfect = False\n","\n","        # Update sample-level statistics\n","        if sample_all_perfect:\n","            statistics[split_name]['perfect_samples'] += 1\n","        elif sample_has_partial or not sample_all_perfect:\n","            statistics[split_name]['partial_samples'] += 1\n","\n","        if is_train and any(sample_result['windows'][ft]['completeness'] < 0.75 for ft in ['onset', 'apex', 'offset']):\n","            statistics[split_name]['problematic_samples'] += 1\n","\n","        verification_results[split_name].append(sample_result)\n","\n","    print(f\"  ✓ {split_name.upper()} verification completed\")\n","\n","# Display comprehensive statistics\n","print(f\"\\n[7] Multi-Frame Sampling Availability Statistics:\")\n","print(f\"=\" * 75)\n","\n","print(f\"\\nTRAIN SET (Multi-Frame Sampling):\")\n","train_stats = statistics['train']\n","print(f\"  Total samples verified: {train_stats['total_samples']}\")\n","print(f\"  ✓ Perfect (all windows 100%): {train_stats['perfect_samples']} ({train_stats['perfect_samples']/train_stats['total_samples']*100:.1f}%)\")\n","print(f\"  ⚠ Partial (some windows 75-99%): {train_stats['partial_samples']} ({train_stats['partial_samples']/train_stats['total_samples']*100:.1f}%)\")\n","print(f\"  ✗ Problematic (windows <75%): {train_stats['problematic_samples']} ({train_stats['problematic_samples']/train_stats['total_samples']*100:.1f}%)\")\n","\n","print(f\"\\n  Frame-wise availability (Multi-Frame Windows):\")\n","for frame_type, stats in train_stats['frame_stats'].items():\n","    total = stats['perfect'] + stats['partial'] + stats['missing']\n","    print(f\"    {frame_type.upper()} windows ({len(WINDOW_CONFIG[frame_type]['offsets'])} frames each):\")\n","    print(f\"      Perfect windows: {stats['perfect']}/{total} ({stats['perfect']/total*100:.1f}%)\")\n","    print(f\"      Partial windows: {stats['partial']}/{total} ({stats['partial']/total*100:.1f}%)\")\n","    print(f\"      Problematic: {stats['missing']}/{total} ({stats['missing']/total*100:.1f}%)\")\n","    print(f\"      Total frames extracted: {stats['total_frames']}\")\n","\n","print(f\"\\nVALIDATION SET (Key-Frames Only):\")\n","val_stats = statistics['val']\n","print(f\"  Total samples verified: {val_stats['total_samples']}\")\n","print(f\"  ✓ Perfect (all key frames available): {val_stats['perfect_samples']} ({val_stats['perfect_samples']/val_stats['total_samples']*100:.1f}%)\")\n","print(f\"  ⚠ Partial (some key frames missing): {val_stats['partial_samples']}\")\n","\n","print(f\"\\n  Key-frame availability:\")\n","for frame_type, stats in val_stats['frame_stats'].items():\n","    total = stats['perfect'] + stats['partial']\n","    print(f\"    {frame_type.upper()}: {stats['perfect']}/{total} available ({stats['perfect']/total*100:.1f}%)\")\n","\n","print(f\"\\nTEST SET (Key-Frames Only):\")\n","test_stats = statistics['test']\n","print(f\"  Total samples verified: {test_stats['total_samples']}\")\n","print(f\"  ✓ Perfect (all key frames available): {test_stats['perfect_samples']} ({test_stats['perfect_samples']/test_stats['total_samples']*100:.1f}%)\")\n","print(f\"  ⚠ Partial (some key frames missing): {test_stats['partial_samples']}\")\n","\n","print(f\"\\n  Key-frame availability:\")\n","for frame_type, stats in test_stats['frame_stats'].items():\n","    total = stats['perfect'] + stats['partial']\n","    print(f\"    {frame_type.upper()}: {stats['perfect']}/{total} available ({stats['perfect']/total*100:.1f}%)\")\n","\n","# Show sample problematic cases if any\n","if train_stats['problematic_samples'] > 0:\n","    print(f\"\\n[8] Problematic Training Samples Analysis (windows <75% complete):\")\n","    problematic_count = 0\n","    for sample in verification_results['train']:\n","        if any(sample['windows'][ft]['completeness'] < 0.75 for ft in ['onset', 'apex', 'offset']):\n","            if problematic_count < 5:\n","                print(f\"\\n  Sample: {sample['sample_id']}\")\n","                print(f\"    Available frames: {sample['available_frame_range'][0]} to {sample['available_frame_range'][1]} ({sample['total_available_frames']} frames)\")\n","                for ft in ['onset', 'apex', 'offset']:\n","                    window = sample['windows'][ft]\n","                    print(f\"    {ft.upper()}: {window['completeness']*100:.0f}% complete - Missing: {window['missing_frames']}\")\n","                problematic_count += 1\n","\n","    if train_stats['problematic_samples'] > 5:\n","        print(f\"\\n  ... and {train_stats['problematic_samples'] - 5} more problematic samples\")\n","\n","# Export verification results\n","print(f\"\\n[9] Exporting verification results...\")\n","\n","output_path = f\"{base_path}/datasets/processed_casme2\"\n","verification_file = f\"{output_path}/multi_frame_verification.json\"\n","\n","# Calculate expected dataset sizes\n","expected_train_frames = train_stats['frame_stats']['onset']['total_frames'] + \\\n","                        train_stats['frame_stats']['apex']['total_frames'] + \\\n","                        train_stats['frame_stats']['offset']['total_frames']\n","\n","expected_val_frames = val_stats['frame_stats']['onset']['perfect'] + \\\n","                      val_stats['frame_stats']['apex']['perfect'] + \\\n","                      val_stats['frame_stats']['offset']['perfect']\n","\n","expected_test_frames = test_stats['frame_stats']['onset']['perfect'] + \\\n","                       test_stats['frame_stats']['apex']['perfect'] + \\\n","                       test_stats['frame_stats']['offset']['perfect']\n","\n","verification_export = {\n","    'verification_date': pd.Timestamp.now().isoformat(),\n","    'phase': 'Phase 3 - Multi-Frame Sampling',\n","    'strategy': {\n","        'train': 'multi_frame_windows',\n","        'val': 'key_frames_only',\n","        'test': 'key_frames_only'\n","    },\n","    'window_configuration': WINDOW_CONFIG,\n","    'statistics': statistics,\n","    'expected_dataset_sizes': {\n","        'train': {\n","            'samples': train_stats['total_samples'],\n","            'total_frames': expected_train_frames,\n","            'frames_per_sample': total_frames_per_sample\n","        },\n","        'val': {\n","            'samples': val_stats['total_samples'],\n","            'total_frames': expected_val_frames,\n","            'frames_per_sample': 3\n","        },\n","        'test': {\n","            'samples': test_stats['total_samples'],\n","            'total_frames': expected_test_frames,\n","            'frames_per_sample': 3\n","        }\n","    },\n","    'split_results': verification_results\n","}\n","\n","with open(verification_file, 'w') as f:\n","    json.dump(verification_export, f, indent=2)\n","\n","print(f\"✓ Verification results saved to: multi_frame_verification.json\")\n","\n","# Final readiness assessment\n","print(f\"\\n[10] Phase 3 Dataset Readiness Assessment:\")\n","print(f\"=\" * 75)\n","\n","train_readiness = (train_stats['perfect_samples'] + train_stats['partial_samples']) / train_stats['total_samples'] * 100\n","val_readiness = val_stats['perfect_samples'] / val_stats['total_samples'] * 100\n","test_readiness = test_stats['perfect_samples'] / test_stats['total_samples'] * 100\n","\n","overall_readiness = (train_readiness + val_readiness + test_readiness) / 3\n","\n","if overall_readiness >= 95:\n","    status = \"READY\"\n","    message = \"Dataset ready for multi-frame extraction\"\n","elif overall_readiness >= 90:\n","    status = \"READY WITH MINOR ISSUES\"\n","    message = f\"{train_stats['problematic_samples']} training samples may need fallback strategy\"\n","else:\n","    status = \"NEEDS ATTENTION\"\n","    message = \"Significant frame availability issues detected\"\n","\n","print(f\"Readiness Status: {status}\")\n","print(f\"Overall Readiness: {overall_readiness:.1f}%\")\n","print(f\"Assessment: {message}\")\n","\n","print(f\"\\n✓ Expected Phase 3 dataset composition:\")\n","print(f\"  TRAIN (Multi-Frame):\")\n","print(f\"    Samples: {train_stats['total_samples']}\")\n","print(f\"    Total frames: {expected_train_frames}\")\n","print(f\"    Breakdown: {train_stats['frame_stats']['onset']['total_frames']} onset + {train_stats['frame_stats']['apex']['total_frames']} apex + {train_stats['frame_stats']['offset']['total_frames']} offset\")\n","print(f\"\\n  VAL (Key-Frames):\")\n","print(f\"    Samples: {val_stats['total_samples']}\")\n","print(f\"    Total frames: {expected_val_frames} (3 per sample)\")\n","print(f\"\\n  TEST (Key-Frames):\")\n","print(f\"    Samples: {test_stats['total_samples']}\")\n","print(f\"    Total frames: {expected_test_frames} (3 per sample)\")\n","print(f\"\\n  GRAND TOTAL: {expected_train_frames + expected_val_frames + expected_test_frames} frames\")\n","\n","print(f\"\\n✓ Next steps:\")\n","print(f\"  - Review verification results in multi_frame_verification.json\")\n","print(f\"  - Proceed to Cell 2: Multi-frame extraction and dataset preparation\")\n","if train_stats['problematic_samples'] > 0:\n","    print(f\"  - Cell 2 will apply fallback strategy for {train_stats['problematic_samples']} problematic samples\")\n","else:\n","    print(f\"  - No fallback strategy needed (all windows sufficient)\")\n","\n","print(\"=\" * 75)"]},{"cell_type":"code","source":["# @title Cell 2: CASME II Multi-Frame Sampling Extraction and Dataset Preparation\n","\n","import os\n","import shutil\n","import json\n","import pandas as pd\n","from google.colab import drive\n","from pathlib import Path\n","\n","# Mount Google Drive\n","print(\"=\" * 75)\n","print(\"CASME II MULTI-FRAME SAMPLING DATASET PREPARATION - PHASE 3\")\n","print(\"=\" * 75)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","processed_path = f\"{base_path}/datasets/processed_casme2\"\n","verification_file = f\"{processed_path}/multi_frame_verification.json\"\n","\n","print(f\"\\n[2] Setting up Phase 3 directory structure...\")\n","print(f\"Target: data_split_v3 (Multi-Frame for Train, Key-Frames for Val/Test)\")\n","\n","# Create data_split_v3 directory structure\n","data_split_v3_path = f\"{processed_path}/data_split_v3\"\n","directories = [\n","    f\"{data_split_v3_path}/train\",\n","    f\"{data_split_v3_path}/val\",\n","    f\"{data_split_v3_path}/test\"\n","]\n","\n","for directory in directories:\n","    os.makedirs(directory, exist_ok=True)\n","    print(f\"✓ Created directory: {directory}\")\n","\n","# Load verification results\n","print(f\"\\n[3] Loading verification results from Cell 1...\")\n","\n","try:\n","    with open(verification_file, 'r') as f:\n","        verification_data = json.load(f)\n","\n","    print(f\"✓ Verification data loaded\")\n","    print(f\"  Strategy: Train=Multi-frame, Val/Test=Key-frames\")\n","    print(f\"  Train samples: {verification_data['statistics']['train']['total_samples']}\")\n","    print(f\"  Expected train frames: {verification_data['expected_dataset_sizes']['train']['total_frames']}\")\n","    print(f\"  Problematic samples: {verification_data['statistics']['train']['problematic_samples']}\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading verification data: {str(e)}\")\n","    exit()\n","\n","# Extract multi-frame sequences and copy to split directories\n","print(f\"\\n[4] Extracting multi-frame sequences with fallback strategy...\")\n","print(f\"Fallback: Missing frames will use nearest available frame (duplication)\")\n","\n","copy_stats = {\n","    'train': {'onset': 0, 'apex': 0, 'offset': 0, 'duplicated_frames': 0},\n","    'val': {'onset': 0, 'apex': 0, 'offset': 0},\n","    'test': {'onset': 0, 'apex': 0, 'offset': 0}\n","}\n","\n","copy_errors = []\n","metadata_v3 = {\n","    'train': {'count': 0, 'samples': [], 'class_distribution': {}},\n","    'val': {'count': 0, 'samples': [], 'class_distribution': {}},\n","    'test': {'count': 0, 'samples': [], 'class_distribution': {}}\n","}\n","\n","for split_name, samples in verification_data['split_results'].items():\n","    print(f\"\\n  Processing {split_name.upper()} set ({len(samples)} samples)...\")\n","\n","    split_dir = f\"{data_split_v3_path}/{split_name}\"\n","    is_train = (split_name == 'train')\n","\n","    for sample in samples:\n","        sample_id = sample['sample_id']\n","        emotion = sample['emotion']\n","        subject = sample['subject']\n","        sequence = sample['sequence']\n","\n","        # Process each frame type\n","        for frame_type in ['onset', 'apex', 'offset']:\n","            window = sample['windows'][frame_type]\n","\n","            if is_train:\n","                # Multi-frame extraction for training\n","                requested_frames = window['requested_frames']\n","                available_frames = window['available_frames']\n","                missing_frames = window['missing_frames']\n","\n","                # Build frame path mapping with fallback\n","                frame_paths = {}\n","                for req_frame in requested_frames:\n","                    if req_frame in available_frames:\n","                        # Frame available, use it\n","                        frame_paths[req_frame] = req_frame\n","                    else:\n","                        # Frame missing, use nearest available frame\n","                        if available_frames:\n","                            nearest_frame = min(available_frames, key=lambda x: abs(x - req_frame))\n","                            frame_paths[req_frame] = nearest_frame\n","                            copy_stats[split_name]['duplicated_frames'] += 1\n","                        else:\n","                            copy_errors.append(f\"No available frames for {sample_id} {frame_type}\")\n","                            continue\n","\n","                # Extract and copy frames\n","                for req_frame, actual_frame in frame_paths.items():\n","                    # Calculate position offset\n","                    key_frame = window['key_frame']\n","                    position_offset = req_frame - key_frame\n","\n","                    # Source path\n","                    source_path = os.path.join(\n","                        base_path, 'datasets/raw/CASME2_RAW_selected',\n","                        subject, sequence, f\"img{actual_frame}.jpg\"\n","                    )\n","\n","                    # Destination filename: {sample_id}_{frame_type}_p{offset}_{emotion}.jpg\n","                    offset_str = f\"p{position_offset:+d}\" if position_offset >= 0 else f\"p{position_offset}\"\n","                    dest_filename = f\"{sample_id}_{frame_type}_{offset_str}_{emotion}.jpg\"\n","                    dest_path = os.path.join(split_dir, dest_filename)\n","\n","                    try:\n","                        if os.path.exists(source_path):\n","                            shutil.copy2(source_path, dest_path)\n","                            copy_stats[split_name][frame_type] += 1\n","\n","                            # Add to metadata\n","                            metadata_v3[split_name]['samples'].append({\n","                                'sample_id': f\"{sample_id}_{frame_type}_{offset_str}\",\n","                                'original_sample_id': sample_id,\n","                                'frame_type': frame_type,\n","                                'frame_offset': position_offset,\n","                                'key_frame': key_frame,\n","                                'actual_frame': actual_frame,\n","                                'requested_frame': req_frame,\n","                                'is_duplicated': (req_frame != actual_frame),\n","                                'subject': subject,\n","                                'sequence': sequence,\n","                                'emotion': emotion,\n","                                'image_filename': dest_filename\n","                            })\n","                        else:\n","                            copy_errors.append(f\"Source not found: {source_path}\")\n","\n","                    except Exception as e:\n","                        copy_errors.append(f\"Copy error for {sample_id} {frame_type} frame {req_frame}: {str(e)}\")\n","\n","            else:\n","                # Key-frame only extraction for val/test\n","                key_frame = window['key_frame']\n","\n","                if not window['is_available']:\n","                    copy_errors.append(f\"Key frame missing: {sample_id} {frame_type}\")\n","                    continue\n","\n","                # Source path\n","                source_path = os.path.join(\n","                    base_path, 'datasets/raw/CASME2_RAW_selected',\n","                    subject, sequence, f\"img{key_frame}.jpg\"\n","                )\n","\n","                # Destination filename: {sample_id}_{frame_type}_{emotion}.jpg\n","                dest_filename = f\"{sample_id}_{frame_type}_{emotion}.jpg\"\n","                dest_path = os.path.join(split_dir, dest_filename)\n","\n","                try:\n","                    if os.path.exists(source_path):\n","                        shutil.copy2(source_path, dest_path)\n","                        copy_stats[split_name][frame_type] += 1\n","\n","                        # Add to metadata\n","                        metadata_v3[split_name]['samples'].append({\n","                            'sample_id': f\"{sample_id}_{frame_type}\",\n","                            'original_sample_id': sample_id,\n","                            'frame_type': frame_type,\n","                            'key_frame': key_frame,\n","                            'subject': subject,\n","                            'sequence': sequence,\n","                            'emotion': emotion,\n","                            'image_filename': dest_filename\n","                        })\n","                    else:\n","                        copy_errors.append(f\"Source not found: {source_path}\")\n","\n","                except Exception as e:\n","                    copy_errors.append(f\"Copy error for {sample_id} {frame_type}: {str(e)}\")\n","\n","    # Update split statistics\n","    total_frames = sum(copy_stats[split_name].get(ft, 0) for ft in ['onset', 'apex', 'offset'])\n","    metadata_v3[split_name]['count'] = total_frames\n","\n","    if is_train:\n","        print(f\"  ✓ {split_name.upper()} extraction completed:\")\n","        print(f\"    Onset frames: {copy_stats[split_name]['onset']}\")\n","        print(f\"    Apex frames: {copy_stats[split_name]['apex']}\")\n","        print(f\"    Offset frames: {copy_stats[split_name]['offset']}\")\n","        print(f\"    Duplicated frames (fallback): {copy_stats[split_name]['duplicated_frames']}\")\n","        print(f\"    Total: {total_frames} images\")\n","    else:\n","        print(f\"  ✓ {split_name.upper()} extraction completed:\")\n","        print(f\"    Key frames: {total_frames} images ({copy_stats[split_name]['onset']} onset + {copy_stats[split_name]['apex']} apex + {copy_stats[split_name]['offset']} offset)\")\n","\n","# Calculate class distribution per split\n","print(f\"\\n[5] Calculating class distribution for each split...\")\n","\n","for split_name in ['train', 'val', 'test']:\n","    emotion_counts = {}\n","    for sample in metadata_v3[split_name]['samples']:\n","        emotion = sample['emotion']\n","        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n","\n","    metadata_v3[split_name]['class_distribution'] = emotion_counts\n","\n","    print(f\"\\n  {split_name.upper()} set distribution ({metadata_v3[split_name]['count']} images):\")\n","    for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):\n","        percentage = (count / metadata_v3[split_name]['count']) * 100\n","        print(f\"    {emotion}: {count} images ({percentage:.1f}%)\")\n","\n","# Display copy errors if any\n","if copy_errors:\n","    print(f\"\\n[6] Copy Errors Summary:\")\n","    print(f\"  Total errors: {len(copy_errors)}\")\n","    if len(copy_errors) <= 5:\n","        for error in copy_errors:\n","            print(f\"    {error}\")\n","    else:\n","        for error in copy_errors[:5]:\n","            print(f\"    {error}\")\n","        print(f\"    ... and {len(copy_errors) - 5} more errors\")\n","\n","# Save enhanced metadata\n","print(f\"\\n[7] Saving enhanced metadata with frame tracking...\")\n","\n","metadata_file_v3 = f\"{data_split_v3_path}/split_metadata_v3.json\"\n","\n","metadata_export = {\n","    'dataset': 'CASME2_MultiFrameSampling',\n","    'phase': 'Phase 3',\n","    'strategy': {\n","        'train': 'multi_frame_windows',\n","        'val': 'key_frames_only',\n","        'test': 'key_frames_only'\n","    },\n","    'window_configuration': verification_data['window_configuration'],\n","    'creation_date': pd.Timestamp.now().isoformat(),\n","    'splits': metadata_v3\n","}\n","\n","with open(metadata_file_v3, 'w') as f:\n","    json.dump(metadata_export, f, indent=2)\n","\n","print(f\"✓ Enhanced metadata saved to: data_split_v3/split_metadata_v3.json\")\n","\n","# Save processing summary\n","print(f\"\\n[8] Generating processing summary...\")\n","\n","total_copied = sum(sum(stats.get(ft, 0) for ft in ['onset', 'apex', 'offset']) for stats in copy_stats.values())\n","expected_total = verification_data['expected_dataset_sizes']['train']['total_frames'] + \\\n","                 verification_data['expected_dataset_sizes']['val']['total_frames'] + \\\n","                 verification_data['expected_dataset_sizes']['test']['total_frames']\n","\n","processing_summary_v3 = {\n","    'dataset': 'CASME2_MultiFrameSampling',\n","    'phase': 'Phase 3',\n","    'processing_date': pd.Timestamp.now().isoformat(),\n","    'source_phase1_samples': verification_data['statistics']['train']['total_samples'] + \\\n","                            verification_data['statistics']['val']['total_samples'] + \\\n","                            verification_data['statistics']['test']['total_samples'],\n","    'extraction_strategy': {\n","        'train': 'multi_frame_windows_with_fallback',\n","        'val': 'key_frames_only',\n","        'test': 'key_frames_only',\n","        'fallback_method': 'nearest_frame_duplication'\n","    },\n","    'copy_statistics': {\n","        'train': {\n","            'total_images': sum(copy_stats['train'].get(ft, 0) for ft in ['onset', 'apex', 'offset']),\n","            'frame_breakdown': {\n","                'onset': copy_stats['train']['onset'],\n","                'apex': copy_stats['train']['apex'],\n","                'offset': copy_stats['train']['offset']\n","            },\n","            'duplicated_frames': copy_stats['train']['duplicated_frames'],\n","            'duplication_rate': (copy_stats['train']['duplicated_frames'] / sum(copy_stats['train'].get(ft, 0) for ft in ['onset', 'apex', 'offset']) * 100) if sum(copy_stats['train'].get(ft, 0) for ft in ['onset', 'apex', 'offset']) > 0 else 0\n","        },\n","        'val': {\n","            'total_images': sum(copy_stats['val'].get(ft, 0) for ft in ['onset', 'apex', 'offset']),\n","            'frame_breakdown': copy_stats['val']\n","        },\n","        'test': {\n","            'total_images': sum(copy_stats['test'].get(ft, 0) for ft in ['onset', 'apex', 'offset']),\n","            'frame_breakdown': copy_stats['test']\n","        }\n","    },\n","    'total_images_copied': total_copied,\n","    'expected_images': expected_total,\n","    'success_rate': (total_copied / expected_total * 100) if expected_total > 0 else 0,\n","    'copy_errors': len(copy_errors),\n","    'class_preservation': {\n","        'train': metadata_v3['train']['class_distribution'],\n","        'val': metadata_v3['val']['class_distribution'],\n","        'test': metadata_v3['test']['class_distribution']\n","    }\n","}\n","\n","summary_file_v3 = f\"{data_split_v3_path}/processing_summary_v3.json\"\n","\n","with open(summary_file_v3, 'w') as f:\n","    json.dump(processing_summary_v3, f, indent=2)\n","\n","print(f\"✓ Processing summary saved to: data_split_v3/processing_summary_v3.json\")\n","\n","# Final validation\n","print(f\"\\n[9] Final validation of data_split_v3 structure...\")\n","\n","validation_results = {}\n","frame_types = ['onset', 'apex', 'offset']\n","\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_v3_path}/{split_name}\"\n","\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir)\n","                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","        # Count by frame type\n","        frame_counts = {'onset': 0, 'apex': 0, 'offset': 0}\n","        for img_file in image_files:\n","            for frame_type in frame_types:\n","                if f\"_{frame_type}_\" in img_file:\n","                    frame_counts[frame_type] += 1\n","                    break\n","\n","        validation_results[split_name] = {\n","            'directory_exists': True,\n","            'total_images': len(image_files),\n","            'frame_breakdown': frame_counts,\n","            'sample_files': image_files[:3]\n","        }\n","    else:\n","        validation_results[split_name] = {\n","            'directory_exists': False,\n","            'total_images': 0,\n","            'frame_breakdown': {},\n","            'sample_files': []\n","        }\n","\n","print(f\"✓ Structure validation:\")\n","for split_name, results in validation_results.items():\n","    status = \"✓\" if results['directory_exists'] and results['total_images'] > 0 else \"✗\"\n","    print(f\"  {status} {split_name}: {results['total_images']} images\")\n","    if results['frame_breakdown']:\n","        print(f\"    Onset: {results['frame_breakdown']['onset']}, \"\n","              f\"Apex: {results['frame_breakdown']['apex']}, \"\n","              f\"Offset: {results['frame_breakdown']['offset']}\")\n","    if results['sample_files']:\n","        print(f\"    Sample: {results['sample_files'][0]}\")\n","\n","# Final summary\n","print(f\"\\n\" + \"=\" * 75)\n","print(\"PHASE 3 MULTI-FRAME DATASET PREPARATION SUMMARY\")\n","print(\"=\" * 75)\n","\n","success_rate = processing_summary_v3['success_rate']\n","status = \"SUCCESS\" if success_rate >= 99 else \"PARTIAL\"\n","\n","print(f\"Processing Status: {status}\")\n","print(f\"Total images copied: {total_copied}/{expected_total} ({success_rate:.1f}%)\")\n","print(f\"Dataset composition: Multi-frame train + Key-frame val/test\")\n","\n","print(f\"\\n✓ Split distribution:\")\n","print(f\"  TRAIN (Multi-Frame):\")\n","print(f\"    Samples: {verification_data['statistics']['train']['total_samples']}\")\n","print(f\"    Total frames: {sum(copy_stats['train'].get(ft, 0) for ft in ['onset', 'apex', 'offset'])}\")\n","print(f\"    Breakdown: {copy_stats['train']['onset']} onset + {copy_stats['train']['apex']} apex + {copy_stats['train']['offset']} offset\")\n","print(f\"    Duplicated frames: {copy_stats['train']['duplicated_frames']} ({processing_summary_v3['copy_statistics']['train']['duplication_rate']:.2f}%)\")\n","print(f\"\\n  VAL (Key-Frames):\")\n","print(f\"    Samples: {verification_data['statistics']['val']['total_samples']}\")\n","print(f\"    Total frames: {sum(copy_stats['val'].get(ft, 0) for ft in ['onset', 'apex', 'offset'])} (3 per sample)\")\n","print(f\"\\n  TEST (Key-Frames):\")\n","print(f\"    Samples: {verification_data['statistics']['test']['total_samples']}\")\n","print(f\"    Total frames: {sum(copy_stats['test'].get(ft, 0) for ft in ['onset', 'apex', 'offset'])} (3 per sample)\")\n","\n","print(f\"\\n✓ Data quality:\")\n","print(f\"  Fallback strategy applied: {copy_stats['train']['duplicated_frames']} frames duplicated\")\n","print(f\"  Duplication rate: {processing_summary_v3['copy_statistics']['train']['duplication_rate']:.2f}% (acceptable threshold)\")\n","print(f\"  Copy errors: {len(copy_errors)}\")\n","print(f\"  Split consistency: Maintained from Phase 1\")\n","\n","print(f\"\\n✓ Output files:\")\n","print(f\"  - Dataset: data_split_v3/train|val|test/\")\n","print(f\"  - Metadata: data_split_v3/split_metadata_v3.json\")\n","print(f\"  - Summary: data_split_v3/processing_summary_v3.json\")\n","\n","print(f\"\\n✓ Next steps:\")\n","print(f\"  - Phase 3 dataset ready for model training with temporal augmentation\")\n","print(f\"  - Train: 13 frames per sample (onset×4 + apex×5 + offset×4)\")\n","print(f\"  - Val/Test: 3 key frames per sample for fair evaluation\")\n","print(f\"  - Proceed to Phase 3 model experiments with multi-frame input\")\n","\n","print(\"=\" * 75)"],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H_bxWFEmhFbB","executionInfo":{"status":"ok","timestamp":1759151627708,"user_tz":-420,"elapsed":1519421,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"fe926144-ffd5-4407-c335-47c7681c6840"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["===========================================================================\n","CASME II MULTI-FRAME SAMPLING DATASET PREPARATION - PHASE 3\n","===========================================================================\n","\n","[1] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","\n","[2] Setting up Phase 3 directory structure...\n","Target: data_split_v3 (Multi-Frame for Train, Key-Frames for Val/Test)\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v3/train\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v3/val\n","✓ Created directory: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split_v3/test\n","\n","[3] Loading verification results from Cell 1...\n","✓ Verification data loaded\n","  Strategy: Train=Multi-frame, Val/Test=Key-frames\n","  Train samples: 201\n","  Expected train frames: 2603\n","  Problematic samples: 5\n","\n","[4] Extracting multi-frame sequences with fallback strategy...\n","Fallback: Missing frames will use nearest available frame (duplication)\n","\n","  Processing TRAIN set (201 samples)...\n","  ✓ TRAIN extraction completed:\n","    Onset frames: 804\n","    Apex frames: 1005\n","    Offset frames: 804\n","    Duplicated frames (fallback): 10\n","    Total: 2613 images\n","\n","  Processing VAL set (26 samples)...\n","  ✓ VAL extraction completed:\n","    Key frames: 78 images (26 onset + 26 apex + 26 offset)\n","\n","  Processing TEST set (28 samples)...\n","  ✓ TEST extraction completed:\n","    Key frames: 83 images (28 onset + 28 apex + 27 offset)\n","\n","[5] Calculating class distribution for each split...\n","\n","  TRAIN set distribution (2613 images):\n","    others: 1027 images (39.3%)\n","    disgust: 650 images (24.9%)\n","    happiness: 325 images (12.4%)\n","    repression: 273 images (10.4%)\n","    surprise: 260 images (10.0%)\n","    sadness: 65 images (2.5%)\n","    fear: 13 images (0.5%)\n","\n","  VAL set distribution (78 images):\n","    others: 30 images (38.5%)\n","    disgust: 18 images (23.1%)\n","    happiness: 9 images (11.5%)\n","    repression: 9 images (11.5%)\n","    surprise: 6 images (7.7%)\n","    sadness: 3 images (3.8%)\n","    fear: 3 images (3.8%)\n","\n","  TEST set distribution (83 images):\n","    others: 30 images (36.1%)\n","    disgust: 21 images (25.3%)\n","    happiness: 12 images (14.5%)\n","    surprise: 9 images (10.8%)\n","    repression: 8 images (9.6%)\n","    sadness: 3 images (3.6%)\n","\n","[6] Copy Errors Summary:\n","  Total errors: 1\n","    Key frame missing: sub16_EP01_08 offset\n","\n","[7] Saving enhanced metadata with frame tracking...\n","✓ Enhanced metadata saved to: data_split_v3/split_metadata_v3.json\n","\n","[8] Generating processing summary...\n","✓ Processing summary saved to: data_split_v3/processing_summary_v3.json\n","\n","[9] Final validation of data_split_v3 structure...\n","✓ Structure validation:\n","  ✓ train: 2613 images\n","    Onset: 804, Apex: 1005, Offset: 804\n","    Sample: sub11_EP02_06f_onset_p+0_others.jpg\n","  ✓ val: 78 images\n","    Onset: 26, Apex: 26, Offset: 26\n","    Sample: sub06_EP10_08_onset_others.jpg\n","  ✓ test: 83 images\n","    Onset: 28, Apex: 28, Offset: 27\n","    Sample: sub14_EP04_04f_onset_others.jpg\n","\n","===========================================================================\n","PHASE 3 MULTI-FRAME DATASET PREPARATION SUMMARY\n","===========================================================================\n","Processing Status: SUCCESS\n","Total images copied: 2774/2764 (100.4%)\n","Dataset composition: Multi-frame train + Key-frame val/test\n","\n","✓ Split distribution:\n","  TRAIN (Multi-Frame):\n","    Samples: 201\n","    Total frames: 2613\n","    Breakdown: 804 onset + 1005 apex + 804 offset\n","    Duplicated frames: 10 (0.38%)\n","\n","  VAL (Key-Frames):\n","    Samples: 26\n","    Total frames: 78 (3 per sample)\n","\n","  TEST (Key-Frames):\n","    Samples: 28\n","    Total frames: 83 (3 per sample)\n","\n","✓ Data quality:\n","  Fallback strategy applied: 10 frames duplicated\n","  Duplication rate: 0.38% (acceptable threshold)\n","  Copy errors: 1\n","  Split consistency: Maintained from Phase 1\n","\n","✓ Output files:\n","  - Dataset: data_split_v3/train|val|test/\n","  - Metadata: data_split_v3/split_metadata_v3.json\n","  - Summary: data_split_v3/processing_summary_v3.json\n","\n","✓ Next steps:\n","  - Phase 3 dataset ready for model training with temporal augmentation\n","  - Train: 13 frames per sample (onset×4 + apex×5 + offset×4)\n","  - Val/Test: 3 key frames per sample for fair evaluation\n","  - Proceed to Phase 3 model experiments with multi-frame input\n","===========================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 3: CASME II Multi-Frame Sampling Visualization\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Professional visualization setup\n","plt.style.use('default')\n","plt.rcParams.update({\n","    'font.family': 'DejaVu Sans',\n","    'font.size': 12,\n","    'axes.titlesize': 16,\n","    'axes.labelsize': 14,\n","    'xtick.labelsize': 12,\n","    'ytick.labelsize': 12,\n","    'legend.fontsize': 11,\n","    'figure.titlesize': 18,\n","    'axes.spines.top': False,\n","    'axes.spines.right': False,\n","    'axes.grid': False,\n","    'figure.facecolor': 'white',\n","    'axes.facecolor': 'white'\n","})\n","\n","def convert_to_serializable(obj):\n","    \"\"\"Convert numpy/pandas types to native Python types for JSON serialization\"\"\"\n","    if isinstance(obj, dict):\n","        return {key: convert_to_serializable(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_serializable(item) for item in obj]\n","    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif pd.isna(obj):\n","        return None\n","    else:\n","        return obj\n","\n","# Color palettes\n","EMOTION_COLORS = {\n","    'others': '#1f77b4',\n","    'disgust': '#d62728',\n","    'happiness': '#2ca02c',\n","    'repression': '#9467bd',\n","    'surprise': '#ff7f0e',\n","    'sadness': '#8c564b',\n","    'fear': '#e377c2'\n","}\n","\n","SPLIT_COLORS = {\n","    'raw': '#1f77b4',\n","    'train': '#ff7f0e',\n","    'val': '#d62728',\n","    'test': '#2ca02c'\n","}\n","\n","print(\"=\" * 80)\n","print(\"CASME II MULTI-FRAME SAMPLING VISUALIZATION - PHASE 3\")\n","print(\"=\" * 80)\n","\n","print(\"\\n[1] Environment setup and drive mounting...\")\n","drive.mount('/content/drive')\n","print(\"✓ Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","metadata_path = f\"{base_path}/datasets/metadata/CASME2-coding-20140508.xlsx\"\n","data_split_v3_path = f\"{base_path}/datasets/processed_casme2/data_split_v3\"\n","split_metadata_v3_path = f\"{data_split_v3_path}/split_metadata_v3.json\"\n","visualization_path = f\"{base_path}/datasets/visualization/03_casme2-mfs\"\n","\n","os.makedirs(visualization_path, exist_ok=True)\n","print(f\"✓ Output directory created: {visualization_path}\")\n","\n","print(\"\\n[2] Loading raw metadata and Phase 3 data...\")\n","\n","# Load raw metadata for comparison\n","try:\n","    raw_metadata = pd.read_excel(metadata_path)\n","    if raw_metadata['ApexFrame'].dtype == 'object':\n","        raw_metadata['ApexFrame'] = pd.to_numeric(raw_metadata['ApexFrame'], errors='coerce')\n","    print(f\"✓ Raw metadata loaded: {len(raw_metadata)} samples\")\n","except Exception as e:\n","    print(f\"✗ Error loading raw metadata: {str(e)}\")\n","    exit()\n","\n","# Load Phase 3 metadata\n","try:\n","    with open(split_metadata_v3_path, 'r') as f:\n","        metadata_v3 = json.load(f)\n","\n","    print(f\"✓ Phase 3 metadata loaded\")\n","    print(f\"  Dataset: {metadata_v3['dataset']}\")\n","    print(f\"  Strategy: Train={metadata_v3['strategy']['train']}, Val/Test={metadata_v3['strategy']['val']}\")\n","\n","except Exception as e:\n","    print(f\"✗ Error loading metadata: {str(e)}\")\n","    exit()\n","\n","print(\"\\n[3] File integrity validation...\")\n","\n","splits_info = metadata_v3['splits']\n","total_actual_files = 0\n","\n","for split_name in ['train', 'val', 'test']:\n","    split_dir = f\"{data_split_v3_path}/{split_name}\"\n","    if os.path.exists(split_dir):\n","        image_files = [f for f in os.listdir(split_dir)\n","                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","        actual_count = len(image_files)\n","        expected_count = splits_info[split_name]['count']\n","        total_actual_files += actual_count\n","        status = '✓' if actual_count == expected_count else '✗'\n","        print(f\"  {status} {split_name.upper()}: {actual_count}/{expected_count} images\")\n","\n","print(f\"✓ Total validated files: {total_actual_files}\")\n","\n","print(\"\\n[4] Preparing visualization data...\")\n","\n","# Extract raw emotion distribution (multiply by 3 for frame comparison)\n","raw_emotion_dist = raw_metadata['Estimated Emotion'].value_counts()\n","\n","# Extract class distributions per split\n","split_data = {}\n","for split_name in ['train', 'val', 'test']:\n","    split_data[split_name] = splits_info[split_name]['class_distribution']\n","\n","# Get all unique emotions sorted by raw distribution (highest to lowest)\n","all_emotions = raw_emotion_dist.index.tolist()\n","\n","print(f\"✓ Data preparation complete\")\n","print(f\"  Emotion classes: {len(all_emotions)}\")\n","print(f\"  Raw samples: {len(raw_metadata)}\")\n","print(f\"  Total Phase 3 images: {total_actual_files}\")\n","\n","print(\"\\n[5] Generating File 1: Multi-Frame vs Key-Frame Distribution Comparison...\")\n","\n","fig1, ax1 = plt.subplots(1, 1, figsize=(16, 9))\n","\n","# Prepare data aligned with emotion order\n","# Raw counts multiplied by 3 to show potential frames\n","raw_counts = [raw_emotion_dist.get(emotion, 0) * 3 for emotion in all_emotions]\n","train_counts = [split_data['train'].get(emotion, 0) for emotion in all_emotions]\n","val_counts = [split_data['val'].get(emotion, 0) for emotion in all_emotions]\n","test_counts = [split_data['test'].get(emotion, 0) for emotion in all_emotions]\n","\n","x = np.arange(len(all_emotions))\n","width = 0.2\n","\n","# Create grouped bars with raw dataset included\n","bars0 = ax1.bar(x - width*1.5, raw_counts, width, label='Raw Dataset (Key Frames)',\n","                color=SPLIT_COLORS['raw'], alpha=0.85)\n","bars1 = ax1.bar(x - width/2, train_counts, width, label='Train Split (Multi Frame)',\n","                color=SPLIT_COLORS['train'], alpha=0.85)\n","bars2 = ax1.bar(x + width/2, val_counts, width, label='Validation Split (Key Frames)',\n","                color=SPLIT_COLORS['val'], alpha=0.85)\n","bars3 = ax1.bar(x + width*1.5, test_counts, width, label='Test Split (Key Frames)',\n","                color=SPLIT_COLORS['test'], alpha=0.85)\n","\n","ax1.set_title('CASME II Multi-Frame Sampling Distribution - Phase 3\\nTrain: Multi-Frame Windows | Val/Test: Key Frames',\n","              fontsize=18, fontweight='bold', pad=25)\n","ax1.set_xlabel('Emotion Classes (Sorted by Frequency)', fontsize=16, labelpad=20)\n","ax1.set_ylabel('Image Count', fontsize=16, labelpad=20)\n","ax1.set_xticks(x)\n","ax1.set_xticklabels(all_emotions, rotation=0)\n","\n","# Add legend with window info\n","legend_labels = [\n","    'Raw Dataset (Key Frames)',\n","    'Train Split (Multi Frame)\\nOnset: +[0,1,2,3] | Apex: [-2,-1,0,1,2] | Offset: [-3,-2,-1,0]',\n","    'Validation Split (Key Frames)',\n","    'Test Split (Key Frames)'\n","]\n","handles = [bars0, bars1, bars2, bars3]\n","ax1.legend(handles, legend_labels, loc='upper right', fontsize=10)\n","ax1.grid(False)\n","\n","# Add value labels on bars\n","all_bars_data = [(bars0, raw_counts), (bars1, train_counts), (bars2, val_counts), (bars3, test_counts)]\n","for bars, values in all_bars_data:\n","    for bar, value in zip(bars, values):\n","        if value > 0:\n","            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n","                    str(value), ha='center', va='bottom', fontsize=9,\n","                    fontweight='bold')\n","\n","plt.tight_layout()\n","file1_path = f\"{visualization_path}/1_multiframe_split_distribution.png\"\n","plt.savefig(file1_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"✓ File 1 saved: 1_multiframe_split_distribution.png\")\n","\n","print(\"\\n[6] Generating File 2: Multi-Frame Statistical Analysis Table...\")\n","\n","fig2 = plt.figure(figsize=(18, 10))\n","ax2 = fig2.add_subplot(1, 1, 1)\n","ax2.axis('off')\n","\n","# Prepare table data\n","table_data = []\n","total_raw = 0\n","total_train = 0\n","total_val = 0\n","total_test = 0\n","\n","for emotion in all_emotions:\n","    raw_count = raw_emotion_dist.get(emotion, 0)\n","    train_count = split_data['train'].get(emotion, 0)\n","    val_count = split_data['val'].get(emotion, 0)\n","    test_count = split_data['test'].get(emotion, 0)\n","\n","    # Calculate original samples from train multi-frame count\n","    # Each sample has 13 frames total, but distribution varies\n","    # Use raw count as reference\n","    train_samples = raw_count * 0.788  # approximate train split ratio\n","\n","    # Calculate raw percentage\n","    raw_percentage = (raw_count / len(raw_metadata)) * 100\n","\n","    # Calculate expansion factor for train\n","    expansion_factor = f\"{train_count / (raw_count * 3) * 100:.0f}%\" if raw_count > 0 else \"N/A\"\n","\n","    # Calculate imbalance ratio\n","    max_count = raw_emotion_dist.max()\n","    imbalance_ratio = f\"{max_count / raw_count:.1f}:1\" if raw_count > 0 else \"∞:1\"\n","\n","    table_data.append([\n","        emotion.title(),\n","        raw_count,\n","        f\"{raw_percentage:.1f}%\",\n","        train_count,\n","        val_count,\n","        test_count,\n","        train_count + val_count + test_count,\n","        expansion_factor,\n","        imbalance_ratio\n","    ])\n","\n","    total_raw += raw_count\n","    total_train += train_count\n","    total_val += val_count\n","    total_test += test_count\n","\n","# Add total row\n","total_all = total_train + total_val + total_test\n","\n","table_data.append([\n","    'TOTAL',\n","    total_raw,\n","    '100.0%',\n","    total_train,\n","    total_val,\n","    total_test,\n","    total_all,\n","    f\"{total_all / (total_raw * 3) * 100:.0f}%\",\n","    '1.0:1'\n","])\n","\n","# Convert to display format\n","table_display_data = []\n","for row in table_data:\n","    display_row = [\n","        row[0],  # emotion\n","        f\"{row[1]:,}\",  # raw samples\n","        row[2],  # raw percentage\n","        f\"{row[3]:,}\",  # train images\n","        f\"{row[4]:,}\",  # val images\n","        f\"{row[5]:,}\",  # test images\n","        f\"{row[6]:,}\",  # total images\n","        row[7],  # expansion\n","        row[8]   # imbalance\n","    ]\n","    table_display_data.append(display_row)\n","\n","# Create table\n","table = ax2.table(\n","    cellText=table_display_data,\n","    colLabels=['Emotion', 'Raw\\nSamples', 'Raw %', 'Train\\nImages\\n(Multi-Frame)', 'Val\\nImages\\n(Key-Frame)',\n","               'Test\\nImages\\n(Key-Frame)', 'Total\\nImages', 'Train\\nExpansion', 'Imbalance'],\n","    cellLoc='center',\n","    loc='center',\n","    colWidths=[0.10, 0.09, 0.08, 0.12, 0.10, 0.10, 0.09, 0.09, 0.09]\n",")\n","\n","table.auto_set_font_size(False)\n","table.set_fontsize(11)\n","table.scale(1, 2.8)\n","\n","# Professional table styling\n","num_rows = len(table_display_data)\n","for i in range(num_rows + 1):\n","    for j in range(9):\n","        cell = table[(i, j)]\n","        if i == 0:  # Header\n","            cell.set_facecolor('#1f77b4')\n","            cell.set_text_props(weight='bold', color='white')\n","        elif i == num_rows:  # Total row\n","            cell.set_facecolor('#f0f0f0')\n","            cell.set_text_props(weight='bold')\n","        else:\n","            emotion = table_display_data[i-1][0].lower()\n","            if emotion in ['fear', 'sadness']:\n","                cell.set_facecolor('#ffe6e6')\n","            else:\n","                cell.set_facecolor('#ffffff')\n","\n","ax2.set_title('CASME II Multi-Frame Sampling Statistical Analysis (Phase 3)\\n' +\n","              'Train: Onset [+0,+1,+2,+3] + Apex [-2,-1,0,+1,+2] + Offset [-3,-2,-1,0] = 13 frames/sample\\n' +\n","              'Val/Test: Key-Frames Only (Onset + Apex + Offset = 3 frames/sample)',\n","              fontsize=16, fontweight='bold', pad=40)\n","\n","plt.tight_layout()\n","file2_path = f\"{visualization_path}/2_multiframe_statistical_table.png\"\n","plt.savefig(file2_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"✓ File 2 saved: 2_multiframe_statistical_table.png\")\n","\n","print(\"\\n[7] Generating visualization metadata...\")\n","\n","# Calculate totals for metadata\n","total_samples = len(raw_metadata)\n","total_images_all = total_train + total_val + total_test\n","\n","# Generate comprehensive metadata\n","analysis_metadata = {\n","    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n","    'phase': 'Phase 3 - Multi-Frame Sampling',\n","    'dataset_info': {\n","        'name': 'CASME II Multi-Frame Sampling Dataset',\n","        'extraction_strategy': 'train_multi_frame_val_test_keyframes',\n","        'original_samples': total_samples,\n","        'total_images': total_images_all,\n","        'window_configuration': {\n","            'onset': 'forward_window_+[0,1,2,3]',\n","            'apex': 'centered_window_[-2,-1,0,1,2]',\n","            'offset': 'backward_window_[-3,-2,-1,0]'\n","        },\n","        'emotion_classes': len(all_emotions)\n","    },\n","    'split_distribution': convert_to_serializable({\n","        'train': {\n","            'strategy': 'multi_frame_windows',\n","            'total_images': total_train,\n","            'original_samples': splits_info['train']['count'] // 13,  # approximate\n","            'frames_per_sample': 13,\n","            'class_distribution': split_data['train']\n","        },\n","        'validation': {\n","            'strategy': 'key_frames_only',\n","            'total_images': total_val,\n","            'original_samples': total_val // 3,\n","            'frames_per_sample': 3,\n","            'class_distribution': split_data['val']\n","        },\n","        'test': {\n","            'strategy': 'key_frames_only',\n","            'total_images': total_test,\n","            'original_samples': total_test // 3,\n","            'frames_per_sample': 3,\n","            'class_distribution': split_data['test']\n","        }\n","    }),\n","    'visualization_files': {\n","        'split_distribution': '1_multiframe_split_distribution.png',\n","        'statistical_table': '2_multiframe_statistical_table.png'\n","    },\n","    'color_scheme': {\n","        'emotion_colors': EMOTION_COLORS,\n","        'split_colors': SPLIT_COLORS\n","    }\n","}\n","\n","metadata_file = f\"{visualization_path}/multiframe_visualization_metadata.json\"\n","with open(metadata_file, 'w') as f:\n","    json.dump(analysis_metadata, f, indent=2)\n","\n","print(f\"✓ Metadata saved: multiframe_visualization_metadata.json\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"MULTI-FRAME SAMPLING VISUALIZATION COMPLETE - PHASE 3\")\n","print(\"=\" * 80)\n","print(f\"Status: SUCCESS\")\n","print(f\"Total images validated: {total_actual_files}\")\n","print(f\"Output location: {visualization_path}\")\n","\n","print(\"\\nGenerated files:\")\n","print(\"  • 1_multiframe_split_distribution.png - Multi-frame vs key-frame comparison\")\n","print(\"  • 2_multiframe_statistical_table.png - Statistical analysis with expansion info\")\n","print(\"  • multiframe_visualization_metadata.json - Comprehensive metadata\")\n","\n","print(\"\\nDataset Summary:\")\n","print(f\"  Original samples: {total_samples}\")\n","print(f\"  Total images (Phase 3): {total_images_all}\")\n","print(f\"  Train: {total_train} images (multi-frame windows)\")\n","print(f\"  Val: {total_val} images (key-frames)\")\n","print(f\"  Test: {total_test} images (key-frames)\")\n","\n","print(\"\\nWindow Configuration:\")\n","print(f\"  Train multi-frame strategy:\")\n","print(f\"    • Onset: +[0,1,2,3] = 4 frames per sample\")\n","print(f\"    • Apex: [-2,-1,0,1,2] = 5 frames per sample\")\n","print(f\"    • Offset: [-3,-2,-1,0] = 4 frames per sample\")\n","print(f\"    • Total: 13 frames per training sample\")\n","print(f\"  Val/Test key-frame strategy:\")\n","print(f\"    • 3 frames per sample (onset, apex, offset)\")\n","\n","print(\"\\n✓ Phase 3 visualization ready for thesis documentation\")\n","print(\"=\" * 80)"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"dhQwsqw1oeG8","executionInfo":{"status":"ok","timestamp":1759153028084,"user_tz":-420,"elapsed":6921,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"f31c9c23-f1f5-4238-d2c5-286d39c99a03"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CASME II MULTI-FRAME SAMPLING VISUALIZATION - PHASE 3\n","================================================================================\n","\n","[1] Environment setup and drive mounting...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted successfully\n","✓ Output directory created: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/03_casme2-mfs\n","\n","[2] Loading raw metadata and Phase 3 data...\n","✓ Raw metadata loaded: 255 samples\n","✓ Phase 3 metadata loaded\n","  Dataset: CASME2_MultiFrameSampling\n","  Strategy: Train=multi_frame_windows, Val/Test=key_frames_only\n","\n","[3] File integrity validation...\n","  ✓ TRAIN: 2613/2613 images\n","  ✓ VAL: 78/78 images\n","  ✓ TEST: 83/83 images\n","✓ Total validated files: 2774\n","\n","[4] Preparing visualization data...\n","✓ Data preparation complete\n","  Emotion classes: 7\n","  Raw samples: 255\n","  Total Phase 3 images: 2774\n","\n","[5] Generating File 1: Multi-Frame vs Key-Frame Distribution Comparison...\n","✓ File 1 saved: 1_multiframe_split_distribution.png\n","\n","[6] Generating File 2: Multi-Frame Statistical Analysis Table...\n","✓ File 2 saved: 2_multiframe_statistical_table.png\n","\n","[7] Generating visualization metadata...\n","✓ Metadata saved: multiframe_visualization_metadata.json\n","\n","================================================================================\n","MULTI-FRAME SAMPLING VISUALIZATION COMPLETE - PHASE 3\n","================================================================================\n","Status: SUCCESS\n","Total images validated: 2774\n","Output location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/03_casme2-mfs\n","\n","Generated files:\n","  • 1_multiframe_split_distribution.png - Multi-frame vs key-frame comparison\n","  • 2_multiframe_statistical_table.png - Statistical analysis with expansion info\n","  • multiframe_visualization_metadata.json - Comprehensive metadata\n","\n","Dataset Summary:\n","  Original samples: 255\n","  Total images (Phase 3): 2774\n","  Train: 2613 images (multi-frame windows)\n","  Val: 78 images (key-frames)\n","  Test: 83 images (key-frames)\n","\n","Window Configuration:\n","  Train multi-frame strategy:\n","    • Onset: +[0,1,2,3] = 4 frames per sample\n","    • Apex: [-2,-1,0,1,2] = 5 frames per sample\n","    • Offset: [-3,-2,-1,0] = 4 frames per sample\n","    • Total: 13 frames per training sample\n","  Val/Test key-frame strategy:\n","    • 3 frames per sample (onset, apex, offset)\n","\n","✓ Phase 3 visualization ready for thesis documentation\n","================================================================================\n"]}]}]}