{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyPJu/rtASuU5rqeztFwjWQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"79a16062a30c404b9cbd3205d82712e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c74891cb09a47c0b5511479a19a8e5a","IPY_MODEL_43c5e971cab84be9a460295205e75331","IPY_MODEL_7a248e5a114d46879831ca8b1adcfe96"],"layout":"IPY_MODEL_e00872d9892b4a579dfa5482d31787c3"}},"8c74891cb09a47c0b5511479a19a8e5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea7065b0c94489786040598625fa38a","placeholder":"​","style":"IPY_MODEL_958b25a9346d4f0f9e4d2e08691abdc8","value":"Fetching 1 files: 100%"}},"43c5e971cab84be9a460295205e75331":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31690da89d0842618fe6868bd251cc3f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84989042e7a4458ac5f55d71ae3f60d","value":1}},"7a248e5a114d46879831ca8b1adcfe96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4febd55e2eb84dc6b7537e18627de1c8","placeholder":"​","style":"IPY_MODEL_5a2699d4948f4c4abb33e806dcce5501","value":" 1/1 [00:00&lt;00:00,  3.50it/s]"}},"e00872d9892b4a579dfa5482d31787c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea7065b0c94489786040598625fa38a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958b25a9346d4f0f9e4d2e08691abdc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31690da89d0842618fe6868bd251cc3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84989042e7a4458ac5f55d71ae3f60d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4febd55e2eb84dc6b7537e18627de1c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a2699d4948f4c4abb33e806dcce5501":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6934b1953f144e27b35367a62149cc83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26a0400e754f4005bd1483549b55e47b","IPY_MODEL_15d8fdc254964e06905be28593f47736","IPY_MODEL_457bf45ecbf84521b854fe101058f81a"],"layout":"IPY_MODEL_1492e049089043aeb8996bfe30e0d3dc"}},"26a0400e754f4005bd1483549b55e47b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d75da361e4ef48f8b8ceaf85ec41e858","placeholder":"​","style":"IPY_MODEL_778d90c5d3e34474ad42408b55005854","value":"preprocessor_config.json: 100%"}},"15d8fdc254964e06905be28593f47736":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24447eb620f6431497e73cdc24085a6d","max":287,"min":0,"orientation":"horizontal","style":"IPY_MODEL_febf4d8353b14d4dbabf8edc0c82ffdc","value":287}},"457bf45ecbf84521b854fe101058f81a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6776be3d207644a8a0d083d19e21c0ee","placeholder":"​","style":"IPY_MODEL_4cd742a9bf6042b7b88ae0a500431798","value":" 287/287 [00:00&lt;00:00, 38.0kB/s]"}},"1492e049089043aeb8996bfe30e0d3dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d75da361e4ef48f8b8ceaf85ec41e858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"778d90c5d3e34474ad42408b55005854":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24447eb620f6431497e73cdc24085a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"febf4d8353b14d4dbabf8edc0c82ffdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6776be3d207644a8a0d083d19e21c0ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cd742a9bf6042b7b88ae0a500431798":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89da40819c024fbda71d0143a27dff78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65d7d09f427244fcbad8e56ee762d340","IPY_MODEL_4d2fd751f4ef46b895c251cae286866b","IPY_MODEL_803beda81c404d37b33f5984516bc5e6"],"layout":"IPY_MODEL_eeafca9f08b34930a346f6f452ba354f"}},"65d7d09f427244fcbad8e56ee762d340":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99b92e9314724e999ac0d6657daa45e5","placeholder":"​","style":"IPY_MODEL_bbd7190dfcf743e9b2a2603da3038b1c","value":"config.json: "}},"4d2fd751f4ef46b895c251cae286866b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab64a6d04234c888bf2dd5787d5f8a0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0523999f0efc4bde94be536a076485db","value":1}},"803beda81c404d37b33f5984516bc5e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e119d33fae8454684065aa973dcddbb","placeholder":"​","style":"IPY_MODEL_083e166e3e7343a7a15708734e9025f4","value":" 69.6k/? [00:00&lt;00:00, 8.06MB/s]"}},"eeafca9f08b34930a346f6f452ba354f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99b92e9314724e999ac0d6657daa45e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbd7190dfcf743e9b2a2603da3038b1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ab64a6d04234c888bf2dd5787d5f8a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0523999f0efc4bde94be536a076485db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e119d33fae8454684065aa973dcddbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"083e166e3e7343a7a15708734e9025f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d98ca3927d4b1ea56a8713bb937cf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_518026b7577a4b1f9f287401b23601fa","IPY_MODEL_732e29078e764b4ba921bb3c12c74d37","IPY_MODEL_962d816edbca4135afea7f9d318293f0"],"layout":"IPY_MODEL_528045887749429b9f56e42c040b7b24"}},"518026b7577a4b1f9f287401b23601fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f26e09d18efe4e01826b2be083d7f303","placeholder":"​","style":"IPY_MODEL_a3ea24d58e624bba9205640d5cd555f5","value":"pytorch_model.bin: 100%"}},"732e29078e764b4ba921bb3c12c74d37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5030bb569d46467b8777627319164bfa","max":349435207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ec4fe930bc34dc59c1be032e2554501","value":349435207}},"962d816edbca4135afea7f9d318293f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a6edef779934fdaa22880e14c365db3","placeholder":"​","style":"IPY_MODEL_269124a117ff4fe5a93e71f1d1d6afe4","value":" 349M/349M [00:02&lt;00:00, 225MB/s]"}},"528045887749429b9f56e42c040b7b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26e09d18efe4e01826b2be083d7f303":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3ea24d58e624bba9205640d5cd555f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5030bb569d46467b8777627319164bfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec4fe930bc34dc59c1be032e2554501":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a6edef779934fdaa22880e14c365db3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"269124a117ff4fe5a93e71f1d1d6afe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"075f09cb27764dabb07ea14a14f2c0d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d44f8b40a02049b0a164fe0324dd3a28","IPY_MODEL_69b02d2cbea047bca8fc3c6e3acad99f","IPY_MODEL_f4b18d8bc88747b7894f700e0a10dd6f"],"layout":"IPY_MODEL_82a594e6d47c4b79bc76f8a4cde71b20"}},"d44f8b40a02049b0a164fe0324dd3a28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c44bc8abe65492d976e8738a58ca272","placeholder":"​","style":"IPY_MODEL_e1ddac9001f5432ea93f309b913271db","value":"model.safetensors: 100%"}},"69b02d2cbea047bca8fc3c6e3acad99f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f81cf668db4f4943b4c9ee6735c53335","max":349376512,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04d935723bf249d5889fd550f00af45f","value":349376512}},"f4b18d8bc88747b7894f700e0a10dd6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47a8bf14868f444e992d9d00412f829a","placeholder":"​","style":"IPY_MODEL_68d711b8fc5b4047a3a465da6250aca1","value":" 349M/349M [00:01&lt;00:00, 339MB/s]"}},"82a594e6d47c4b79bc76f8a4cde71b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c44bc8abe65492d976e8738a58ca272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ddac9001f5432ea93f309b913271db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f81cf668db4f4943b4c9ee6735c53335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d935723bf249d5889fd550f00af45f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47a8bf14868f444e992d9d00412f829a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68d711b8fc5b4047a3a465da6250aca1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["79a16062a30c404b9cbd3205d82712e1","8c74891cb09a47c0b5511479a19a8e5a","43c5e971cab84be9a460295205e75331","7a248e5a114d46879831ca8b1adcfe96","e00872d9892b4a579dfa5482d31787c3","7ea7065b0c94489786040598625fa38a","958b25a9346d4f0f9e4d2e08691abdc8","31690da89d0842618fe6868bd251cc3f","c84989042e7a4458ac5f55d71ae3f60d","4febd55e2eb84dc6b7537e18627de1c8","5a2699d4948f4c4abb33e806dcce5501","6934b1953f144e27b35367a62149cc83","26a0400e754f4005bd1483549b55e47b","15d8fdc254964e06905be28593f47736","457bf45ecbf84521b854fe101058f81a","1492e049089043aeb8996bfe30e0d3dc","d75da361e4ef48f8b8ceaf85ec41e858","778d90c5d3e34474ad42408b55005854","24447eb620f6431497e73cdc24085a6d","febf4d8353b14d4dbabf8edc0c82ffdc","6776be3d207644a8a0d083d19e21c0ee","4cd742a9bf6042b7b88ae0a500431798","89da40819c024fbda71d0143a27dff78","65d7d09f427244fcbad8e56ee762d340","4d2fd751f4ef46b895c251cae286866b","803beda81c404d37b33f5984516bc5e6","eeafca9f08b34930a346f6f452ba354f","99b92e9314724e999ac0d6657daa45e5","bbd7190dfcf743e9b2a2603da3038b1c","5ab64a6d04234c888bf2dd5787d5f8a0","0523999f0efc4bde94be536a076485db","9e119d33fae8454684065aa973dcddbb","083e166e3e7343a7a15708734e9025f4","73d98ca3927d4b1ea56a8713bb937cf4","518026b7577a4b1f9f287401b23601fa","732e29078e764b4ba921bb3c12c74d37","962d816edbca4135afea7f9d318293f0","528045887749429b9f56e42c040b7b24","f26e09d18efe4e01826b2be083d7f303","a3ea24d58e624bba9205640d5cd555f5","5030bb569d46467b8777627319164bfa","7ec4fe930bc34dc59c1be032e2554501","2a6edef779934fdaa22880e14c365db3","269124a117ff4fe5a93e71f1d1d6afe4"]},"collapsed":true,"cellView":"form","id":"6czBFl51n-RV","executionInfo":{"status":"ok","timestamp":1758873316751,"user_tz":-420,"elapsed":62136,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"e352e6c9-13f4-43b4-9bee-ab4a28cc00f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CASME II DEIT TRANSFORMER OPTIMIZED BASELINE INFRASTRUCTURE\n","============================================================\n","\n","[1] Mounting Google Drive...\n","Mounted at /content/drive\n","Google Drive mounted successfully\n","\n","[2] Importing required libraries...\n","CASME II DeiT Optimized Baseline - Infrastructure Configuration\n","======================================================================\n","Loading CASME II dataset metadata...\n","Dataset: CASME2\n","Total samples: 255\n","Split strategy: stratified_80_10_10\n","Using DeiT-Base-Distilled for advanced micro-expression recognition with distillation token\n","\n","==================================================\n","OPTIMIZED EXPERIMENT CONFIGURATION\n","==================================================\n","Loss Function: Focal Loss\n","  Gamma: 2.0\n","  Alpha Weights (per-class): [0.053, 0.067, 0.094, 0.102, 0.106, 0.201, 0.376]\n","  Alpha Sum Validation: 0.999\n","DeiT Model: facebook/deit-base-distilled-patch16-224\n","Input Size: 384x384\n","Patch Size: 16x16\n","Expected Hidden Dim: 768\n","Distillation Token: Enabled\n","==================================================\n","\n","Device: cuda\n","GPU: NVIDIA L4 (23.8 GB)\n","L4: Balanced performance configuration for DeiT\n","\n","Train distribution: {'others': 79, 'disgust': 50, 'happiness': 25, 'repression': 21, 'surprise': 20, 'sadness': 5, 'fear': 1}\n","Validation distribution: {'others': 10, 'disgust': 6, 'happiness': 3, 'repression': 3, 'surprise': 2, 'sadness': 1, 'fear': 1}\n","Test distribution: {'others': 10, 'disgust': 7, 'happiness': 4, 'repression': 3, 'surprise': 3, 'sadness': 1}\n","Applied Focal Loss alpha weights: [0.053 0.067 0.094 0.102 0.106 0.201 0.376]\n","Alpha weights sum: 0.999\n","\n","DeiT Transformer Configuration Summary:\n","  Model: facebook/deit-base-distilled-patch16-224\n","  Variant: base\n","  Input size: 384px\n","  Patch size: 16\n","  Learning rate: 1e-05\n","  Batch size: 16\n","  Distillation token: True\n","\n","Setting up DeiT Image Processor for 384px input...\n"]},{"output_type":"display_data","data":{"text/plain":["Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a16062a30c404b9cbd3205d82712e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6934b1953f144e27b35367a62149cc83"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DeiT Image Processor configured for 384px with interpolate_pos_encoding\n","\n","Dataset paths:\n","Train: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/train\n","Validation: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/val\n","Test: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_casme2/data_split/test\n","\n","DeiT CASME II architecture validation...\n"]},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89da40819c024fbda71d0143a27dff78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/349M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d98ca3927d4b1ea56a8713bb937cf4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DeiT feature dimension: 768\n","DeiT distillation token: Available in model\n","DeiT CASME II: 768 -> 512 -> 128 -> 7\n","Validation successful: Output shape torch.Size([1, 7])\n","Expected patches: 576\n","Total tokens (CLS + DIST + patches): 578\n","Patch size: 16x16\n","Input resolution: 384x384\n","Interpolate position encoding: True\n","Distillation token: Active\n","\n","============================================================\n","CASME II DEIT TRANSFORMER OPTIMIZED BASELINE CONFIGURATION COMPLETE\n","============================================================\n","Loss Configuration:\n","  Function: Optimized Focal Loss\n","  Gamma: 2.0\n","  Per-class Alpha: [0.053, 0.067, 0.094, 0.102, 0.106, 0.201, 0.376]\n","  Alpha Sum: 0.999\n","\n","Model Configuration:\n","  Architecture: facebook/deit-base-distilled-patch16-224\n","  Variant: base\n","  Input Resolution: 384px\n","  Patch Size: 16x16\n","  Hidden Dimension: 768\n","  Distillation Token: True\n","  Position Interpolation: True\n","\n","Dataset Configuration:\n","  Classes: 7\n","  Weight Optimization: Per-class Alpha\n","  Token Processing: CLS + Distillation + Patch Tokens\n","\n","Architecture Highlights:\n","  Medical-Proven Approach: DeiTModel + Custom Classification Head\n","  Position Encoding: Interpolate from 224px -> 384px\n","  Distillation Capability: Available through model architecture\n","  Stability Features: LayerNorm + GELU + Proper Dropout\n","\n","Next: Cell 2 - Dataset Loading and DeiT Training Pipeline\n"]}],"source":["# @title Cell 1: CASME II DeiT Infrastructure Configuration\n","\n","# File: 02_04_DeiT_Direct_Optimized_Baseline_Cell1.py\n","# Location: experiments/02_04_DeiT_Direct_Baseline.ipynb\n","# Purpose: Optimized DeiT for CASME II micro-expression recognition with distillation token mechanism and advanced class weight optimization\n","\n","# Mount Google Drive\n","from google.colab import drive\n","print(\"=\" * 60)\n","print(\"CASME II DEIT TRANSFORMER OPTIMIZED BASELINE INFRASTRUCTURE\")\n","print(\"=\" * 60)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"Google Drive mounted successfully\")\n","\n","print(\"\\n[2] Importing required libraries...\")\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import timm\n","import json\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import time\n","from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Project paths configuration - updated for DeiT\n","PROJECT_ROOT = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","DATASET_ROOT = f\"{PROJECT_ROOT}/datasets/processed_casme2/data_split_v1\"\n","CHECKPOINT_ROOT = f\"{PROJECT_ROOT}/models/02_04_deit_casme2-af\"\n","RESULTS_ROOT = f\"{PROJECT_ROOT}/results/02_04_deit_casme2-af\"\n","\n","# Load CASME II dataset metadata - preserved existing paths\n","METADATA_TRAIN = f\"{DATASET_ROOT}/split_metadata.json\"\n","PROCESSING_SUMMARY = f\"{DATASET_ROOT}/processing_summary.json\"\n","\n","print(\"CASME II DeiT Optimized Baseline - Infrastructure Configuration\")\n","print(\"=\" * 70)\n","\n","# Load dataset metadata\n","print(\"Loading CASME II dataset metadata...\")\n","with open(METADATA_TRAIN, 'r') as f:\n","    casme2_metadata = json.load(f)\n","\n","with open(PROCESSING_SUMMARY, 'r') as f:\n","    processing_info = json.load(f)\n","\n","print(f\"Dataset: {processing_info['dataset']}\")\n","print(f\"Total samples: {processing_info['total_samples']}\")\n","print(f\"Split strategy: {processing_info['split_strategy']}\")\n","\n","# =====================================================\n","# ADVANCED EXPERIMENT CONFIGURATION - DeiT Transformer Optimized Parameters\n","# =====================================================\n","\n","# FOCAL LOSS CONFIGURATION - Toggle and Advanced Parameters\n","USE_FOCAL_LOSS = True  # Set True to enable Focal Loss, False for CrossEntropy\n","FOCAL_LOSS_GAMMA = 2.0  # Focal loss focusing parameter (typically 1.0 - 3.0)\n","\n","# OPTIMIZED CLASS WEIGHTS CONFIGURATION - Inverse Square Root Frequency Approach\n","# CASME II classes: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness', 'fear']\n","# Train distribution: [99, 63, 32, 27, 25, 7, 2] - inverse sqrt frequency approach\n","\n","# CrossEntropy Loss - Optimized inverse square root frequency weights\n","CROSSENTROPY_CLASS_WEIGHTS = [1.00, 1.25, 1.76, 1.91, 1.99, 3.76, 7.04]\n","\n","# Focal Loss - Normalized per-class alpha values (sum = 1.0)\n","FOCAL_LOSS_ALPHA_WEIGHTS = [0.053, 0.067, 0.094, 0.102, 0.106, 0.201, 0.376]\n","\n","# DEIT TRANSFORMER MODEL CONFIGURATION - Support Small and Base distilled variants\n","DEIT_MODEL_VARIANT = 'base'  # Options: 'small' or 'base'\n","\n","# Dynamic DeiT model selection based on variant\n","if DEIT_MODEL_VARIANT == 'small':\n","    DEIT_MODEL_NAME = 'facebook/deit-small-distilled-patch16-224'\n","    EXPECTED_HIDDEN_DIM = 384\n","    PATCH_SIZE = 16\n","    INPUT_SIZE = 384  # Upscaled for micro-expression detail preservation\n","    print(\"Using DeiT-Small-Distilled for efficient micro-expression analysis with distillation token\")\n","elif DEIT_MODEL_VARIANT == 'base':\n","    DEIT_MODEL_NAME = 'facebook/deit-base-distilled-patch16-224'\n","    EXPECTED_HIDDEN_DIM = 768\n","    PATCH_SIZE = 16\n","    INPUT_SIZE = 384  # Upscaled for micro-expression detail preservation\n","    print(\"Using DeiT-Base-Distilled for advanced micro-expression recognition with distillation token\")\n","else:\n","    raise ValueError(f\"Unsupported DEIT_MODEL_VARIANT: {DEIT_MODEL_VARIANT}\")\n","\n","# Display experiment configuration\n","print(\"\\n\" + \"=\" * 50)\n","print(\"OPTIMIZED EXPERIMENT CONFIGURATION\")\n","print(\"=\" * 50)\n","print(f\"Loss Function: {'Focal Loss' if USE_FOCAL_LOSS else 'CrossEntropy Loss'}\")\n","if USE_FOCAL_LOSS:\n","    print(f\"  Gamma: {FOCAL_LOSS_GAMMA}\")\n","    print(f\"  Alpha Weights (per-class): {FOCAL_LOSS_ALPHA_WEIGHTS}\")\n","    print(f\"  Alpha Sum Validation: {sum(FOCAL_LOSS_ALPHA_WEIGHTS):.3f}\")\n","else:\n","    print(f\"  Class Weights (inverse sqrt freq): {CROSSENTROPY_CLASS_WEIGHTS}\")\n","print(f\"DeiT Model: {DEIT_MODEL_NAME}\")\n","print(f\"Input Size: {INPUT_SIZE}x{INPUT_SIZE}\")\n","print(f\"Patch Size: {PATCH_SIZE}x{PATCH_SIZE}\")\n","print(f\"Expected Hidden Dim: {EXPECTED_HIDDEN_DIM}\")\n","print(f\"Distillation Token: Enabled\")\n","print(\"=\" * 50)\n","\n","# Enhanced GPU configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n","gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n","\n","print(f\"\\nDevice: {device}\")\n","print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n","\n","# Hardware-optimized batch size for 384px input with DeiT\n","if 'A100' in gpu_name:\n","    BATCH_SIZE = 24\n","    NUM_WORKERS = 8\n","    torch.backends.cudnn.benchmark = True\n","    print(\"A100: Optimized batch size for DeiT 384px\")\n","elif 'L4' in gpu_name:\n","    BATCH_SIZE = 16\n","    NUM_WORKERS = 6\n","    torch.backends.cudnn.benchmark = True\n","    print(\"L4: Balanced performance configuration for DeiT\")\n","else:\n","    BATCH_SIZE = 8\n","    NUM_WORKERS = 4\n","    print(\"Default GPU: Conservative settings for DeiT\")\n","\n","# CASME II class mapping and analysis - preserved existing structure\n","CASME2_CLASSES = ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness', 'fear']\n","CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CASME2_CLASSES)}\n","\n","# Analyze class distribution from metadata\n","train_dist = casme2_metadata['train']['class_distribution']\n","val_dist = casme2_metadata['val']['class_distribution']\n","test_dist = casme2_metadata['test']['class_distribution']\n","\n","print(f\"\\nTrain distribution: {train_dist}\")\n","print(f\"Validation distribution: {val_dist}\")\n","print(f\"Test distribution: {test_dist}\")\n","\n","# Apply optimized class weights based on loss function selection\n","if USE_FOCAL_LOSS:\n","    # For Focal Loss - use normalized alpha weights (per-class importance)\n","    class_weights = torch.tensor(FOCAL_LOSS_ALPHA_WEIGHTS, dtype=torch.float32).to(device)\n","    print(f\"Applied Focal Loss alpha weights: {class_weights.cpu().numpy()}\")\n","    print(f\"Alpha weights sum: {class_weights.sum().item():.3f}\")\n","else:\n","    # For CrossEntropy - use inverse sqrt frequency weights\n","    class_weights = torch.tensor(CROSSENTROPY_CLASS_WEIGHTS, dtype=torch.float32).to(device)\n","    print(f\"Applied CrossEntropy class weights: {class_weights.cpu().numpy()}\")\n","\n","# CASME II DeiT Transformer Optimized Configuration\n","CASME2_DEIT_CONFIG = {\n","    # Architecture configuration - DeiT Transformer specific\n","    'deit_model': DEIT_MODEL_NAME,\n","    'deit_variant': DEIT_MODEL_VARIANT,\n","    'input_size': INPUT_SIZE,\n","    'patch_size': PATCH_SIZE,\n","    'num_classes': 7,\n","    'dropout_rate': 0.2,\n","    'expected_hidden_dim': EXPECTED_HIDDEN_DIM,\n","    'use_distillation_token': True,\n","    'distillation_enabled': True,\n","    'interpolate_pos_encoding': True,\n","\n","    # Training configuration (proven effective from medical imaging)\n","    'learning_rate': 1e-5,\n","    'weight_decay': 1e-5,\n","    'gradient_clip': 1.0,\n","    'num_epochs': 50,\n","    'batch_size': BATCH_SIZE,\n","    'num_workers': NUM_WORKERS,\n","    'device': device,\n","\n","    # Scheduler configuration\n","    'scheduler_type': 'plateau',\n","    'scheduler_mode': 'max',\n","    'scheduler_factor': 0.5,\n","    'scheduler_patience': 3,\n","    'scheduler_min_lr': 1e-6,\n","    'scheduler_monitor': 'val_f1_macro',\n","\n","    # Optimized loss configuration\n","    'use_focal_loss': USE_FOCAL_LOSS,\n","    'focal_loss_gamma': FOCAL_LOSS_GAMMA,\n","    'focal_loss_alpha_weights': FOCAL_LOSS_ALPHA_WEIGHTS,\n","    'crossentropy_class_weights': CROSSENTROPY_CLASS_WEIGHTS,\n","    'class_weights': class_weights,\n","\n","    # Evaluation configuration\n","    'use_macro_avg': True,\n","    'early_stopping': False,\n","    'save_best_f1': True,\n","    'save_strategy': 'best_only'\n","}\n","\n","print(f\"\\nDeiT Transformer Configuration Summary:\")\n","print(f\"  Model: {CASME2_DEIT_CONFIG['deit_model']}\")\n","print(f\"  Variant: {CASME2_DEIT_CONFIG['deit_variant']}\")\n","print(f\"  Input size: {CASME2_DEIT_CONFIG['input_size']}px\")\n","print(f\"  Patch size: {CASME2_DEIT_CONFIG['patch_size']}\")\n","print(f\"  Learning rate: {CASME2_DEIT_CONFIG['learning_rate']}\")\n","print(f\"  Batch size: {BATCH_SIZE}\")\n","print(f\"  Distillation token: {CASME2_DEIT_CONFIG['use_distillation_token']}\")\n","\n","# =====================================================\n","# ADVANCED FOCAL LOSS IMPLEMENTATION - Per-Class Alpha Support (Preserved from Swin)\n","# =====================================================\n","\n","class OptimizedFocalLoss(nn.Module):\n","    \"\"\"\n","    Advanced Focal Loss implementation with per-class alpha support\n","    Paper: \"Focal Loss for Dense Object Detection\" (Lin et al., 2017)\n","\n","    Enhanced Formula: FL(p_t) = -α_t(1-p_t)^γ log(p_t)\n","\n","    Args:\n","        alpha (list/tensor): Per-class alpha weights (must sum to 1.0)\n","        gamma (float): Focusing parameter for hard examples (default: 2.0)\n","        reduction (str): Reduction method ('mean', 'sum', 'none')\n","    \"\"\"\n","\n","    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n","        super(OptimizedFocalLoss, self).__init__()\n","\n","        if alpha is not None:\n","            if isinstance(alpha, list):\n","                self.alpha = torch.tensor(alpha, dtype=torch.float32)\n","            else:\n","                self.alpha = alpha\n","\n","            # Validation: alpha should sum to 1.0 for proper normalization\n","            alpha_sum = self.alpha.sum().item()\n","            if abs(alpha_sum - 1.0) > 0.01:\n","                print(f\"Warning: Alpha weights sum to {alpha_sum:.3f}, expected 1.0\")\n","\n","        else:\n","            self.alpha = None\n","\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, inputs, targets):\n","        # Calculate cross entropy loss\n","        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n","\n","        # Calculate p_t (probability of true class)\n","        pt = torch.exp(-ce_loss)\n","\n","        # Apply per-class alpha if provided\n","        if self.alpha is not None:\n","            if self.alpha.device != targets.device:\n","                self.alpha = self.alpha.to(targets.device)\n","            alpha_t = self.alpha.gather(0, targets)\n","        else:\n","            alpha_t = 1.0\n","\n","        # Apply focal loss formula: α_t(1-p_t)^γ * CE_loss\n","        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n","\n","        # Apply reduction\n","        if self.reduction == 'mean':\n","            return focal_loss.mean()\n","        elif self.reduction == 'sum':\n","            return focal_loss.sum()\n","        else:\n","            return focal_loss\n","\n","# FIXED: DeiT Architecture for CASME II with proven medical approach\n","class DeiTCASME2Baseline(nn.Module):\n","    \"\"\"DeiT baseline for CASME II micro-expression recognition with distillation token mechanism - Medical approach\"\"\"\n","\n","    def __init__(self, num_classes, dropout_rate=0.2):\n","        super(DeiTCASME2Baseline, self).__init__()\n","\n","        # FIXED: Use DeiTModel + custom head (like medical reference) instead of DeiTForImageClassificationWithTeacher\n","        from transformers import DeiTModel\n","\n","        self.deit = DeiTModel.from_pretrained(\n","            CASME2_DEIT_CONFIG['deit_model'],\n","            add_pooling_layer=False  # Use CLS token manually\n","        )\n","\n","        # Enable fine-tuning for micro-expression domain\n","        for param in self.deit.parameters():\n","            param.requires_grad = True\n","\n","        # Get DeiT feature dimensions\n","        self.deit_feature_dim = self.deit.config.hidden_size\n","\n","        print(f\"DeiT feature dimension: {self.deit_feature_dim}\")\n","        print(f\"DeiT distillation token: Available in model\")\n","\n","        # Verify expected dimensions\n","        if self.deit_feature_dim != CASME2_DEIT_CONFIG['expected_hidden_dim']:\n","            print(f\"Warning: Expected {CASME2_DEIT_CONFIG['expected_hidden_dim']}, got {self.deit_feature_dim}\")\n","            print(f\"Note: DeiT-{CASME2_DEIT_CONFIG['deit_variant']} hidden_size: {self.deit_feature_dim}\")\n","\n","        # MEDICAL PROVEN: Classification head with LayerNorm for stability (same structure as medical reference)\n","        self.classifier_layers = nn.Sequential(\n","            nn.Linear(self.deit_feature_dim, 512),\n","            nn.LayerNorm(512),\n","            nn.GELU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Linear(512, 128),\n","            nn.LayerNorm(128),\n","            nn.GELU(),\n","            nn.Dropout(dropout_rate),\n","        )\n","\n","        # Final classification layer for CASME II classes\n","        self.classifier = nn.Linear(128, num_classes)\n","\n","        print(f\"DeiT CASME II: {self.deit_feature_dim} -> 512 -> 128 -> {num_classes}\")\n","\n","    def forward(self, pixel_values):\n","        # FIXED: DeiT forward pass with position embedding interpolation (medical approach)\n","        deit_outputs = self.deit(\n","            pixel_values=pixel_values,\n","            interpolate_pos_encoding=True  # KEY: Enable position embedding interpolation for 384px\n","        )\n","\n","        # MEDICAL PROVEN: Extract CLS token features (first token) from last hidden state\n","        deit_features = deit_outputs.last_hidden_state[:, 0]  # [batch, hidden_size]\n","\n","        # Classification pipeline\n","        processed_features = self.classifier_layers(deit_features)\n","        output = self.classifier(processed_features)\n","\n","        return output\n","\n","# Enhanced optimizer and scheduler factory\n","def create_optimizer_scheduler_casme2(model, config):\n","    \"\"\"Create optimizer and scheduler for CASME II DeiT training\"\"\"\n","\n","    # AdamW optimizer with proven configuration\n","    optimizer = optim.AdamW(\n","        model.parameters(),\n","        lr=config['learning_rate'],\n","        weight_decay=config['weight_decay'],\n","        betas=(0.9, 0.999)\n","    )\n","\n","    # ReduceLROnPlateau scheduler monitoring validation F1\n","    if config['scheduler_type'] == 'plateau':\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer,\n","            mode=config['scheduler_mode'],\n","            factor=config['scheduler_factor'],\n","            patience=config['scheduler_patience'],\n","            min_lr=config['scheduler_min_lr']\n","        )\n","        print(f\"Scheduler: ReduceLROnPlateau monitoring {config['scheduler_monitor']}\")\n","    else:\n","        scheduler = None\n","\n","    return optimizer, scheduler\n","\n","# FIXED: DeiT Image Processor setup for 384px input (medical approach)\n","from transformers import DeiTImageProcessor\n","\n","print(\"\\nSetting up DeiT Image Processor for 384px input...\")\n","\n","deit_processor = DeiTImageProcessor.from_pretrained(\n","    CASME2_DEIT_CONFIG['deit_model'],\n","    do_resize=False,     # CRITICAL: Don't resize to 224px - keep 384px (medical approach)\n","    do_normalize=True,   # Apply ImageNet normalization\n","    do_rescale=True,     # Rescale pixel values to [0,1]\n","    do_center_crop=False # No center crop - use full 384px image\n",")\n","\n","# Transform functions for DeiT\n","def deit_transform_train(image):\n","    \"\"\"Training transform with DeiT Image Processor\"\"\"\n","    inputs = deit_processor(image, return_tensors=\"pt\")\n","    return inputs['pixel_values'].squeeze(0)\n","\n","def deit_transform_val(image):\n","    \"\"\"Validation transform with DeiT Image Processor\"\"\"\n","    inputs = deit_processor(image, return_tensors=\"pt\")\n","    return inputs['pixel_values'].squeeze(0)\n","\n","print(f\"DeiT Image Processor configured for 384px with interpolate_pos_encoding\")\n","\n","# Custom Dataset class for CASME II - preserved existing structure\n","class CASME2Dataset(Dataset):\n","    \"\"\"Custom dataset class for CASME II with JSON metadata support\"\"\"\n","\n","    def __init__(self, split_metadata, dataset_root, transform=None, split='train'):\n","        self.metadata = split_metadata[split]['samples']\n","        self.dataset_root = dataset_root\n","        self.transform = transform\n","        self.split = split\n","\n","        print(f\"Loaded {len(self.metadata)} samples for {split} split\")\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","        sample = self.metadata[idx]\n","\n","        # Load image\n","        image_path = os.path.join(self.dataset_root, self.split, sample['image_filename'])\n","        image = Image.open(image_path).convert('RGB')\n","\n","        # Apply transform\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Get class label\n","        emotion = sample['emotion']\n","        label = CLASS_TO_IDX[emotion]\n","\n","        return image, label, sample['sample_id']\n","\n","# Create directories - updated for DeiT\n","os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n","os.makedirs(f\"{RESULTS_ROOT}/training_logs\", exist_ok=True)\n","os.makedirs(f\"{RESULTS_ROOT}/evaluation_results\", exist_ok=True)\n","\n","# Dataset paths - preserved existing structure\n","TRAIN_PATH = f\"{DATASET_ROOT}/train\"\n","VAL_PATH = f\"{DATASET_ROOT}/val\"\n","TEST_PATH = f\"{DATASET_ROOT}/test\"\n","\n","print(f\"\\nDataset paths:\")\n","print(f\"Train: {TRAIN_PATH}\")\n","print(f\"Validation: {VAL_PATH}\")\n","print(f\"Test: {TEST_PATH}\")\n","\n","# FIXED: Enhanced architecture validation with DeiT distillation token\n","print(\"\\nDeiT CASME II architecture validation...\")\n","\n","try:\n","    test_model = DeiTCASME2Baseline(num_classes=7, dropout_rate=0.2).to(device)\n","    test_input = torch.randn(1, 3, 384, 384).to(device)\n","    test_output = test_model(test_input)\n","\n","    # Calculate expected patches for DeiT at 384px\n","    expected_patches = (CASME2_DEIT_CONFIG['input_size'] // CASME2_DEIT_CONFIG['patch_size']) ** 2  # 384/16 = 24, 24^2 = 576\n","    total_tokens = expected_patches + 2  # +2 for CLS and distillation tokens\n","\n","    print(f\"Validation successful: Output shape {test_output.shape}\")\n","    print(f\"Expected patches: {expected_patches}\")\n","    print(f\"Total tokens (CLS + DIST + patches): {total_tokens}\")\n","    print(f\"Patch size: {CASME2_DEIT_CONFIG['patch_size']}x{CASME2_DEIT_CONFIG['patch_size']}\")\n","    print(f\"Input resolution: {CASME2_DEIT_CONFIG['input_size']}x{CASME2_DEIT_CONFIG['input_size']}\")\n","    print(f\"Interpolate position encoding: {CASME2_DEIT_CONFIG['interpolate_pos_encoding']}\")\n","    print(f\"Distillation token: Active\")\n","\n","    del test_model, test_input, test_output\n","    torch.cuda.empty_cache()\n","\n","except Exception as e:\n","    print(f\"Validation failed: {e}\")\n","\n","# Optimized loss function factory with advanced configuration (preserved from Swin)\n","def create_criterion_casme2(weights, use_focal_loss=False, alpha_weights=None, gamma=2.0):\n","    \"\"\"\n","    Optimized factory function to create loss criterion based on advanced configuration\n","\n","    Args:\n","        weights (Tensor): Class weights for CrossEntropy (ignored if focal loss used)\n","        use_focal_loss (bool): Whether to use Focal Loss or CrossEntropy\n","        alpha_weights (list): Per-class alpha weights for Focal Loss (must sum to 1.0)\n","        gamma (float): Focal loss gamma parameter\n","\n","    Returns:\n","        Loss function (nn.Module)\n","    \"\"\"\n","    if use_focal_loss:\n","        print(f\"Using Optimized Focal Loss with gamma={gamma}\")\n","        if alpha_weights:\n","            print(f\"Per-class alpha weights: {alpha_weights}\")\n","            print(f\"Alpha sum: {sum(alpha_weights):.3f}\")\n","        return OptimizedFocalLoss(alpha=alpha_weights, gamma=gamma)\n","    else:\n","        print(f\"Using CrossEntropy Loss with optimized class weights\")\n","        print(f\"Class weights: {weights.cpu().numpy()}\")\n","        return nn.CrossEntropyLoss(weight=weights)\n","\n","# Global configuration for training pipeline - enhanced for DeiT\n","GLOBAL_CONFIG_CASME2 = {\n","    'device': device,\n","    'batch_size': BATCH_SIZE,\n","    'num_workers': NUM_WORKERS,\n","    'num_classes': 7,\n","    'class_weights': class_weights,\n","    'class_names': CASME2_CLASSES,\n","    'class_to_idx': CLASS_TO_IDX,\n","    'transform_train': deit_transform_train,\n","    'transform_val': deit_transform_val,\n","    'deit_config': CASME2_DEIT_CONFIG,\n","    'checkpoint_root': CHECKPOINT_ROOT,\n","    'results_root': RESULTS_ROOT,\n","    'train_path': TRAIN_PATH,\n","    'val_path': VAL_PATH,\n","    'test_path': TEST_PATH,\n","    'metadata': casme2_metadata,\n","    'optimizer_scheduler_factory': create_optimizer_scheduler_casme2,\n","    'criterion_factory': create_criterion_casme2\n","}\n","\n","# Configuration validation and summary\n","print(\"\\n\" + \"=\" * 60)\n","print(\"CASME II DEIT TRANSFORMER OPTIMIZED BASELINE CONFIGURATION COMPLETE\")\n","print(\"=\" * 60)\n","\n","print(f\"Loss Configuration:\")\n","if USE_FOCAL_LOSS:\n","    print(f\"  Function: Optimized Focal Loss\")\n","    print(f\"  Gamma: {FOCAL_LOSS_GAMMA}\")\n","    print(f\"  Per-class Alpha: {FOCAL_LOSS_ALPHA_WEIGHTS}\")\n","    print(f\"  Alpha Sum: {sum(FOCAL_LOSS_ALPHA_WEIGHTS):.3f}\")\n","else:\n","    print(f\"  Function: CrossEntropy with Optimized Weights\")\n","    print(f\"  Class Weights: {CROSSENTROPY_CLASS_WEIGHTS}\")\n","\n","print(f\"\\nModel Configuration:\")\n","print(f\"  Architecture: {DEIT_MODEL_NAME}\")\n","print(f\"  Variant: {DEIT_MODEL_VARIANT}\")\n","print(f\"  Input Resolution: {INPUT_SIZE}px\")\n","print(f\"  Patch Size: {PATCH_SIZE}x{PATCH_SIZE}\")\n","print(f\"  Hidden Dimension: {EXPECTED_HIDDEN_DIM}\")\n","print(f\"  Distillation Token: {CASME2_DEIT_CONFIG['use_distillation_token']}\")\n","print(f\"  Position Interpolation: {CASME2_DEIT_CONFIG['interpolate_pos_encoding']}\")\n","\n","print(f\"\\nDataset Configuration:\")\n","print(f\"  Classes: {len(CASME2_CLASSES)}\")\n","print(f\"  Weight Optimization: {'Per-class Alpha' if USE_FOCAL_LOSS else 'Inverse Sqrt Frequency'}\")\n","print(f\"  Token Processing: CLS + Distillation + Patch Tokens\")\n","\n","print(f\"\\nArchitecture Highlights:\")\n","print(f\"  Medical-Proven Approach: DeiTModel + Custom Classification Head\")\n","print(f\"  Position Encoding: Interpolate from 224px -> 384px\")\n","print(f\"  Distillation Capability: Available through model architecture\")\n","print(f\"  Stability Features: LayerNorm + GELU + Proper Dropout\")\n","\n","print(\"\\nNext: Cell 2 - Dataset Loading and DeiT Training Pipeline\")"]},{"cell_type":"code","source":["# @title Cell 2: CASME II DeiT Training Pipeline\n","\n","# File: 02_04_DeiT_Direct_Enhanced_Baseline_Cell2.py\n","# Location: experiments/02_04_DeiT_Direct_Baseline.ipynb\n","# Purpose: Training pipeline for CASME II DeiT micro-expression recognition with distillation token mechanism\n","\n","import os\n","import time\n","import json\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score\n","from concurrent.futures import ThreadPoolExecutor\n","import multiprocessing as mp\n","\n","print(\"CASME II DeiT Enhanced Training Pipeline with Fixed Checkpoints\")\n","print(\"=\" * 70)\n","print(f\"Loss Function: {'Optimized Focal Loss' if CASME2_DEIT_CONFIG['use_focal_loss'] else 'CrossEntropy Loss'}\")\n","if CASME2_DEIT_CONFIG['use_focal_loss']:\n","    print(f\"Focal Loss Parameters:\")\n","    print(f\"  Gamma: {CASME2_DEIT_CONFIG['focal_loss_gamma']}\")\n","    print(f\"  Per-class Alpha: {CASME2_DEIT_CONFIG['focal_loss_alpha_weights']}\")\n","    print(f\"  Alpha Sum: {sum(CASME2_DEIT_CONFIG['focal_loss_alpha_weights']):.3f}\")\n","else:\n","    print(f\"CrossEntropy Parameters:\")\n","    print(f\"  Optimized Class Weights: {CASME2_DEIT_CONFIG['crossentropy_class_weights']}\")\n","print(f\"DeiT Architecture: {CASME2_DEIT_CONFIG['deit_variant']} variant with distillation token\")\n","print(f\"Input resolution: {CASME2_DEIT_CONFIG['input_size']}x{CASME2_DEIT_CONFIG['input_size']}\")\n","print(f\"Position interpolation: {CASME2_DEIT_CONFIG['interpolate_pos_encoding']}\")\n","print(f\"Training epochs: {CASME2_DEIT_CONFIG['num_epochs']}\")\n","print(f\"Scheduler patience: {CASME2_DEIT_CONFIG['scheduler_patience']}\")\n","\n","# Enhanced CASME II Dataset with clean RAM caching for DeiT\n","class CASME2DatasetTrainingDeiT(Dataset):\n","    \"\"\"Enhanced CASME II dataset for DeiT training with clean RAM caching optimization\"\"\"\n","\n","    def __init__(self, split_metadata, dataset_root, transform=None, split='train', use_ram_cache=True):\n","        self.metadata = split_metadata[split]['samples']\n","        self.dataset_root = dataset_root\n","        self.transform = transform\n","        self.split = split\n","        self.use_ram_cache = use_ram_cache\n","        self.images = []\n","        self.labels = []\n","        self.sample_ids = []\n","        self.cached_images = []\n","\n","        print(f\"Loading CASME II {split} dataset for DeiT training...\")\n","\n","        # Process metadata\n","        for sample in self.metadata:\n","            image_path = os.path.join(dataset_root, split, sample['image_filename'])\n","            self.images.append(image_path)\n","            self.labels.append(CLASS_TO_IDX[sample['emotion']])\n","            self.sample_ids.append(sample['sample_id'])\n","\n","        print(f\"Loaded {len(self.images)} CASME II {split} samples\")\n","        self._print_distribution()\n","\n","        # RAM caching for training efficiency\n","        if self.use_ram_cache:\n","            self._preload_to_ram()\n","\n","    def _print_distribution(self):\n","        \"\"\"Print class distribution\"\"\"\n","        label_counts = {}\n","        for label in self.labels:\n","            label_counts[label] = label_counts.get(label, 0) + 1\n","\n","        for label, count in sorted(label_counts.items()):\n","            class_name = CASME2_CLASSES[label]\n","            percentage = (count / len(self.labels)) * 100\n","            print(f\"  {class_name}: {count} samples ({percentage:.1f}%)\")\n","\n","    def _preload_to_ram(self):\n","        \"\"\"Clean RAM preloading optimized for DeiT training at 384px\"\"\"\n","        print(f\"Preloading {len(self.images)} {self.split} images to RAM for DeiT...\")\n","\n","        valid_images = 0\n","        self.cached_images = [None] * len(self.images)\n","\n","        # Clean loading without verbose progress\n","        for i, img_path in enumerate(self.images):\n","            try:\n","                image = Image.open(img_path).convert('RGB')\n","                if image.size != (384, 384):\n","                    image = image.resize((384, 384), Image.Resampling.LANCZOS)\n","                self.cached_images[i] = image\n","                valid_images += 1\n","            except Exception as e:\n","                print(f\"Error loading {img_path}: {e}\")\n","                self.cached_images[i] = Image.new('RGB', (384, 384), (128, 128, 128))\n","\n","        ram_usage_gb = len(self.cached_images) * 384 * 384 * 3 * 4 / 1e9\n","        print(f\"{self.split.upper()} RAM caching completed: {valid_images} images, ~{ram_usage_gb:.2f}GB\")\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        if self.use_ram_cache and self.cached_images[idx] is not None:\n","            image = self.cached_images[idx].copy()\n","        else:\n","            try:\n","                image = Image.open(self.images[idx]).convert('RGB')\n","                if image.size != (384, 384):\n","                    image = image.resize((384, 384), Image.Resampling.LANCZOS)\n","            except:\n","                image = Image.new('RGB', (384, 384), (128, 128, 128))\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, self.labels[idx], self.sample_ids[idx]\n","\n","# Enhanced metrics calculation with comprehensive error handling\n","def calculate_metrics_safe_robust(outputs, labels, class_names, average='macro'):\n","    \"\"\"Calculate metrics with enhanced error handling and validation\"\"\"\n","    try:\n","        # Validate input tensors\n","        if outputs.size(0) != labels.size(0):\n","            raise ValueError(f\"Batch size mismatch: outputs {outputs.size(0)} vs labels {labels.size(0)}\")\n","\n","        if isinstance(outputs, torch.Tensor):\n","            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n","        else:\n","            predictions = np.array(outputs)\n","\n","        if isinstance(labels, torch.Tensor):\n","            labels = labels.cpu().numpy()\n","        else:\n","            labels = np.array(labels)\n","\n","        # Validate predictions are in valid range\n","        unique_preds = np.unique(predictions)\n","        unique_labels = np.unique(labels)\n","\n","        accuracy = accuracy_score(labels, predictions)\n","        precision, recall, f1, _ = precision_recall_fscore_support(\n","            labels, predictions,\n","            average=average,\n","            zero_division=0,\n","            labels=list(range(len(class_names)))\n","        )\n","\n","        return {\n","            'accuracy': float(accuracy),\n","            'precision': float(precision),\n","            'recall': float(recall),\n","            'f1_score': float(f1)\n","        }\n","    except Exception as e:\n","        print(f\"Warning: Enhanced metrics calculation error: {e}\")\n","        return {\n","            'accuracy': 0.0,\n","            'precision': 0.0,\n","            'recall': 0.0,\n","            'f1_score': 0.0\n","        }\n","\n","# FIXED: Enhanced training epoch function with DeiT fixed architecture compatibility\n","def train_epoch_deit(model, dataloader, criterion, optimizer, device, epoch, total_epochs):\n","    \"\"\"Enhanced training epoch for DeiT with fixed architecture compatibility\"\"\"\n","    model.train()\n","    running_loss = 0.0\n","    all_outputs = []\n","    all_labels = []\n","\n","    progress_bar = tqdm(dataloader, desc=f\"CASME II DeiT Training Epoch {epoch+1}/{total_epochs}\")\n","\n","    for batch_idx, (images, labels, sample_ids) in enumerate(progress_bar):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # FIXED: DeiT model output - now works with DeiTModel + custom head architecture\n","        outputs = model(images)\n","\n","        # Validate output shape for 7 CASME II classes\n","        if outputs.dim() != 2 or outputs.size(1) != 7:\n","            raise ValueError(f\"Invalid CASME II DeiT output shape: {outputs.shape}, expected [batch_size, 7]\")\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","\n","        # Gradient clipping for DeiT stability\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CASME2_DEIT_CONFIG['gradient_clip'])\n","\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","        # Memory optimized: Move to CPU before accumulating\n","        all_outputs.append(outputs.detach().cpu())\n","        all_labels.append(labels.detach().cpu())\n","\n","        # Update progress with DeiT-specific information\n","        if batch_idx % 5 == 0:\n","            avg_loss = running_loss / (batch_idx + 1)\n","            current_lr = optimizer.param_groups[0]['lr']\n","            progress_bar.set_postfix({\n","                'Loss': f'{avg_loss:.4f}',\n","                'LR': f'{current_lr:.2e}',\n","                'DeiT': CASME2_DEIT_CONFIG['deit_variant']\n","            })\n","\n","    # Enhanced metrics calculation with error recovery\n","    try:\n","        epoch_outputs = torch.cat(all_outputs, dim=0)\n","        epoch_labels = torch.cat(all_labels, dim=0)\n","        metrics = calculate_metrics_safe_robust(epoch_outputs, epoch_labels, CASME2_CLASSES, average='macro')\n","    except Exception as e:\n","        print(f\"Warning: DeiT training metrics calculation failed: {e}\")\n","        metrics = {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n","\n","    avg_loss = running_loss / len(dataloader)\n","    return avg_loss, metrics\n","\n","# FIXED: Enhanced validation epoch function with DeiT fixed architecture compatibility\n","def validate_epoch_deit(model, dataloader, criterion, device, epoch, total_epochs):\n","    \"\"\"Enhanced validation epoch for DeiT with fixed architecture compatibility\"\"\"\n","    model.eval()\n","    running_loss = 0.0\n","    all_outputs = []\n","    all_labels = []\n","    all_sample_ids = []\n","\n","    with torch.no_grad():\n","        progress_bar = tqdm(dataloader, desc=f\"CASME II DeiT Validation Epoch {epoch+1}/{total_epochs}\")\n","\n","        for batch_idx, (images, labels, sample_ids) in enumerate(progress_bar):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # FIXED: DeiT model output - now works with DeiTModel + custom head architecture\n","            outputs = model(images)\n","\n","            loss = criterion(outputs, labels)\n","            running_loss += loss.item()\n","\n","            # Memory optimized: Move to CPU before accumulating\n","            all_outputs.append(outputs.detach().cpu())\n","            all_labels.append(labels.detach().cpu())\n","            all_sample_ids.extend(sample_ids)\n","\n","            if batch_idx % 3 == 0:\n","                avg_loss = running_loss / (batch_idx + 1)\n","                progress_bar.set_postfix({\n","                    'Val Loss': f'{avg_loss:.4f}',\n","                    'DeiT': CASME2_DEIT_CONFIG['deit_variant']\n","                })\n","\n","    # Enhanced metrics calculation with error recovery\n","    try:\n","        epoch_outputs = torch.cat(all_outputs, dim=0)\n","        epoch_labels = torch.cat(all_labels, dim=0)\n","        metrics = calculate_metrics_safe_robust(epoch_outputs, epoch_labels, CASME2_CLASSES, average='macro')\n","    except Exception as e:\n","        print(f\"Warning: DeiT validation metrics calculation failed: {e}\")\n","        metrics = {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n","\n","    avg_loss = running_loss / len(dataloader)\n","    return avg_loss, metrics, all_sample_ids\n","\n","# FIXED: Enhanced checkpoint saving function with complete device migration\n","def save_checkpoint_robust_fixed(model, optimizer, scheduler, epoch, train_metrics, val_metrics,\n","                                checkpoint_dir, best_metrics, config, max_retries=3):\n","    \"\"\"FIXED: Enhanced checkpoint saving with complete device migration and error recovery\"\"\"\n","\n","    print(f\"Saving checkpoint with enhanced device migration...\")\n","\n","    # CRITICAL FIX: Complete device migration to CPU before serialization\n","    try:\n","        # 1. Move model state dict to CPU with proper tensor handling\n","        print(\"  Migrating model state dict to CPU...\")\n","        model_state_cpu = {}\n","        for k, v in model.state_dict().items():\n","            if isinstance(v, torch.Tensor):\n","                model_state_cpu[k] = v.cpu().clone()\n","            else:\n","                model_state_cpu[k] = v\n","\n","        # 2. Move optimizer state dict to CPU with nested tensor handling\n","        print(\"  Migrating optimizer state dict to CPU...\")\n","        optimizer_state_cpu = {}\n","        for k, v in optimizer.state_dict().items():\n","            if isinstance(v, torch.Tensor):\n","                optimizer_state_cpu[k] = v.cpu().clone()\n","            elif isinstance(v, dict):\n","                # Handle nested dictionaries in optimizer state\n","                optimizer_state_cpu[k] = {}\n","                for nested_k, nested_v in v.items():\n","                    if isinstance(nested_v, torch.Tensor):\n","                        optimizer_state_cpu[k][nested_k] = nested_v.cpu().clone()\n","                    elif isinstance(nested_v, dict):\n","                        # Handle double-nested dictionaries (param_groups, etc.)\n","                        optimizer_state_cpu[k][nested_k] = {}\n","                        for deep_k, deep_v in nested_v.items():\n","                            if isinstance(deep_v, torch.Tensor):\n","                                optimizer_state_cpu[k][nested_k][deep_k] = deep_v.cpu().clone()\n","                            else:\n","                                optimizer_state_cpu[k][nested_k][deep_k] = deep_v\n","                    else:\n","                        optimizer_state_cpu[k][nested_k] = nested_v\n","            else:\n","                optimizer_state_cpu[k] = v\n","\n","        # 3. Move scheduler state dict to CPU if exists\n","        scheduler_state_cpu = None\n","        if scheduler:\n","            print(\"  Migrating scheduler state dict to CPU...\")\n","            scheduler_state_cpu = {}\n","            for k, v in scheduler.state_dict().items():\n","                if isinstance(v, torch.Tensor):\n","                    scheduler_state_cpu[k] = v.cpu().clone()\n","                else:\n","                    scheduler_state_cpu[k] = v\n","\n","        # 4. Force GPU memory cleanup before serialization\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","            torch.cuda.synchronize()\n","\n","        print(\"  Device migration completed successfully\")\n","\n","    except Exception as e:\n","        print(f\"ERROR: Device migration failed: {e}\")\n","        return None\n","\n","    # Convert all metrics to serializable format\n","    def make_serializable_enhanced(obj):\n","        \"\"\"Enhanced serialization with complete tensor handling\"\"\"\n","        if isinstance(obj, torch.Tensor):\n","            return obj.cpu().item() if obj.numel() == 1 else obj.cpu().tolist()\n","        elif isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        elif isinstance(obj, (np.integer, np.int32, np.int64)):\n","            return int(obj)\n","        elif isinstance(obj, (np.floating, np.float32, np.float64)):\n","            return float(obj)\n","        elif isinstance(obj, dict):\n","            return {k: make_serializable_enhanced(v) for k, v in obj.items()}\n","        elif isinstance(obj, (list, tuple)):\n","            return [make_serializable_enhanced(item) for item in obj]\n","        else:\n","            try:\n","                return float(obj) if isinstance(obj, (int, float)) else str(obj)\n","            except:\n","                return str(obj)\n","\n","    # Create checkpoint with CPU-migrated state dicts\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model_state_cpu,  # Now on CPU\n","        'optimizer_state_dict': optimizer_state_cpu,  # Now on CPU\n","        'scheduler_state_dict': scheduler_state_cpu,  # Now on CPU or None\n","        'train_metrics': make_serializable_enhanced(train_metrics),\n","        'val_metrics': make_serializable_enhanced(val_metrics),\n","        'casme2_deit_config': make_serializable_enhanced(config),\n","        'best_f1': float(best_metrics['f1']),\n","        'best_loss': float(best_metrics['loss']),\n","        'best_acc': float(best_metrics['accuracy']),\n","        'class_names': CASME2_CLASSES,\n","        'num_classes': 7,\n","        'deit_variant': config['deit_variant'],\n","        'deit_model': config['deit_model']\n","    }\n","\n","    best_path = f\"{checkpoint_dir}/casme2_deit_direct_best_f1.pth\"\n","\n","    # Enhanced save with retry logic and proper file handling\n","    for attempt in range(max_retries):\n","        try:\n","            # Create temporary file first\n","            temp_path = f\"{best_path}.tmp\"\n","\n","            print(f\"  Attempt {attempt + 1}: Saving to temporary file...\")\n","            torch.save(checkpoint, temp_path)\n","\n","            # Move temporary file to final location (atomic operation)\n","            import shutil\n","            shutil.move(temp_path, best_path)\n","\n","            print(f\"Checkpoint saved successfully: {os.path.basename(best_path)}\")\n","            print(f\"  DeiT variant: {config['deit_variant']}\")\n","            print(f\"  Model: {config['deit_model']}\")\n","            return best_path\n","\n","        except Exception as e:\n","            print(f\"Checkpoint save attempt {attempt + 1} failed: {e}\")\n","\n","            # Clean up temporary file if it exists\n","            if os.path.exists(temp_path):\n","                try:\n","                    os.remove(temp_path)\n","                except:\n","                    pass\n","\n","            if attempt < max_retries - 1:\n","                print(f\"  Retrying in 2 seconds...\")\n","                time.sleep(2)  # Brief pause before retry\n","\n","                # Additional memory cleanup before retry\n","                if torch.cuda.is_available():\n","                    torch.cuda.empty_cache()\n","                    torch.cuda.synchronize()\n","                continue\n","            else:\n","                print(f\"All {max_retries} checkpoint save attempts failed\")\n","                return None\n","\n","    return None\n","\n","# Safe JSON serialization function - enhanced for DeiT\n","def safe_json_serialize_deit(obj):\n","    \"\"\"Convert objects to JSON-serializable format with DeiT-specific handling\"\"\"\n","    if isinstance(obj, torch.Tensor):\n","        return obj.cpu().item() if obj.numel() == 1 else obj.cpu().numpy().tolist()\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, (np.integer, np.int32, np.int64)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float32, np.float64)):\n","        return float(obj)\n","    elif isinstance(obj, dict):\n","        return {k: safe_json_serialize_deit(v) for k, v in obj.items()}\n","    elif isinstance(obj, (list, tuple)):\n","        return [safe_json_serialize_deit(item) for item in obj]\n","    elif hasattr(obj, '__dict__'):\n","        return safe_json_serialize_deit(obj.__dict__)\n","    else:\n","        try:\n","            return float(obj) if isinstance(obj, (int, float)) else str(obj)\n","        except:\n","            return str(obj)\n","\n","# Create enhanced datasets for DeiT\n","print(\"\\nCreating CASME II DeiT training datasets...\")\n","\n","train_dataset = CASME2DatasetTrainingDeiT(\n","    split_metadata=GLOBAL_CONFIG_CASME2['metadata'],\n","    dataset_root=GLOBAL_CONFIG_CASME2['train_path'].replace('/train', ''),\n","    transform=GLOBAL_CONFIG_CASME2['transform_train'],\n","    split='train',\n","    use_ram_cache=True\n",")\n","\n","val_dataset = CASME2DatasetTrainingDeiT(\n","    split_metadata=GLOBAL_CONFIG_CASME2['metadata'],\n","    dataset_root=GLOBAL_CONFIG_CASME2['val_path'].replace('/val', ''),\n","    transform=GLOBAL_CONFIG_CASME2['transform_val'],\n","    split='val',\n","    use_ram_cache=True\n",")\n","\n","# Create data loaders with DeiT-optimized settings\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=CASME2_DEIT_CONFIG['batch_size'],\n","    shuffle=True,\n","    num_workers=CASME2_DEIT_CONFIG['num_workers'],\n","    pin_memory=True,\n","    prefetch_factor=2\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=CASME2_DEIT_CONFIG['batch_size'],\n","    shuffle=False,\n","    num_workers=CASME2_DEIT_CONFIG['num_workers'],\n","    pin_memory=True,\n","    prefetch_factor=2\n",")\n","\n","print(f\"Training batches: {len(train_loader)} (samples: {len(train_dataset)})\")\n","print(f\"Validation batches: {len(val_loader)} (samples: {len(val_dataset)})\")\n","\n","# Initialize DeiT model, criterion, optimizer, scheduler\n","print(\"\\nInitializing CASME II DeiT enhanced model...\")\n","model = DeiTCASME2Baseline(\n","    num_classes=GLOBAL_CONFIG_CASME2['num_classes'],\n","    dropout_rate=CASME2_DEIT_CONFIG['dropout_rate']\n",").to(GLOBAL_CONFIG_CASME2['device'])\n","\n","# Enhanced criterion creation using configurable factory function\n","if CASME2_DEIT_CONFIG['use_focal_loss']:\n","    criterion = GLOBAL_CONFIG_CASME2['criterion_factory'](\n","        weights=GLOBAL_CONFIG_CASME2['class_weights'],\n","        use_focal_loss=True,\n","        alpha_weights=CASME2_DEIT_CONFIG['focal_loss_alpha_weights'],\n","        gamma=CASME2_DEIT_CONFIG['focal_loss_gamma']\n","    )\n","else:\n","    criterion = GLOBAL_CONFIG_CASME2['criterion_factory'](\n","        weights=GLOBAL_CONFIG_CASME2['class_weights'],\n","        use_focal_loss=False,\n","        alpha_weights=None,\n","        gamma=2.0\n","    )\n","\n","optimizer, scheduler = GLOBAL_CONFIG_CASME2['optimizer_scheduler_factory'](\n","    model, CASME2_DEIT_CONFIG\n",")\n","\n","print(f\"Optimizer: AdamW (LR={CASME2_DEIT_CONFIG['learning_rate']})\")\n","print(f\"Scheduler: ReduceLROnPlateau (patience={CASME2_DEIT_CONFIG['scheduler_patience']})\")\n","print(f\"Criterion: {'Optimized Focal Loss' if CASME2_DEIT_CONFIG['use_focal_loss'] else 'CrossEntropy'}\")\n","print(f\"DeiT Architecture: {CASME2_DEIT_CONFIG['deit_variant']} variant with position interpolation\")\n","\n","# Training history tracking for DeiT\n","training_history = {\n","    'train_loss': [],\n","    'val_loss': [],\n","    'train_f1': [],\n","    'val_f1': [],\n","    'train_acc': [],\n","    'val_acc': [],\n","    'learning_rate': [],\n","    'epoch_time': []\n","}\n","\n","# Enhanced best metrics tracking for multi-criteria checkpoint saving\n","best_metrics = {\n","    'f1': 0.0,\n","    'loss': float('inf'),\n","    'accuracy': 0.0,\n","    'epoch': 0\n","}\n","\n","print(\"\\nStarting CASME II DeiT enhanced training with fixed checkpoints...\")\n","print(f\"Training configuration: {CASME2_DEIT_CONFIG['num_epochs']} epochs\")\n","print(f\"Position interpolation: 224px -> 384px with DeiTModel + custom head\")\n","print(\"=\" * 70)\n","\n","# Main training loop with enhanced checkpoint reliability for DeiT\n","start_time = time.time()\n","\n","for epoch in range(CASME2_DEIT_CONFIG['num_epochs']):\n","    epoch_start_time = time.time()\n","    print(f\"\\nEpoch {epoch+1}/{CASME2_DEIT_CONFIG['num_epochs']}\")\n","\n","    # Training phase with DeiT-specific adaptations\n","    train_loss, train_metrics = train_epoch_deit(\n","        model, train_loader, criterion, optimizer,\n","        GLOBAL_CONFIG_CASME2['device'], epoch, CASME2_DEIT_CONFIG['num_epochs']\n","    )\n","\n","    # Validation phase with DeiT-specific adaptations\n","    val_loss, val_metrics, val_sample_ids = validate_epoch_deit(\n","        model, val_loader, criterion,\n","        GLOBAL_CONFIG_CASME2['device'], epoch, CASME2_DEIT_CONFIG['num_epochs']\n","    )\n","\n","    # Update scheduler\n","    if scheduler:\n","        scheduler.step(val_metrics['f1_score'])\n","\n","    # Record training history\n","    epoch_time = time.time() - epoch_start_time\n","    current_lr = optimizer.param_groups[0]['lr']\n","\n","    training_history['train_loss'].append(float(train_loss))\n","    training_history['val_loss'].append(float(val_loss))\n","    training_history['train_f1'].append(float(train_metrics['f1_score']))\n","    training_history['val_f1'].append(float(val_metrics['f1_score']))\n","    training_history['train_acc'].append(float(train_metrics['accuracy']))\n","    training_history['val_acc'].append(float(val_metrics['accuracy']))\n","    training_history['learning_rate'].append(float(current_lr))\n","    training_history['epoch_time'].append(float(epoch_time))\n","\n","    # Print epoch summary\n","    print(f\"Train - Loss: {train_loss:.4f}, F1: {train_metrics['f1_score']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n","    print(f\"Val   - Loss: {val_loss:.4f}, F1: {val_metrics['f1_score']:.4f}, Acc: {val_metrics['accuracy']:.4f}\")\n","    print(f\"Time  - Epoch: {epoch_time:.1f}s, LR: {current_lr:.2e}\")\n","\n","    # Enhanced multi-criteria checkpoint saving logic\n","    save_model = False\n","    improvement_reason = \"\"\n","\n","    # Multi-criteria evaluation hierarchy\n","    if val_metrics['f1_score'] > best_metrics['f1']:\n","        save_model = True\n","        improvement_reason = \"Higher F1\"\n","    elif val_metrics['f1_score'] == best_metrics['f1']:\n","        if val_loss < best_metrics['loss']:\n","            save_model = True\n","            improvement_reason = \"Same F1, Lower Loss\"\n","        elif val_loss == best_metrics['loss'] and val_metrics['accuracy'] > best_metrics['accuracy']:\n","            save_model = True\n","            improvement_reason = \"Same F1&Loss, Higher Accuracy\"\n","\n","    if save_model:\n","        best_metrics['f1'] = val_metrics['f1_score']\n","        best_metrics['loss'] = val_loss\n","        best_metrics['accuracy'] = val_metrics['accuracy']\n","        best_metrics['epoch'] = epoch + 1\n","\n","        # Use FIXED checkpoint saving function\n","        best_model_path = save_checkpoint_robust_fixed(\n","            model, optimizer, scheduler, epoch,\n","            train_metrics, val_metrics, GLOBAL_CONFIG_CASME2['checkpoint_root'],\n","            best_metrics, CASME2_DEIT_CONFIG\n","        )\n","\n","        if best_model_path:\n","            print(f\"New best DeiT model: {improvement_reason} - F1: {best_metrics['f1']:.4f}\")\n","        else:\n","            print(f\"Warning: Failed to save DeiT checkpoint despite improvement\")\n","\n","    # Progress tracking\n","    elapsed_time = time.time() - start_time\n","    estimated_total = (elapsed_time / (epoch + 1)) * CASME2_DEIT_CONFIG['num_epochs']\n","    remaining_time = estimated_total - elapsed_time\n","    progress_pct = ((epoch + 1) / CASME2_DEIT_CONFIG['num_epochs']) * 100\n","\n","    print(f\"Progress: {progress_pct:.1f}% | Best F1: {best_metrics['f1']:.4f} | ETA: {remaining_time/60:.1f}min | DeiT-{CASME2_DEIT_CONFIG['deit_variant']}\")\n","\n","# Training completion\n","total_time = time.time() - start_time\n","actual_epochs = CASME2_DEIT_CONFIG['num_epochs']\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CASME II DEIT TRANSFORMER ENHANCED BASELINE TRAINING COMPLETED\")\n","print(\"=\" * 70)\n","print(f\"Training time: {total_time/60:.1f} minutes\")\n","print(f\"Epochs completed: {actual_epochs}\")\n","print(f\"Best validation F1: {best_metrics['f1']:.4f} (epoch {best_metrics['epoch']})\")\n","print(f\"Final train F1: {training_history['train_f1'][-1]:.4f}\")\n","print(f\"Final validation F1: {training_history['val_f1'][-1]:.4f}\")\n","print(f\"DeiT Architecture: {CASME2_DEIT_CONFIG['deit_variant']} variant with position interpolation\")\n","\n","# Enhanced training documentation export for DeiT\n","results_dir = GLOBAL_CONFIG_CASME2['results_root']\n","os.makedirs(f\"{results_dir}/training_logs\", exist_ok=True)\n","\n","training_history_path = f\"{results_dir}/training_logs/casme2_deit_direct_training_history.json\"\n","\n","print(\"\\nExporting enhanced DeiT training documentation...\")\n","\n","try:\n","    # Create comprehensive training summary with DeiT-specific configuration\n","    training_summary = {\n","        'experiment_type': 'CASME2_DeiT_Enhanced_Baseline',\n","        'experiment_configuration': {\n","            'loss_function': 'Optimized Focal Loss' if CASME2_DEIT_CONFIG['use_focal_loss'] else 'CrossEntropy',\n","            'weight_approach': 'Per-class Alpha (sum=1.0)' if CASME2_DEIT_CONFIG['use_focal_loss'] else 'Inverse Sqrt Frequency',\n","            'focal_loss_gamma': CASME2_DEIT_CONFIG['focal_loss_gamma'],\n","            'focal_loss_alpha_weights': CASME2_DEIT_CONFIG['focal_loss_alpha_weights'],\n","            'crossentropy_class_weights': CASME2_DEIT_CONFIG['crossentropy_class_weights'],\n","            'deit_model': CASME2_DEIT_CONFIG['deit_model'],\n","            'deit_variant': CASME2_DEIT_CONFIG['deit_variant'],\n","            'input_size': CASME2_DEIT_CONFIG['input_size'],\n","            'patch_size': CASME2_DEIT_CONFIG['patch_size'],\n","            'distillation_token': CASME2_DEIT_CONFIG['use_distillation_token'],\n","            'interpolate_pos_encoding': CASME2_DEIT_CONFIG['interpolate_pos_encoding']\n","        },\n","        'training_history': safe_json_serialize_deit(training_history),\n","        'best_val_f1': float(best_metrics['f1']),\n","        'best_val_loss': float(best_metrics['loss']),\n","        'best_val_accuracy': float(best_metrics['accuracy']),\n","        'best_epoch': int(best_metrics['epoch']),\n","        'total_epochs': int(actual_epochs),\n","        'total_time_minutes': float(total_time / 60),\n","        'average_epoch_time_seconds': float(np.mean(training_history['epoch_time'])),\n","        'config': safe_json_serialize_deit(CASME2_DEIT_CONFIG),\n","        'final_train_f1': float(training_history['train_f1'][-1]),\n","        'final_val_f1': float(training_history['val_f1'][-1]),\n","        'model_checkpoint': 'casme2_deit_direct_best_f1.pth',\n","        'dataset_info': {\n","            'name': 'CASME_II',\n","            'total_samples': 255,\n","            'train_samples': len(train_dataset),\n","            'val_samples': len(val_dataset),\n","            'num_classes': 7,\n","            'class_names': CASME2_CLASSES\n","        },\n","        'architecture_info': {\n","            'model_type': 'DeiTCASME2Baseline',\n","            'backbone': CASME2_DEIT_CONFIG['deit_model'],\n","            'variant': CASME2_DEIT_CONFIG['deit_variant'],\n","            'input_size': f\"{CASME2_DEIT_CONFIG['input_size']}x{CASME2_DEIT_CONFIG['input_size']}\",\n","            'patch_size': f\"{CASME2_DEIT_CONFIG['patch_size']}x{CASME2_DEIT_CONFIG['patch_size']}\",\n","            'hidden_dim': CASME2_DEIT_CONFIG['expected_hidden_dim'],\n","            'distillation_token': CASME2_DEIT_CONFIG['use_distillation_token'],\n","            'position_interpolation': CASME2_DEIT_CONFIG['interpolate_pos_encoding'],\n","            'architecture_approach': 'DeiTModel + Custom Classification Head (Medical Proven)',\n","            'total_tokens': f\"CLS + Distillation + {(CASME2_DEIT_CONFIG['input_size']//CASME2_DEIT_CONFIG['patch_size'])**2} patches\"\n","        },\n","        'enhanced_features': {\n","            'medical_proven_architecture': True,\n","            'position_encoding_interpolation': True,\n","            'fixed_checkpoint_saving': True,\n","            'device_migration_complete': True,\n","            'robust_error_handling': True,\n","            'multi_criteria_checkpoint_logic': True,\n","            'memory_optimized_training': True,\n","            'clean_dataset_loading': True,\n","            'retry_checkpoint_logic': True\n","        }\n","    }\n","\n","    # Save with proper JSON serialization\n","    with open(training_history_path, 'w') as f:\n","        json.dump(training_summary, f, indent=2)\n","\n","    print(f\"Enhanced DeiT training documentation saved: {training_history_path}\")\n","    print(f\"Experiment details: {training_summary['experiment_configuration']['loss_function']} loss\")\n","    if CASME2_DEIT_CONFIG['use_focal_loss']:\n","        print(f\"  Gamma: {CASME2_DEIT_CONFIG['focal_loss_gamma']}, Alpha Sum: {sum(CASME2_DEIT_CONFIG['focal_loss_alpha_weights']):.3f}\")\n","    print(f\"Model variant: {CASME2_DEIT_CONFIG['deit_model']} ({CASME2_DEIT_CONFIG['deit_variant']})\")\n","    print(f\"Architecture approach: DeiTModel + Custom Head (Medical Proven)\")\n","    print(f\"Position interpolation: {CASME2_DEIT_CONFIG['interpolate_pos_encoding']}\")\n","    print(f\"Checkpoint saving: FIXED with complete device migration\")\n","\n","except Exception as e:\n","    print(f\"Warning: Could not save DeiT training documentation: {e}\")\n","    print(\"Training completed successfully, but documentation export failed\")\n","\n","# Enhanced memory cleanup for DeiT\n","if torch.cuda.is_available():\n","    torch.cuda.synchronize()\n","    torch.cuda.empty_cache()\n","\n","print(\"\\nNext: Cell 3 - CASME II DeiT Enhanced Evaluation\")\n","print(\"Enhanced DeiT training pipeline completed successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["075f09cb27764dabb07ea14a14f2c0d8","d44f8b40a02049b0a164fe0324dd3a28","69b02d2cbea047bca8fc3c6e3acad99f","f4b18d8bc88747b7894f700e0a10dd6f","82a594e6d47c4b79bc76f8a4cde71b20","6c44bc8abe65492d976e8738a58ca272","e1ddac9001f5432ea93f309b913271db","f81cf668db4f4943b4c9ee6735c53335","04d935723bf249d5889fd550f00af45f","47a8bf14868f444e992d9d00412f829a","68d711b8fc5b4047a3a465da6250aca1"]},"collapsed":true,"cellView":"form","id":"ANMiGSH5s9PK","executionInfo":{"status":"ok","timestamp":1758874082696,"user_tz":-420,"elapsed":765900,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"78ea72cf-1bd3-45cd-cf84-e2e6b7fef733"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CASME II DeiT Enhanced Training Pipeline with Fixed Checkpoints\n","======================================================================\n","Loss Function: Optimized Focal Loss\n","Focal Loss Parameters:\n","  Gamma: 2.0\n","  Per-class Alpha: [0.053, 0.067, 0.094, 0.102, 0.106, 0.201, 0.376]\n","  Alpha Sum: 0.999\n","DeiT Architecture: base variant with distillation token\n","Input resolution: 384x384\n","Position interpolation: True\n","Training epochs: 50\n","Scheduler patience: 3\n","\n","Creating CASME II DeiT training datasets...\n","Loading CASME II train dataset for DeiT training...\n","Loaded 201 CASME II train samples\n","  others: 79 samples (39.3%)\n","  disgust: 50 samples (24.9%)\n","  happiness: 25 samples (12.4%)\n","  repression: 21 samples (10.4%)\n","  surprise: 20 samples (10.0%)\n","  sadness: 5 samples (2.5%)\n","  fear: 1 samples (0.5%)\n","Preloading 201 train images to RAM for DeiT...\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/349M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075f09cb27764dabb07ea14a14f2c0d8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRAIN RAM caching completed: 201 images, ~0.36GB\n","Loading CASME II val dataset for DeiT training...\n","Loaded 26 CASME II val samples\n","  others: 10 samples (38.5%)\n","  disgust: 6 samples (23.1%)\n","  happiness: 3 samples (11.5%)\n","  repression: 3 samples (11.5%)\n","  surprise: 2 samples (7.7%)\n","  sadness: 1 samples (3.8%)\n","  fear: 1 samples (3.8%)\n","Preloading 26 val images to RAM for DeiT...\n","VAL RAM caching completed: 26 images, ~0.05GB\n","Training batches: 13 (samples: 201)\n","Validation batches: 2 (samples: 26)\n","\n","Initializing CASME II DeiT enhanced model...\n","DeiT feature dimension: 768\n","DeiT distillation token: Available in model\n","DeiT CASME II: 768 -> 512 -> 128 -> 7\n","Using Optimized Focal Loss with gamma=2.0\n","Per-class alpha weights: [0.053, 0.067, 0.094, 0.102, 0.106, 0.201, 0.376]\n","Alpha sum: 0.999\n","Scheduler: ReduceLROnPlateau monitoring val_f1_macro\n","Optimizer: AdamW (LR=1e-05)\n","Scheduler: ReduceLROnPlateau (patience=3)\n","Criterion: Optimized Focal Loss\n","DeiT Architecture: base variant with position interpolation\n","\n","Starting CASME II DeiT enhanced training with fixed checkpoints...\n","Training configuration: 50 epochs\n","Position interpolation: 224px -> 384px with DeiTModel + custom head\n","======================================================================\n","\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 1/50: 100%|██████████| 13/13 [00:10<00:00,  1.23it/s, Loss=0.1076, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 1/50: 100%|██████████| 2/2 [00:00<00:00,  2.71it/s, Val Loss=0.0475, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.1044, F1: 0.1245, Acc: 0.2388\n","Val   - Loss: 0.1552, F1: 0.1076, Acc: 0.3077\n","Time  - Epoch: 11.4s, LR: 1.00e-05\n","Saving checkpoint with enhanced device migration...\n","  Migrating model state dict to CPU...\n","  Migrating optimizer state dict to CPU...\n","  Migrating scheduler state dict to CPU...\n","  Device migration completed successfully\n","  Attempt 1: Saving to temporary file...\n","Checkpoint saved successfully: casme2_deit_direct_best_f1.pth\n","  DeiT variant: base\n","  Model: facebook/deit-base-distilled-patch16-224\n","New best DeiT model: Higher F1 - F1: 0.1076\n","Progress: 2.0% | Best F1: 0.1076 | ETA: 11.3min | DeiT-base\n","\n","Epoch 2/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 2/50: 100%|██████████| 13/13 [00:09<00:00,  1.35it/s, Loss=0.0808, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 2/50: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s, Val Loss=0.0476, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0866, F1: 0.1755, Acc: 0.3980\n","Val   - Loss: 0.1510, F1: 0.2459, Acc: 0.3846\n","Time  - Epoch: 10.5s, LR: 1.00e-05\n","Saving checkpoint with enhanced device migration...\n","  Migrating model state dict to CPU...\n","  Migrating optimizer state dict to CPU...\n","  Migrating scheduler state dict to CPU...\n","  Device migration completed successfully\n","  Attempt 1: Saving to temporary file...\n","Checkpoint saved successfully: casme2_deit_direct_best_f1.pth\n","  DeiT variant: base\n","  Model: facebook/deit-base-distilled-patch16-224\n","New best DeiT model: Higher F1 - F1: 0.2459\n","Progress: 4.0% | Best F1: 0.2459 | ETA: 10.7min | DeiT-base\n","\n","Epoch 3/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 3/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0768, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 3/50: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s, Val Loss=0.0496, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0753, F1: 0.2678, Acc: 0.4179\n","Val   - Loss: 0.1435, F1: 0.2022, Acc: 0.3462\n","Time  - Epoch: 10.7s, LR: 1.00e-05\n","Progress: 6.0% | Best F1: 0.2459 | ETA: 9.8min | DeiT-base\n","\n","Epoch 4/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 4/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0685, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 4/50: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s, Val Loss=0.0461, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0672, F1: 0.3470, Acc: 0.4876\n","Val   - Loss: 0.1479, F1: 0.2173, Acc: 0.3462\n","Time  - Epoch: 10.7s, LR: 1.00e-05\n","Progress: 8.0% | Best F1: 0.2459 | ETA: 9.3min | DeiT-base\n","\n","Epoch 5/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 5/50: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, Loss=0.0590, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 5/50: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s, Val Loss=0.0436, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0592, F1: 0.4234, Acc: 0.5423\n","Val   - Loss: 0.1467, F1: 0.2007, Acc: 0.3846\n","Time  - Epoch: 10.9s, LR: 1.00e-05\n","Progress: 10.0% | Best F1: 0.2459 | ETA: 8.9min | DeiT-base\n","\n","Epoch 6/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 6/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0526, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 6/50: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s, Val Loss=0.0425, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0524, F1: 0.4825, Acc: 0.6269\n","Val   - Loss: 0.1464, F1: 0.2667, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-05\n","Saving checkpoint with enhanced device migration...\n","  Migrating model state dict to CPU...\n","  Migrating optimizer state dict to CPU...\n","  Migrating scheduler state dict to CPU...\n","  Device migration completed successfully\n","  Attempt 1: Saving to temporary file...\n","Checkpoint saved successfully: casme2_deit_direct_best_f1.pth\n","  DeiT variant: base\n","  Model: facebook/deit-base-distilled-patch16-224\n","New best DeiT model: Higher F1 - F1: 0.2667\n","Progress: 12.0% | Best F1: 0.2667 | ETA: 9.0min | DeiT-base\n","\n","Epoch 7/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 7/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0479, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 7/50: 100%|██████████| 2/2 [00:00<00:00,  2.27it/s, Val Loss=0.0422, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0502, F1: 0.5003, Acc: 0.6269\n","Val   - Loss: 0.1466, F1: 0.3030, Acc: 0.4231\n","Time  - Epoch: 10.8s, LR: 1.00e-05\n","Saving checkpoint with enhanced device migration...\n","  Migrating model state dict to CPU...\n","  Migrating optimizer state dict to CPU...\n","  Migrating scheduler state dict to CPU...\n","  Device migration completed successfully\n","  Attempt 1: Saving to temporary file...\n","Checkpoint saved successfully: casme2_deit_direct_best_f1.pth\n","  DeiT variant: base\n","  Model: facebook/deit-base-distilled-patch16-224\n","New best DeiT model: Higher F1 - F1: 0.3030\n","Progress: 14.0% | Best F1: 0.3030 | ETA: 8.9min | DeiT-base\n","\n","Epoch 8/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 8/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0430, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 8/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0411, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0434, F1: 0.5417, Acc: 0.6816\n","Val   - Loss: 0.1508, F1: 0.2060, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-05\n","Progress: 16.0% | Best F1: 0.3030 | ETA: 8.5min | DeiT-base\n","\n","Epoch 9/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 9/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0391, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 9/50: 100%|██████████| 2/2 [00:00<00:00,  2.05it/s, Val Loss=0.0420, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0378, F1: 0.7425, Acc: 0.7313\n","Val   - Loss: 0.1500, F1: 0.1857, Acc: 0.3077\n","Time  - Epoch: 10.9s, LR: 1.00e-05\n","Progress: 18.0% | Best F1: 0.3030 | ETA: 8.2min | DeiT-base\n","\n","Epoch 10/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 10/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0349, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 10/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0394, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0347, F1: 0.6428, Acc: 0.7711\n","Val   - Loss: 0.1541, F1: 0.1887, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-05\n","Progress: 20.0% | Best F1: 0.3030 | ETA: 8.0min | DeiT-base\n","\n","Epoch 11/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 11/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0280, LR=1.00e-05, DeiT=base]\n","CASME II DeiT Validation Epoch 11/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0399, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0287, F1: 0.8594, Acc: 0.8358\n","Val   - Loss: 0.1528, F1: 0.1857, Acc: 0.3077\n","Time  - Epoch: 10.9s, LR: 5.00e-06\n","Progress: 22.0% | Best F1: 0.3030 | ETA: 7.7min | DeiT-base\n","\n","Epoch 12/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 12/50: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s, Loss=0.0252, LR=5.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 12/50: 100%|██████████| 2/2 [00:00<00:00,  2.03it/s, Val Loss=0.0400, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0259, F1: 0.8746, Acc: 0.8756\n","Val   - Loss: 0.1550, F1: 0.1857, Acc: 0.3077\n","Time  - Epoch: 11.0s, LR: 5.00e-06\n","Progress: 24.0% | Best F1: 0.3030 | ETA: 7.5min | DeiT-base\n","\n","Epoch 13/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 13/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0229, LR=5.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 13/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0410, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0228, F1: 0.8788, Acc: 0.8706\n","Val   - Loss: 0.1514, F1: 0.1755, Acc: 0.3077\n","Time  - Epoch: 10.9s, LR: 5.00e-06\n","Progress: 26.0% | Best F1: 0.3030 | ETA: 7.2min | DeiT-base\n","\n","Epoch 14/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 14/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0212, LR=5.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 14/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0401, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0211, F1: 0.9182, Acc: 0.9154\n","Val   - Loss: 0.1527, F1: 0.1857, Acc: 0.3077\n","Time  - Epoch: 11.0s, LR: 5.00e-06\n","Progress: 28.0% | Best F1: 0.3030 | ETA: 7.0min | DeiT-base\n","\n","Epoch 15/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 15/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0195, LR=5.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 15/50: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s, Val Loss=0.0399, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0196, F1: 0.9074, Acc: 0.8955\n","Val   - Loss: 0.1542, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 11.0s, LR: 2.50e-06\n","Progress: 30.0% | Best F1: 0.3030 | ETA: 6.8min | DeiT-base\n","\n","Epoch 16/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 16/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0173, LR=2.50e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 16/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0399, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0172, F1: 0.9158, Acc: 0.9254\n","Val   - Loss: 0.1515, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 2.50e-06\n","Progress: 32.0% | Best F1: 0.3030 | ETA: 6.6min | DeiT-base\n","\n","Epoch 17/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 17/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0160, LR=2.50e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 17/50: 100%|██████████| 2/2 [00:00<00:00,  2.04it/s, Val Loss=0.0383, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0167, F1: 0.9345, Acc: 0.9353\n","Val   - Loss: 0.1554, F1: 0.1755, Acc: 0.3077\n","Time  - Epoch: 11.0s, LR: 2.50e-06\n","Progress: 34.0% | Best F1: 0.3030 | ETA: 6.3min | DeiT-base\n","\n","Epoch 18/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 18/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0147, LR=2.50e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 18/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0392, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0156, F1: 0.9699, Acc: 0.9701\n","Val   - Loss: 0.1543, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 2.50e-06\n","Progress: 36.0% | Best F1: 0.3030 | ETA: 6.1min | DeiT-base\n","\n","Epoch 19/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 19/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0139, LR=2.50e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 19/50: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s, Val Loss=0.0393, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0150, F1: 0.9835, Acc: 0.9701\n","Val   - Loss: 0.1530, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.25e-06\n","Progress: 38.0% | Best F1: 0.3030 | ETA: 5.9min | DeiT-base\n","\n","Epoch 20/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 20/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0146, LR=1.25e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 20/50: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s, Val Loss=0.0388, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0148, F1: 0.9770, Acc: 0.9652\n","Val   - Loss: 0.1542, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.25e-06\n","Progress: 40.0% | Best F1: 0.3030 | ETA: 5.7min | DeiT-base\n","\n","Epoch 21/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 21/50: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s, Loss=0.0144, LR=1.25e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 21/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0396, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0140, F1: 0.9793, Acc: 0.9701\n","Val   - Loss: 0.1551, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 11.0s, LR: 1.25e-06\n","Progress: 42.0% | Best F1: 0.3030 | ETA: 5.5min | DeiT-base\n","\n","Epoch 22/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 22/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0137, LR=1.25e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 22/50: 100%|██████████| 2/2 [00:00<00:00,  2.11it/s, Val Loss=0.0391, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0137, F1: 0.9839, Acc: 0.9701\n","Val   - Loss: 0.1552, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.25e-06\n","Progress: 44.0% | Best F1: 0.3030 | ETA: 5.3min | DeiT-base\n","\n","Epoch 23/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 23/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0128, LR=1.25e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 23/50: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s, Val Loss=0.0395, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0130, F1: 0.9743, Acc: 0.9751\n","Val   - Loss: 0.1552, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 10.8s, LR: 1.00e-06\n","Progress: 46.0% | Best F1: 0.3030 | ETA: 5.1min | DeiT-base\n","\n","Epoch 24/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 24/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0129, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 24/50: 100%|██████████| 2/2 [00:00<00:00,  2.02it/s, Val Loss=0.0395, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0131, F1: 0.9915, Acc: 0.9851\n","Val   - Loss: 0.1551, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 48.0% | Best F1: 0.3030 | ETA: 4.9min | DeiT-base\n","\n","Epoch 25/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 25/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0126, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 25/50: 100%|██████████| 2/2 [00:00<00:00,  2.02it/s, Val Loss=0.0399, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0129, F1: 0.9790, Acc: 0.9851\n","Val   - Loss: 0.1550, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 50.0% | Best F1: 0.3030 | ETA: 4.7min | DeiT-base\n","\n","Epoch 26/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 26/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0116, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 26/50: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s, Val Loss=0.0393, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0117, F1: 0.9916, Acc: 0.9851\n","Val   - Loss: 0.1541, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 52.0% | Best F1: 0.3030 | ETA: 4.5min | DeiT-base\n","\n","Epoch 27/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 27/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0137, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 27/50: 100%|██████████| 2/2 [00:00<00:00,  2.11it/s, Val Loss=0.0385, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0142, F1: 0.9856, Acc: 0.9751\n","Val   - Loss: 0.1555, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 54.0% | Best F1: 0.3030 | ETA: 4.3min | DeiT-base\n","\n","Epoch 28/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 28/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0115, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 28/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0386, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0116, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1553, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 56.0% | Best F1: 0.3030 | ETA: 4.1min | DeiT-base\n","\n","Epoch 29/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 29/50: 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, Loss=0.0130, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 29/50: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s, Val Loss=0.0389, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0131, F1: 0.9893, Acc: 0.9801\n","Val   - Loss: 0.1559, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 10.8s, LR: 1.00e-06\n","Progress: 58.0% | Best F1: 0.3030 | ETA: 3.9min | DeiT-base\n","\n","Epoch 30/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 30/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0125, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 30/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0395, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0123, F1: 0.9954, Acc: 0.9950\n","Val   - Loss: 0.1561, F1: 0.1911, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 60.0% | Best F1: 0.3030 | ETA: 3.8min | DeiT-base\n","\n","Epoch 31/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 31/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0112, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 31/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0396, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0114, F1: 0.9909, Acc: 0.9851\n","Val   - Loss: 0.1562, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 62.0% | Best F1: 0.3030 | ETA: 3.6min | DeiT-base\n","\n","Epoch 32/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 32/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0106, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 32/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0393, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0108, F1: 0.9909, Acc: 0.9851\n","Val   - Loss: 0.1553, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 64.0% | Best F1: 0.3030 | ETA: 3.4min | DeiT-base\n","\n","Epoch 33/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 33/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0107, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 33/50: 100%|██████████| 2/2 [00:00<00:00,  2.03it/s, Val Loss=0.0393, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0107, F1: 0.9953, Acc: 0.9900\n","Val   - Loss: 0.1543, F1: 0.2130, Acc: 0.3846\n","Time  - Epoch: 11.0s, LR: 1.00e-06\n","Progress: 66.0% | Best F1: 0.3030 | ETA: 3.2min | DeiT-base\n","\n","Epoch 34/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 34/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0110, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 34/50: 100%|██████████| 2/2 [00:00<00:00,  2.05it/s, Val Loss=0.0392, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0113, F1: 0.9929, Acc: 0.9851\n","Val   - Loss: 0.1551, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 68.0% | Best F1: 0.3030 | ETA: 3.0min | DeiT-base\n","\n","Epoch 35/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 35/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0101, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 35/50: 100%|██████████| 2/2 [00:00<00:00,  2.05it/s, Val Loss=0.0388, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0100, F1: 0.9793, Acc: 0.9900\n","Val   - Loss: 0.1554, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 70.0% | Best F1: 0.3030 | ETA: 2.8min | DeiT-base\n","\n","Epoch 36/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 36/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0109, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 36/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0383, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0105, F1: 0.9930, Acc: 0.9851\n","Val   - Loss: 0.1552, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 72.0% | Best F1: 0.3030 | ETA: 2.6min | DeiT-base\n","\n","Epoch 37/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 37/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0092, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 37/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0390, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0096, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1549, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 11.0s, LR: 1.00e-06\n","Progress: 74.0% | Best F1: 0.3030 | ETA: 2.4min | DeiT-base\n","\n","Epoch 38/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 38/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0098, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 38/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0390, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0111, F1: 0.9903, Acc: 0.9851\n","Val   - Loss: 0.1554, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 76.0% | Best F1: 0.3030 | ETA: 2.2min | DeiT-base\n","\n","Epoch 39/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 39/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0101, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 39/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0385, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0100, F1: 1.0000, Acc: 1.0000\n","Val   - Loss: 0.1564, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 78.0% | Best F1: 0.3030 | ETA: 2.1min | DeiT-base\n","\n","Epoch 40/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 40/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0099, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 40/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0388, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0099, F1: 0.9953, Acc: 0.9900\n","Val   - Loss: 0.1557, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 80.0% | Best F1: 0.3030 | ETA: 1.9min | DeiT-base\n","\n","Epoch 41/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 41/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0093, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 41/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0394, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0094, F1: 0.9954, Acc: 0.9900\n","Val   - Loss: 0.1555, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 82.0% | Best F1: 0.3030 | ETA: 1.7min | DeiT-base\n","\n","Epoch 42/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 42/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0093, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 42/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0392, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0093, F1: 0.9892, Acc: 0.9801\n","Val   - Loss: 0.1557, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 11.0s, LR: 1.00e-06\n","Progress: 84.0% | Best F1: 0.3030 | ETA: 1.5min | DeiT-base\n","\n","Epoch 43/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 43/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0092, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 43/50: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s, Val Loss=0.0386, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0090, F1: 0.9954, Acc: 0.9950\n","Val   - Loss: 0.1558, F1: 0.2130, Acc: 0.3846\n","Time  - Epoch: 11.0s, LR: 1.00e-06\n","Progress: 86.0% | Best F1: 0.3030 | ETA: 1.3min | DeiT-base\n","\n","Epoch 44/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 44/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0095, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 44/50: 100%|██████████| 2/2 [00:00<00:00,  2.04it/s, Val Loss=0.0388, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0093, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1558, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 88.0% | Best F1: 0.3030 | ETA: 1.1min | DeiT-base\n","\n","Epoch 45/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 45/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0088, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 45/50: 100%|██████████| 2/2 [00:00<00:00,  2.05it/s, Val Loss=0.0391, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0088, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1557, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 90.0% | Best F1: 0.3030 | ETA: 0.9min | DeiT-base\n","\n","Epoch 46/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 46/50: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Loss=0.0089, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 46/50: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s, Val Loss=0.0393, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0086, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1549, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 92.0% | Best F1: 0.3030 | ETA: 0.7min | DeiT-base\n","\n","Epoch 47/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 47/50: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Loss=0.0080, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 47/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0388, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0080, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1562, F1: 0.1966, Acc: 0.3462\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 94.0% | Best F1: 0.3030 | ETA: 0.6min | DeiT-base\n","\n","Epoch 48/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 48/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0083, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 48/50: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s, Val Loss=0.0384, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0083, F1: 0.9856, Acc: 0.9950\n","Val   - Loss: 0.1561, F1: 0.2130, Acc: 0.3846\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 96.0% | Best F1: 0.3030 | ETA: 0.4min | DeiT-base\n","\n","Epoch 49/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 49/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0095, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 49/50: 100%|██████████| 2/2 [00:00<00:00,  2.03it/s, Val Loss=0.0387, DeiT=base]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0093, F1: 0.9953, Acc: 0.9900\n","Val   - Loss: 0.1557, F1: 0.2130, Acc: 0.3846\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 98.0% | Best F1: 0.3030 | ETA: 0.2min | DeiT-base\n","\n","Epoch 50/50\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Training Epoch 50/50: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Loss=0.0079, LR=1.00e-06, DeiT=base]\n","CASME II DeiT Validation Epoch 50/50: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s, Val Loss=0.0386, DeiT=base]"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.0081, F1: 0.9977, Acc: 0.9950\n","Val   - Loss: 0.1563, F1: 0.2130, Acc: 0.3846\n","Time  - Epoch: 10.9s, LR: 1.00e-06\n","Progress: 100.0% | Best F1: 0.3030 | ETA: 0.0min | DeiT-base\n","\n","======================================================================\n","CASME II DEIT TRANSFORMER ENHANCED BASELINE TRAINING COMPLETED\n","======================================================================\n","Training time: 9.3 minutes\n","Epochs completed: 50\n","Best validation F1: 0.3030 (epoch 7)\n","Final train F1: 0.9977\n","Final validation F1: 0.2130\n","DeiT Architecture: base variant with position interpolation\n","\n","Exporting enhanced DeiT training documentation...\n","Enhanced DeiT training documentation saved: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/results/02_04_deit_casme2-af/training_logs/casme2_deit_direct_training_history.json\n","Experiment details: Optimized Focal Loss loss\n","  Gamma: 2.0, Alpha Sum: 0.999\n","Model variant: facebook/deit-base-distilled-patch16-224 (base)\n","Architecture approach: DeiTModel + Custom Head (Medical Proven)\n","Position interpolation: True\n","Checkpoint saving: FIXED with complete device migration\n","\n","Next: Cell 3 - CASME II DeiT Enhanced Evaluation\n","Enhanced DeiT training pipeline completed successfully!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# @title Cell 3: CASME II DeiT Direct Baseline Evaluation\n","\n","# File: 02_04_DeiT_Direct_Baseline_Cell3.py\n","# Location: experiments/02_04_DeiT_Direct_Baseline.ipynb\n","# Purpose: Evaluation framework for trained CASME II DeiT micro-expression recognition model with distillation token\n","\n","import os\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","\n","# Evaluation specific imports\n","from sklearn.metrics import (\n","    accuracy_score, precision_recall_fscore_support,\n","    classification_report, confusion_matrix,\n","    roc_curve, auc\n",")\n","from sklearn.preprocessing import label_binarize\n","from concurrent.futures import ThreadPoolExecutor\n","import multiprocessing as mp\n","import pickle\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Enhanced test dataset for CASME II DeiT evaluation with clean loading\n","class CASME2DatasetEvaluationDeiT(Dataset):\n","    \"\"\"Enhanced CASME II test dataset with clean evaluation support for DeiT\"\"\"\n","\n","    def __init__(self, split_metadata, dataset_root, transform=None, split='test', use_ram_cache=True):\n","        self.metadata = split_metadata[split]['samples']\n","        self.dataset_root = dataset_root\n","        self.transform = transform\n","        self.split = split\n","        self.use_ram_cache = use_ram_cache\n","        self.images = []\n","        self.labels = []\n","        self.sample_ids = []\n","        self.emotions = []\n","        self.subjects = []\n","        self.cached_images = []\n","\n","        print(f\"Loading CASME II {split} dataset for DeiT evaluation...\")\n","\n","        # Process metadata for evaluation\n","        for sample in self.metadata:\n","            image_path = os.path.join(dataset_root, split, sample['image_filename'])\n","            self.images.append(image_path)\n","            self.labels.append(CLASS_TO_IDX[sample['emotion']])\n","            self.sample_ids.append(sample['sample_id'])\n","            self.emotions.append(sample['emotion'])\n","            self.subjects.append(sample['subject'])\n","\n","        print(f\"Loaded {len(self.images)} CASME II {split} samples for DeiT evaluation\")\n","        self._print_evaluation_distribution()\n","\n","        # RAM caching for fast evaluation\n","        if self.use_ram_cache:\n","            self._preload_to_ram_evaluation()\n","\n","    def _print_evaluation_distribution(self):\n","        \"\"\"Print comprehensive distribution for evaluation analysis\"\"\"\n","        if len(self.labels) == 0:\n","            print(\"No test samples found!\")\n","            return\n","\n","        label_counts = {}\n","        subject_counts = {}\n","\n","        for label, subject in zip(self.labels, self.subjects):\n","            label_counts[label] = label_counts.get(label, 0) + 1\n","            subject_counts[subject] = subject_counts.get(subject, 0) + 1\n","\n","        print(\"Test set class distribution:\")\n","        for label, count in sorted(label_counts.items()):\n","            class_name = CASME2_CLASSES[label]\n","            percentage = (count / len(self.labels)) * 100\n","            print(f\"  {class_name}: {count} samples ({percentage:.1f}%)\")\n","\n","        print(f\"Test set covers {len(subject_counts)} subjects\")\n","\n","        # Check for missing classes\n","        missing_classes = []\n","        for i, class_name in enumerate(CASME2_CLASSES):\n","            if i not in label_counts:\n","                missing_classes.append(class_name)\n","\n","        if missing_classes:\n","            print(f\"Missing classes in test set: {missing_classes}\")\n","\n","    def _preload_to_ram_evaluation(self):\n","        \"\"\"Clean RAM preloading optimized for DeiT evaluation at 384px\"\"\"\n","        print(f\"Preloading {len(self.images)} test images to RAM for DeiT evaluation...\")\n","\n","        valid_images = 0\n","        self.cached_images = [None] * len(self.images)\n","\n","        # Clean loading for evaluation stability\n","        for i, img_path in enumerate(self.images):\n","            try:\n","                image = Image.open(img_path).convert('RGB')\n","                if image.size != (384, 384):\n","                    image = image.resize((384, 384), Image.Resampling.LANCZOS)\n","                self.cached_images[i] = image\n","                valid_images += 1\n","            except Exception as e:\n","                print(f\"Error loading {img_path}: {e}\")\n","                # Create neutral placeholder\n","                self.cached_images[i] = Image.new('RGB', (384, 384), (128, 128, 128))\n","\n","        ram_usage_gb = len(self.cached_images) * 384 * 384 * 3 * 4 / 1e9\n","        print(f\"Test RAM caching completed: {valid_images} valid images, ~{ram_usage_gb:.2f}GB\")\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        if self.use_ram_cache and self.cached_images[idx] is not None:\n","            image = self.cached_images[idx].copy()\n","        else:\n","            try:\n","                image = Image.open(self.images[idx]).convert('RGB')\n","                if image.size != (384, 384):\n","                    image = image.resize((384, 384), Image.Resampling.LANCZOS)\n","            except:\n","                image = Image.new('RGB', (384, 384), (128, 128, 128))\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return (image, self.labels[idx], self.sample_ids[idx],\n","                self.emotions[idx], self.subjects[idx], os.path.basename(self.images[idx]))\n","\n","# CASME II DeiT evaluation configuration\n","EVALUATION_CONFIG_CASME2_DEIT = {\n","    'model_type': 'DeiT_CASME2_Direct_Baseline',\n","    'task_type': 'micro_expression_recognition',\n","    'num_classes': 7,\n","    'class_names': CASME2_CLASSES,\n","    'checkpoint_file': 'casme2_deit_direct_best_f1.pth',\n","    'dataset_name': 'CASME_II',\n","    'input_size': '384x384',\n","    'evaluation_protocol': 'stratified_split',\n","    'architecture': 'deit_transformer_distillation'\n","}\n","\n","print(\"CASME II DeiT Direct Baseline Evaluation Framework\")\n","print(\"=\" * 65)\n","print(f\"Model: {EVALUATION_CONFIG_CASME2_DEIT['model_type']}\")\n","print(f\"Task: {EVALUATION_CONFIG_CASME2_DEIT['task_type']}\")\n","print(f\"Classes: {EVALUATION_CONFIG_CASME2_DEIT['class_names']}\")\n","print(f\"Input size: {EVALUATION_CONFIG_CASME2_DEIT['input_size']}\")\n","print(f\"Architecture: {EVALUATION_CONFIG_CASME2_DEIT['architecture']}\")\n","\n","# FIXED: Simplified logits extraction for DeiT fixed architecture\n","def extract_logits_safe_casme2_deit(outputs_all):\n","    \"\"\"Simplified logits extraction for CASME II DeiT fixed architecture (DeiTModel + custom head)\"\"\"\n","    # FIXED: With DeiTModel + custom head, output is directly a tensor\n","    if isinstance(outputs_all, torch.Tensor):\n","        return outputs_all\n","    # Fallback for other structures\n","    if isinstance(outputs_all, (tuple, list)):\n","        return outputs_all[0]\n","    if isinstance(outputs_all, dict):\n","        for key in ('logits', 'prediction', 'outputs'):\n","            value = outputs_all.get(key)\n","            if isinstance(value, torch.Tensor):\n","                return value\n","    raise RuntimeError(\"Unable to extract tensor logits from CASME II DeiT model output\")\n","\n","def load_trained_model_casme2_deit(checkpoint_path, device):\n","    \"\"\"Load trained CASME II DeiT model with fixed architecture compatibility\"\"\"\n","    print(f\"Loading trained CASME II DeiT model from: {checkpoint_path}\")\n","\n","    if not os.path.exists(checkpoint_path):\n","        raise FileNotFoundError(f\"DeiT checkpoint not found: {checkpoint_path}\")\n","\n","    # Multiple loading approaches for maximum compatibility\n","    checkpoint = None\n","    loading_method = \"unknown\"\n","\n","    try:\n","        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n","        loading_method = \"standard\"\n","    except Exception as e1:\n","        try:\n","            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n","            loading_method = \"weights_only_false\"\n","        except Exception as e2:\n","            try:\n","                import pickle\n","                with open(checkpoint_path, 'rb') as f:\n","                    checkpoint = pickle.load(f)\n","                loading_method = \"pickle\"\n","            except Exception as e3:\n","                raise RuntimeError(f\"All DeiT loading methods failed: {e1}, {e2}, {e3}\")\n","\n","    print(f\"DeiT checkpoint loaded using: {loading_method}\")\n","\n","    # Extract DeiT-specific configuration\n","    deit_config = checkpoint.get('casme2_deit_config', {})\n","    deit_variant = checkpoint.get('deit_variant', 'small')\n","    deit_model_name = checkpoint.get('deit_model', 'facebook/deit-small-distilled-patch16-224')\n","\n","    print(f\"Detected DeiT variant: {deit_variant}\")\n","    print(f\"Detected DeiT model: {deit_model_name}\")\n","    print(f\"Architecture approach: DeiTModel + Custom Head (Medical Proven)\")\n","\n","    # FIXED: Initialize CASME II DeiT model with fixed architecture\n","    model = DeiTCASME2Baseline(\n","        num_classes=EVALUATION_CONFIG_CASME2_DEIT['num_classes'],\n","        dropout_rate=deit_config.get('dropout_rate', 0.2)\n","    ).to(device)\n","\n","    # Load state dict with fallback approaches\n","    state_dict = checkpoint.get('model_state_dict', checkpoint)\n","\n","    try:\n","        model.load_state_dict(state_dict, strict=True)\n","        print(\"DeiT model state loaded with strict=True\")\n","    except Exception as e:\n","        print(f\"Strict loading failed, trying non-strict: {str(e)[:100]}...\")\n","        try:\n","            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n","            if missing_keys or unexpected_keys:\n","                print(f\"Non-strict loading: Missing {len(missing_keys)}, Unexpected {len(unexpected_keys)}\")\n","            else:\n","                print(\"DeiT model state loaded with strict=False (no key mismatches)\")\n","        except Exception as e2:\n","            raise RuntimeError(f\"Both DeiT loading approaches failed: {e2}\")\n","\n","    model.eval()\n","\n","    # Extract training information\n","    training_info = {\n","        'best_val_f1': float(checkpoint.get('best_f1', 0.0)),\n","        'best_val_loss': float(checkpoint.get('best_loss', float('inf'))),\n","        'best_val_accuracy': float(checkpoint.get('best_acc', 0.0)),\n","        'best_epoch': int(checkpoint.get('epoch', 0)) + 1,\n","        'model_checkpoint': EVALUATION_CONFIG_CASME2_DEIT['checkpoint_file'],\n","        'num_classes': EVALUATION_CONFIG_CASME2_DEIT['num_classes'],\n","        'deit_variant': deit_variant,\n","        'deit_model': deit_model_name,\n","        'architecture_approach': 'DeiTModel + Custom Classification Head',\n","        'position_interpolation': deit_config.get('interpolate_pos_encoding', True),\n","        'config': checkpoint.get('casme2_deit_config', {})\n","    }\n","\n","    print(f\"DeiT model loaded successfully:\")\n","    print(f\"  Best validation F1: {training_info['best_val_f1']:.4f}\")\n","    print(f\"  Best validation accuracy: {training_info['best_val_accuracy']:.4f}\")\n","    print(f\"  Best epoch: {training_info['best_epoch']}\")\n","    print(f\"  DeiT variant: {training_info['deit_variant']}\")\n","    print(f\"  Position interpolation: {training_info['position_interpolation']}\")\n","    print(f\"  Model classes: {EVALUATION_CONFIG_CASME2_DEIT['num_classes']}\")\n","\n","    return model, training_info\n","\n","def run_model_inference_casme2_deit(model, test_loader, device):\n","    \"\"\"Run CASME II DeiT model inference with fixed architecture compatibility\"\"\"\n","    print(\"Running CASME II DeiT model inference on test set...\")\n","\n","    model.eval()\n","    all_predictions = []\n","    all_probabilities = []\n","    all_labels = []\n","    all_sample_ids = []\n","    all_emotions = []\n","    all_subjects = []\n","    all_filenames = []\n","\n","    inference_start = time.time()\n","\n","    with torch.no_grad():\n","        for batch_idx, (images, labels, sample_ids, emotions, subjects, filenames) in enumerate(\n","            tqdm(test_loader, desc=\"CASME II DeiT Inference\")):\n","\n","            images = images.to(device)\n","\n","            # FIXED: Forward pass dengan simplified output extraction\n","            try:\n","                outputs_raw = model(images)\n","                outputs = extract_logits_safe_casme2_deit(outputs_raw)\n","            except Exception as e:\n","                print(f\"Error in DeiT model forward pass: {e}\")\n","                # Fallback - should not be needed with fixed architecture\n","                outputs = model(images)\n","\n","            # Validate output shape for 7 CASME II classes\n","            if outputs.shape[1] != 7:\n","                print(f\"Warning: Expected 7 classes output, got {outputs.shape[1]}\")\n","\n","            # Get probabilities and predictions\n","            probabilities = torch.softmax(outputs, dim=1)\n","            predictions = torch.argmax(probabilities, dim=1)\n","\n","            # Store results (CPU for memory efficiency)\n","            all_predictions.extend(predictions.cpu().numpy())\n","            all_probabilities.extend(probabilities.cpu().numpy())\n","            all_labels.extend(labels.numpy())\n","            all_sample_ids.extend(sample_ids)\n","            all_emotions.extend(emotions)\n","            all_subjects.extend(subjects)\n","            all_filenames.extend(filenames)\n","\n","    inference_time = time.time() - inference_start\n","\n","    # Convert to arrays\n","    predictions_array = np.array(all_predictions)\n","    probabilities_array = np.array(all_probabilities)\n","    labels_array = np.array(all_labels)\n","\n","    print(f\"CASME II DeiT inference completed: {len(predictions_array)} samples in {inference_time:.2f}s\")\n","\n","    # Analyze prediction distribution\n","    unique_predictions, pred_counts = np.unique(predictions_array, return_counts=True)\n","    print(f\"Predicted classes: {[CASME2_CLASSES[i] for i in unique_predictions]}\")\n","\n","    unique_labels, label_counts = np.unique(labels_array, return_counts=True)\n","    print(f\"True classes in test: {[CASME2_CLASSES[i] for i in unique_labels]}\")\n","\n","    return {\n","        'predictions': predictions_array,\n","        'probabilities': probabilities_array,\n","        'labels': labels_array,\n","        'sample_ids': all_sample_ids,\n","        'emotions': all_emotions,\n","        'subjects': all_subjects,\n","        'filenames': all_filenames,\n","        'inference_time': inference_time,\n","        'samples_count': len(predictions_array)\n","    }\n","\n","def analyze_wrong_predictions_casme2_deit(inference_results):\n","    \"\"\"Comprehensive wrong predictions analysis for CASME II DeiT\"\"\"\n","    print(\"Analyzing wrong predictions for CASME II DeiT micro-expression recognition...\")\n","\n","    predictions = inference_results['predictions']\n","    labels = inference_results['labels']\n","    sample_ids = inference_results['sample_ids']\n","    emotions = inference_results['emotions']\n","    subjects = inference_results['subjects']\n","    filenames = inference_results['filenames']\n","\n","    # Find wrong predictions\n","    wrong_mask = predictions != labels\n","    wrong_indices = np.where(wrong_mask)[0]\n","\n","    # Organize by true emotion class\n","    wrong_predictions_by_class = {}\n","    subject_error_analysis = {}\n","\n","    for class_name in CASME2_CLASSES:\n","        wrong_predictions_by_class[class_name] = []\n","\n","    # Analyze wrong predictions\n","    for idx in wrong_indices:\n","        true_label = labels[idx]\n","        pred_label = predictions[idx]\n","        sample_id = sample_ids[idx]\n","        emotion = emotions[idx]\n","        subject = subjects[idx]\n","        filename = filenames[idx]\n","\n","        true_class = CASME2_CLASSES[true_label]\n","        pred_class = CASME2_CLASSES[pred_label]\n","\n","        wrong_info = {\n","            'sample_id': sample_id,\n","            'filename': filename,\n","            'subject': subject,\n","            'true_label': int(true_label),\n","            'true_class': true_class,\n","            'predicted_label': int(pred_label),\n","            'predicted_class': pred_class,\n","            'emotion': emotion\n","        }\n","\n","        wrong_predictions_by_class[true_class].append(wrong_info)\n","\n","        # Subject error tracking\n","        if subject not in subject_error_analysis:\n","            subject_error_analysis[subject] = {'total': 0, 'wrong': 0, 'errors': []}\n","        subject_error_analysis[subject]['wrong'] += 1\n","        subject_error_analysis[subject]['errors'].append(wrong_info)\n","\n","    # Count total samples per subject\n","    for subject in subjects:\n","        if subject in subject_error_analysis:\n","            subject_error_analysis[subject]['total'] += 1\n","        else:\n","            subject_error_analysis[subject] = {'total': 1, 'wrong': 0, 'errors': []}\n","\n","    # Calculate error rates per subject\n","    for subject in subject_error_analysis:\n","        total = subject_error_analysis[subject]['total']\n","        wrong = subject_error_analysis[subject]['wrong']\n","        subject_error_analysis[subject]['error_rate'] = wrong / total if total > 0 else 0.0\n","\n","    # Summary statistics\n","    total_wrong = len(wrong_indices)\n","    total_samples = len(predictions)\n","    error_rate = (total_wrong / total_samples) * 100\n","\n","    # Confusion patterns analysis\n","    confusion_patterns = {}\n","    for idx in wrong_indices:\n","        true_label = labels[idx]\n","        pred_label = predictions[idx]\n","        pattern = f\"{CASME2_CLASSES[true_label]}_to_{CASME2_CLASSES[pred_label]}\"\n","        confusion_patterns[pattern] = confusion_patterns.get(pattern, 0) + 1\n","\n","    analysis_results = {\n","        'analysis_metadata': {\n","            'evaluation_timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n","            'model_type': EVALUATION_CONFIG_CASME2_DEIT['model_type'],\n","            'dataset': EVALUATION_CONFIG_CASME2_DEIT['dataset_name'],\n","            'architecture': EVALUATION_CONFIG_CASME2_DEIT['architecture'],\n","            'total_samples': int(total_samples),\n","            'total_wrong_predictions': int(total_wrong),\n","            'overall_error_rate': float(error_rate)\n","        },\n","        'wrong_predictions_by_class': wrong_predictions_by_class,\n","        'subject_error_analysis': subject_error_analysis,\n","        'confusion_patterns': confusion_patterns,\n","        'error_summary': {\n","            class_name: len(wrong_predictions_by_class[class_name])\n","            for class_name in CASME2_CLASSES\n","        }\n","    }\n","\n","    return analysis_results\n","\n","def calculate_comprehensive_metrics_casme2_deit(inference_results):\n","    \"\"\"Calculate comprehensive evaluation metrics for CASME II DeiT micro-expression recognition\"\"\"\n","    print(\"Calculating comprehensive metrics for CASME II DeiT micro-expression recognition...\")\n","\n","    predictions = inference_results['predictions']\n","    probabilities = inference_results['probabilities']\n","    labels = inference_results['labels']\n","\n","    if len(predictions) == 0:\n","        raise ValueError(\"No predictions to evaluate!\")\n","\n","    # Identify available classes in test set\n","    unique_test_labels = sorted(np.unique(labels))\n","    unique_predictions = sorted(np.unique(predictions))\n","\n","    print(f\"Test set contains labels: {[CASME2_CLASSES[i] for i in unique_test_labels]}\")\n","    print(f\"DeiT model predicted classes: {[CASME2_CLASSES[i] for i in unique_predictions]}\")\n","\n","    # Basic metrics\n","    accuracy = accuracy_score(labels, predictions)\n","\n","    # Macro metrics (only for available classes)\n","    precision, recall, f1, support = precision_recall_fscore_support(\n","        labels, predictions, labels=unique_test_labels, average='macro', zero_division=0\n","    )\n","\n","    print(f\"Macro F1 (available classes): {f1:.4f}\")\n","\n","    # Per-class metrics (all 7 classes)\n","    precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n","        labels, predictions, labels=range(7), average=None, zero_division=0\n","    )\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(labels, predictions, labels=range(7))\n","\n","    # Multi-class AUC (only for classes with test samples)\n","    auc_scores = {}\n","    fpr_dict = {}\n","    tpr_dict = {}\n","\n","    try:\n","        labels_binarized = label_binarize(labels, classes=range(7))\n","\n","        for i, class_name in enumerate(CASME2_CLASSES):\n","            if i in unique_test_labels and len(np.unique(labels_binarized[:, i])) > 1:\n","                fpr, tpr, _ = roc_curve(labels_binarized[:, i], probabilities[:, i])\n","                auc_score = auc(fpr, tpr)\n","                auc_scores[class_name] = float(auc_score)\n","                fpr_dict[class_name] = fpr.tolist()\n","                tpr_dict[class_name] = tpr.tolist()\n","            else:\n","                auc_scores[class_name] = 0.0\n","                fpr_dict[class_name] = [0.0, 1.0]\n","                tpr_dict[class_name] = [0.0, 0.0]\n","\n","        # Macro AUC for available classes\n","        available_auc_scores = [auc_scores[CASME2_CLASSES[i]] for i in unique_test_labels]\n","        macro_auc = float(np.mean(available_auc_scores)) if available_auc_scores else 0.0\n","\n","    except Exception as e:\n","        print(f\"Warning: AUC calculation failed: {e}\")\n","        auc_scores = {class_name: 0.0 for class_name in CASME2_CLASSES}\n","        macro_auc = 0.0\n","\n","    # Subject-level analysis\n","    subjects = inference_results['subjects']\n","    subject_performance = {}\n","\n","    for subject in set(subjects):\n","        subject_mask = [s == subject for s in subjects]\n","        subject_predictions = predictions[subject_mask]\n","        subject_labels = labels[subject_mask]\n","\n","        if len(subject_predictions) > 0:\n","            subject_acc = accuracy_score(subject_labels, subject_predictions)\n","            subject_performance[subject] = {\n","                'accuracy': float(subject_acc),\n","                'samples': int(len(subject_predictions)),\n","                'correct': int(np.sum(subject_predictions == subject_labels))\n","            }\n","\n","    # Comprehensive results\n","    comprehensive_results = {\n","        'evaluation_metadata': {\n","            'model_type': EVALUATION_CONFIG_CASME2_DEIT['model_type'],\n","            'dataset': EVALUATION_CONFIG_CASME2_DEIT['dataset_name'],\n","            'architecture': EVALUATION_CONFIG_CASME2_DEIT['architecture'],\n","            'evaluation_timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n","            'num_classes': EVALUATION_CONFIG_CASME2_DEIT['num_classes'],\n","            'class_names': EVALUATION_CONFIG_CASME2_DEIT['class_names'],\n","            'test_samples': int(len(labels)),\n","            'available_classes': [CASME2_CLASSES[i] for i in unique_test_labels],\n","            'missing_classes': [CASME2_CLASSES[i] for i in range(7) if i not in unique_test_labels]\n","        },\n","\n","        'overall_performance': {\n","            'accuracy': float(accuracy),\n","            'macro_precision': float(precision),\n","            'macro_recall': float(recall),\n","            'macro_f1': float(f1),\n","            'macro_auc': macro_auc\n","        },\n","\n","        'per_class_performance': {},\n","\n","        'confusion_matrix': cm.tolist(),\n","\n","        'subject_level_performance': subject_performance,\n","\n","        'roc_analysis': {\n","            'auc_scores': auc_scores,\n","            'fpr_curves': fpr_dict,\n","            'tpr_curves': tpr_dict\n","        },\n","\n","        'inference_performance': {\n","            'total_time_seconds': float(inference_results['inference_time']),\n","            'average_time_ms_per_sample': float(inference_results['inference_time'] * 1000 / len(labels))\n","        }\n","    }\n","\n","    # Per-class performance details\n","    for i, class_name in enumerate(CASME2_CLASSES):\n","        comprehensive_results['per_class_performance'][class_name] = {\n","            'precision': float(precision_per_class[i]),\n","            'recall': float(recall_per_class[i]),\n","            'f1_score': float(f1_per_class[i]),\n","            'support': int(support_per_class[i]),\n","            'auc': auc_scores[class_name],\n","            'in_test_set': i in unique_test_labels\n","        }\n","\n","    return comprehensive_results\n","\n","def save_evaluation_results_casme2_deit(evaluation_results, wrong_predictions_results, results_dir):\n","    \"\"\"Save comprehensive evaluation results for CASME II DeiT\"\"\"\n","    os.makedirs(results_dir, exist_ok=True)\n","\n","    # Save main evaluation results\n","    results_file = f\"{results_dir}/casme2_deit_direct_evaluation_results.json\"\n","    with open(results_file, 'w') as f:\n","        json.dump(evaluation_results, f, indent=2, default=str)\n","\n","    # Save wrong predictions analysis\n","    wrong_predictions_file = f\"{results_dir}/casme2_deit_direct_wrong_predictions.json\"\n","    with open(wrong_predictions_file, 'w') as f:\n","        json.dump(wrong_predictions_results, f, indent=2, default=str)\n","\n","    print(f\"DeiT evaluation results saved:\")\n","    print(f\"  Main results: {results_file}\")\n","    print(f\"  Wrong predictions: {wrong_predictions_file}\")\n","\n","    return results_file, wrong_predictions_file\n","\n","# Main evaluation execution for DeiT\n","try:\n","    print(\"Starting CASME II DeiT Direct Baseline comprehensive evaluation...\")\n","\n","    # Create test dataset\n","    print(\"Creating CASME II test dataset for DeiT...\")\n","    casme2_test_dataset = CASME2DatasetEvaluationDeiT(\n","        split_metadata=GLOBAL_CONFIG_CASME2['metadata'],\n","        dataset_root=GLOBAL_CONFIG_CASME2['test_path'].replace('/test', ''),\n","        transform=GLOBAL_CONFIG_CASME2['transform_val'],\n","        split='test',\n","        use_ram_cache=True\n","    )\n","\n","    if len(casme2_test_dataset) == 0:\n","        raise ValueError(\"No test samples found! Check test data path.\")\n","\n","    casme2_test_loader = DataLoader(\n","        casme2_test_dataset,\n","        batch_size=CASME2_DEIT_CONFIG['batch_size'],\n","        shuffle=False,\n","        num_workers=CASME2_DEIT_CONFIG['num_workers'],\n","        pin_memory=True\n","    )\n","\n","    # Load trained DeiT model\n","    checkpoint_path = f\"{GLOBAL_CONFIG_CASME2['checkpoint_root']}/{EVALUATION_CONFIG_CASME2_DEIT['checkpoint_file']}\"\n","    casme2_deit_model, training_info = load_trained_model_casme2_deit(checkpoint_path, GLOBAL_CONFIG_CASME2['device'])\n","\n","    # Run DeiT inference\n","    inference_results = run_model_inference_casme2_deit(casme2_deit_model, casme2_test_loader, GLOBAL_CONFIG_CASME2['device'])\n","\n","    # Calculate comprehensive metrics\n","    evaluation_results = calculate_comprehensive_metrics_casme2_deit(inference_results)\n","\n","    # Analyze wrong predictions\n","    wrong_predictions_results = analyze_wrong_predictions_casme2_deit(inference_results)\n","\n","    # Add training information\n","    evaluation_results['training_information'] = training_info\n","\n","    # Save results\n","    results_dir = f\"{GLOBAL_CONFIG_CASME2['results_root']}/evaluation_results\"\n","    results_file, wrong_file = save_evaluation_results_casme2_deit(\n","        evaluation_results, wrong_predictions_results, results_dir\n","    )\n","\n","    # Display comprehensive results\n","    print(\"\\n\" + \"=\" * 65)\n","    print(\"CASME II DEIT TRANSFORMER DIRECT BASELINE EVALUATION RESULTS\")\n","    print(\"=\" * 65)\n","\n","    # Overall performance\n","    overall = evaluation_results['overall_performance']\n","    print(f\"Overall Performance (Macro - Available Classes):\")\n","    print(f\"  Accuracy:  {overall['accuracy']:.4f}\")\n","    print(f\"  Precision: {overall['macro_precision']:.4f}\")\n","    print(f\"  Recall:    {overall['macro_recall']:.4f}\")\n","    print(f\"  F1 Score:  {overall['macro_f1']:.4f}\")\n","    print(f\"  AUC:       {overall['macro_auc']:.4f}\")\n","\n","    # Per-class performance\n","    print(f\"\\nPer-Class Performance:\")\n","    for class_name, metrics in evaluation_results['per_class_performance'].items():\n","        in_test = \"Present\" if metrics['in_test_set'] else \"Missing\"\n","        print(f\"  {class_name} [{in_test}]: F1={metrics['f1_score']:.4f}, \"\n","              f\"AUC={metrics['auc']:.4f}, Support={metrics['support']}\")\n","\n","    # Training vs test comparison\n","    print(f\"\\nTraining vs Test Performance:\")\n","    training_f1 = training_info['best_val_f1']\n","    training_acc = training_info['best_val_accuracy']\n","    test_f1 = overall['macro_f1']\n","    test_acc = overall['accuracy']\n","\n","    print(f\"  Training Val F1:  {training_f1:.4f}\")\n","    print(f\"  Test F1:          {test_f1:.4f}\")\n","    print(f\"  F1 Difference:    {training_f1 - test_f1:+.4f}\")\n","    print(f\"  Training Val Acc: {training_acc:.4f}\")\n","    print(f\"  Test Accuracy:    {test_acc:.4f}\")\n","    print(f\"  Acc Difference:   {training_acc - test_acc:+.4f}\")\n","    print(f\"  Best Epoch:       {training_info['best_epoch']}\")\n","    print(f\"  DeiT Variant:     {training_info['deit_variant']}\")\n","    print(f\"  Architecture:     {training_info['architecture_approach']}\")\n","\n","    # Wrong predictions summary\n","    print(f\"\\n\" + \"=\" * 40)\n","    print(\"WRONG PREDICTIONS ANALYSIS\")\n","    print(\"=\" * 40)\n","\n","    wrong_meta = wrong_predictions_results['analysis_metadata']\n","    print(f\"Total wrong predictions: {wrong_meta['total_wrong_predictions']} / {wrong_meta['total_samples']}\")\n","    print(f\"Overall error rate: {wrong_meta['overall_error_rate']:.2f}%\")\n","\n","    print(f\"\\nErrors by True Class:\")\n","    for class_name, error_count in wrong_predictions_results['error_summary'].items():\n","        if error_count > 0:\n","            wrong_samples = wrong_predictions_results['wrong_predictions_by_class'][class_name]\n","            print(f\"  {class_name}: {error_count} errors\")\n","            for sample in wrong_samples[:3]:  # Show first 3\n","                print(f\"    - {sample['filename']} -> predicted as {sample['predicted_class']}\")\n","            if len(wrong_samples) > 3:\n","                print(f\"    ... and {len(wrong_samples) - 3} more\")\n","\n","    # Subject-level analysis\n","    print(f\"\\nSubject-Level Performance:\")\n","    subject_perfs = list(evaluation_results['subject_level_performance'].items())\n","    subject_perfs.sort(key=lambda x: x[1]['accuracy'], reverse=True)\n","    for subject, perf in subject_perfs[:5]:  # Show top 5\n","        print(f\"  {subject}: {perf['accuracy']:.3f} ({perf['correct']}/{perf['samples']})\")\n","\n","    # Most common confusion patterns\n","    print(f\"\\nMost Common Confusion Patterns:\")\n","    patterns = sorted(wrong_predictions_results['confusion_patterns'].items(),\n","                     key=lambda x: x[1], reverse=True)\n","    for pattern, count in patterns[:3]:\n","        print(f\"  {pattern}: {count} cases\")\n","\n","    print(f\"\\nInference Performance:\")\n","    print(f\"  Total time: {inference_results['inference_time']:.2f}s\")\n","    print(f\"  Speed: {evaluation_results['inference_performance']['average_time_ms_per_sample']:.1f} ms/sample\")\n","\n","    print(f\"\\nMissing Classes: {evaluation_results['evaluation_metadata']['missing_classes']}\")\n","\n","    print(f\"\\nArchitecture Features:\")\n","    print(f\"  Fixed Architecture: DeiTModel + Custom Classification Head\")\n","    print(f\"  Position Interpolation: {training_info['position_interpolation']}\")\n","    print(f\"  Medical-Proven Approach: Verified compatibility with 384px input\")\n","\n","    print(\"\\n\" + \"=\" * 65)\n","    print(\"CASME II DEIT TRANSFORMER DIRECT BASELINE EVALUATION COMPLETED\")\n","    print(\"=\" * 65)\n","\n","except Exception as e:\n","    print(f\"DeiT evaluation failed: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","\n","finally:\n","    # Memory cleanup\n","    if torch.cuda.is_available():\n","        torch.cuda.synchronize()\n","        torch.cuda.empty_cache()\n","\n","print(\"Next: Cell 4 - DeiT Confusion Matrix Analysis and Visualization\")"],"metadata":{"cellView":"form","id":"O9WalXmhvUuQ","executionInfo":{"status":"ok","timestamp":1758874118706,"user_tz":-420,"elapsed":35980,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"c4ffab31-d217-4251-be2e-746a122acacd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CASME II DeiT Direct Baseline Evaluation Framework\n","=================================================================\n","Model: DeiT_CASME2_Direct_Baseline\n","Task: micro_expression_recognition\n","Classes: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness', 'fear']\n","Input size: 384x384\n","Architecture: deit_transformer_distillation\n","Starting CASME II DeiT Direct Baseline comprehensive evaluation...\n","Creating CASME II test dataset for DeiT...\n","Loading CASME II test dataset for DeiT evaluation...\n","Loaded 28 CASME II test samples for DeiT evaluation\n","Test set class distribution:\n","  others: 10 samples (35.7%)\n","  disgust: 7 samples (25.0%)\n","  happiness: 4 samples (14.3%)\n","  repression: 3 samples (10.7%)\n","  surprise: 3 samples (10.7%)\n","  sadness: 1 samples (3.6%)\n","Test set covers 16 subjects\n","Missing classes in test set: ['fear']\n","Preloading 28 test images to RAM for DeiT evaluation...\n","Test RAM caching completed: 28 valid images, ~0.05GB\n","Loading trained CASME II DeiT model from: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/models/02_04_deit_casme2-af/casme2_deit_direct_best_f1.pth\n","DeiT checkpoint loaded using: standard\n","Detected DeiT variant: base\n","Detected DeiT model: facebook/deit-base-distilled-patch16-224\n","Architecture approach: DeiTModel + Custom Head (Medical Proven)\n","DeiT feature dimension: 768\n","DeiT distillation token: Available in model\n","DeiT CASME II: 768 -> 512 -> 128 -> 7\n","DeiT model state loaded with strict=True\n","DeiT model loaded successfully:\n","  Best validation F1: 0.3030\n","  Best validation accuracy: 0.4231\n","  Best epoch: 7\n","  DeiT variant: base\n","  Position interpolation: 1.0\n","  Model classes: 7\n","Running CASME II DeiT model inference on test set...\n"]},{"output_type":"stream","name":"stderr","text":["CASME II DeiT Inference: 100%|██████████| 2/2 [00:01<00:00,  1.88it/s]"]},{"output_type":"stream","name":"stdout","text":["CASME II DeiT inference completed: 28 samples in 1.06s\n","Predicted classes: ['others', 'disgust', 'happiness', 'repression', 'sadness']\n","True classes in test: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness']\n","Calculating comprehensive metrics for CASME II DeiT micro-expression recognition...\n","Test set contains labels: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness']\n","DeiT model predicted classes: ['others', 'disgust', 'happiness', 'repression', 'sadness']\n","Macro F1 (available classes): 0.2554\n","Analyzing wrong predictions for CASME II DeiT micro-expression recognition...\n","DeiT evaluation results saved:\n","  Main results: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/results/02_04_deit_casme2-af/evaluation_results/casme2_deit_direct_evaluation_results.json\n","  Wrong predictions: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/results/02_04_deit_casme2-af/evaluation_results/casme2_deit_direct_wrong_predictions.json\n","\n","=================================================================\n","CASME II DEIT TRANSFORMER DIRECT BASELINE EVALUATION RESULTS\n","=================================================================\n","Overall Performance (Macro - Available Classes):\n","  Accuracy:  0.3929\n","  Precision: 0.2426\n","  Recall:    0.2758\n","  F1 Score:  0.2554\n","  AUC:       0.6157\n","\n","Per-Class Performance:\n","  others [Present]: F1=0.5263, AUC=0.7222, Support=10\n","  disgust [Present]: F1=0.4706, AUC=0.6735, Support=7\n","  happiness [Present]: F1=0.2500, AUC=0.5625, Support=4\n","  repression [Present]: F1=0.2857, AUC=0.8800, Support=3\n","  surprise [Present]: F1=0.0000, AUC=0.5600, Support=3\n","  sadness [Present]: F1=0.0000, AUC=0.2963, Support=1\n","  fear [Missing]: F1=0.0000, AUC=0.0000, Support=0\n","\n","Training vs Test Performance:\n","  Training Val F1:  0.3030\n","  Test F1:          0.2554\n","  F1 Difference:    +0.0476\n","  Training Val Acc: 0.4231\n","  Test Accuracy:    0.3929\n","  Acc Difference:   +0.0302\n","  Best Epoch:       7\n","  DeiT Variant:     base\n","  Architecture:     DeiTModel + Custom Classification Head\n","\n","========================================\n","WRONG PREDICTIONS ANALYSIS\n","========================================\n","Total wrong predictions: 17 / 28\n","Overall error rate: 60.71%\n","\n","Errors by True Class:\n","  others: 5 errors\n","    - sub14_EP04_04f_others.jpg -> predicted as happiness\n","    - sub04_EP13_02f_others.jpg -> predicted as disgust\n","    - sub03_EP07_03_others.jpg -> predicted as disgust\n","    ... and 2 more\n","  disgust: 3 errors\n","    - sub05_EP09_05f_disgust.jpg -> predicted as others\n","    - sub15_EP08_02_disgust.jpg -> predicted as others\n","    - sub01_EP19_05f_disgust.jpg -> predicted as others\n","  happiness: 3 errors\n","    - sub23_EP02_01_happiness.jpg -> predicted as repression\n","    - sub12_EP03_04_happiness.jpg -> predicted as disgust\n","    - sub17_EP06_07_happiness.jpg -> predicted as repression\n","  repression: 2 errors\n","    - sub09_EP09_05_repression.jpg -> predicted as happiness\n","    - sub16_EP01_08_repression.jpg -> predicted as others\n","  surprise: 3 errors\n","    - sub17_EP01_13_surprise.jpg -> predicted as happiness\n","    - sub12_EP02_05_surprise.jpg -> predicted as disgust\n","    - sub02_EP11_01_surprise.jpg -> predicted as repression\n","  sadness: 1 errors\n","    - sub17_EP15_03_sadness.jpg -> predicted as disgust\n","\n","Subject-Level Performance:\n","  sub20: 1.000 (1/1)\n","  sub10: 1.000 (1/1)\n","  sub26: 1.000 (3/3)\n","  sub05: 0.667 (2/3)\n","  sub01: 0.500 (1/2)\n","\n","Most Common Confusion Patterns:\n","  others_to_disgust: 3 cases\n","  disgust_to_others: 3 cases\n","  happiness_to_repression: 2 cases\n","\n","Inference Performance:\n","  Total time: 1.06s\n","  Speed: 38.0 ms/sample\n","\n","Missing Classes: ['fear']\n","\n","Architecture Features:\n","  Fixed Architecture: DeiTModel + Custom Classification Head\n","  Position Interpolation: 1.0\n","  Medical-Proven Approach: Verified compatibility with 384px input\n","\n","=================================================================\n","CASME II DEIT TRANSFORMER DIRECT BASELINE EVALUATION COMPLETED\n","=================================================================\n","Next: Cell 4 - DeiT Confusion Matrix Analysis and Visualization\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# @title Cell 4: CASME II DeiT Direct Baseline Confusion Matrix Generation\n","\n","# File: 02_04_DeiT_Direct_Baseline_Cell4.py\n","# Location: experiments/02_04_DeiT_Direct_Baseline.ipynb\n","# Purpose: Generate professional confusion matrix and comprehensive analysis for CASME II DeiT micro-expression recognition\n","# Dependencies: Trained model evaluation results from Cell 3\n","\n","import json\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import seaborn as sns\n","from datetime import datetime\n","\n","print(\"CASME II DeiT Direct Baseline Confusion Matrix Generation\")\n","print(\"=\" * 65)\n","\n","# Project paths configuration - DeiT specific\n","PROJECT_ROOT = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","RESULTS_ROOT = f\"{PROJECT_ROOT}/results/02_04_deit_casme2-af\"\n","\n","def find_evaluation_json_files_casme2_deit(results_path):\n","    \"\"\"Find CASME II DeiT evaluation JSON files\"\"\"\n","    json_files = {}\n","\n","    eval_dir = f\"{results_path}/evaluation_results\"\n","\n","    if os.path.exists(eval_dir):\n","        # Look for main DeiT evaluation results\n","        eval_files = glob.glob(f\"{eval_dir}/casme2_deit_direct_evaluation_results.json\")\n","        if eval_files:\n","            json_files['main'] = eval_files[0]\n","            print(f\"Found CASME II DeiT evaluation file: {os.path.basename(eval_files[0])}\")\n","\n","        # Look for DeiT wrong predictions analysis\n","        wrong_files = glob.glob(f\"{eval_dir}/casme2_deit_direct_wrong_predictions.json\")\n","        if wrong_files:\n","            json_files['wrong_predictions'] = wrong_files[0]\n","            print(f\"Found DeiT wrong predictions file: {os.path.basename(wrong_files[0])}\")\n","\n","        if not json_files:\n","            print(f\"WARNING: No DeiT evaluation results found in {eval_dir}\")\n","            print(\"Make sure Cell 3 (DeiT evaluation) has been executed first!\")\n","    else:\n","        print(f\"ERROR: DeiT evaluation directory not found: {eval_dir}\")\n","\n","    return json_files\n","\n","def load_evaluation_results_casme2_deit(json_path):\n","    \"\"\"Load and parse CASME II DeiT evaluation results JSON\"\"\"\n","    try:\n","        with open(json_path, 'r') as f:\n","            data = json.load(f)\n","        print(f\"Successfully loaded DeiT evaluation results from: {os.path.basename(json_path)}\")\n","        return data\n","    except Exception as e:\n","        print(f\"ERROR loading {json_path}: {str(e)}\")\n","        return None\n","\n","def calculate_weighted_f1_casme2_deit(per_class_performance):\n","    \"\"\"Calculate weighted F1 score for CASME II DeiT micro-expression classes\"\"\"\n","    # Only count classes that have test samples (support > 0)\n","    total_support = sum([class_data['support'] for class_data in per_class_performance.values()\n","                        if class_data['support'] > 0])\n","\n","    if total_support == 0:\n","        return 0.0\n","\n","    weighted_f1 = 0.0\n","\n","    for class_name, class_data in per_class_performance.items():\n","        if class_data['support'] > 0:  # Only include classes with test samples\n","            weight = class_data['support'] / total_support\n","            weighted_f1 += class_data['f1_score'] * weight\n","\n","    return weighted_f1\n","\n","def calculate_balanced_accuracy_casme2_deit(confusion_matrix):\n","    \"\"\"\n","    Calculate balanced accuracy for CASME II DeiT 7-class micro-expression recognition\n","    Handles classes with zero support (missing in test set)\n","    \"\"\"\n","    cm = np.array(confusion_matrix)\n","    n_classes = cm.shape[0]\n","\n","    per_class_balanced_acc = []\n","\n","    # Find classes with actual test samples\n","    classes_with_samples = []\n","    for i in range(n_classes):\n","        if cm[i, :].sum() > 0:  # Class has test samples\n","            classes_with_samples.append(i)\n","\n","    for i in classes_with_samples:\n","        # True positives, false negatives, false positives, true negatives for class i\n","        tp = cm[i, i]\n","        fn = cm[i, :].sum() - tp  # Sum of row i minus diagonal\n","        fp = cm[:, i].sum() - tp  # Sum of column i minus diagonal\n","        tn = cm.sum() - tp - fn - fp  # Total minus TP, FN, FP\n","\n","        # Calculate sensitivity and specificity for class i\n","        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n","\n","        # Per-class balanced accuracy\n","        class_balanced_acc = (sensitivity + specificity) / 2\n","        per_class_balanced_acc.append(class_balanced_acc)\n","\n","    # Overall balanced accuracy (mean of available classes)\n","    balanced_acc = np.mean(per_class_balanced_acc) if per_class_balanced_acc else 0.0\n","\n","    return balanced_acc\n","\n","def determine_text_color_casme2_deit(color_value, threshold=0.5):\n","    \"\"\"Determine optimal text color based on background intensity\"\"\"\n","    return 'white' if color_value > threshold else 'black'\n","\n","def analyze_missing_classes_casme2_deit(data):\n","    \"\"\"Analyze missing classes in CASME II DeiT test set\"\"\"\n","    meta = data['evaluation_metadata']\n","    available_classes = meta.get('available_classes', [])\n","    missing_classes = meta.get('missing_classes', [])\n","    training_info = data.get('training_information', {})\n","    deit_variant = training_info.get('deit_variant', 'unknown')\n","    distillation_token = training_info.get('distillation_token', False)\n","\n","    print(f\"DeiT Analysis:\")\n","    print(f\"  Variant: {deit_variant}\")\n","    print(f\"  Distillation Token: {distillation_token}\")\n","    print(f\"  Available in test: {available_classes}\")\n","    print(f\"  Missing from test: {missing_classes}\")\n","\n","    return {\n","        'available': available_classes,\n","        'missing': missing_classes,\n","        'total_classes': len(meta['class_names']),\n","        'deit_variant': deit_variant,\n","        'distillation_token': distillation_token\n","    }\n","\n","def create_confusion_matrix_plot_casme2_deit(data, output_path):\n","    \"\"\"Create professional confusion matrix visualization for CASME II DeiT micro-expression recognition\"\"\"\n","\n","    # Extract data\n","    meta = data['evaluation_metadata']\n","    class_names = meta['class_names']\n","    cm = np.array(data['confusion_matrix'], dtype=int)\n","    overall = data['overall_performance']\n","    per_class = data['per_class_performance']\n","    training_info = data.get('training_information', {})\n","    deit_variant = training_info.get('deit_variant', 'unknown')\n","    distillation_token = training_info.get('distillation_token', False)\n","\n","    print(f\"Processing DeiT confusion matrix for CASME II classes: {class_names}\")\n","    print(f\"DeiT variant: {deit_variant}\")\n","    print(f\"Distillation token: {distillation_token}\")\n","    print(f\"Confusion matrix shape: {cm.shape}\")\n","\n","    # Calculate comprehensive metrics\n","    macro_f1 = overall.get('macro_f1', 0.0)\n","    accuracy = overall.get('accuracy', 0.0)\n","    weighted_f1 = calculate_weighted_f1_casme2_deit(per_class)\n","    balanced_acc = calculate_balanced_accuracy_casme2_deit(cm)\n","\n","    print(f\"Calculated metrics - Macro F1: {macro_f1:.4f}, Weighted F1: {weighted_f1:.4f}, \"\n","          f\"Balanced Acc: {balanced_acc:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","    # Row-wise normalization for percentage display\n","    row_sums = cm.sum(axis=1, keepdims=True)\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        cm_pct = np.divide(cm, row_sums, where=(row_sums!=0))\n","        cm_pct = np.nan_to_num(cm_pct)\n","\n","    # Create visualization with appropriate size for 7 classes\n","    fig, ax = plt.subplots(figsize=(12, 10))\n","\n","    # Color scheme optimized for DeiT micro-expression research\n","    cmap = 'Blues'\n","\n","    # Create heatmap with improved color scaling\n","    im = ax.imshow(cm_pct, interpolation='nearest', cmap=cmap, vmin=0.0, vmax=0.8)\n","\n","    # Add colorbar\n","    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","    cbar.set_label('True Class Percentage', rotation=270, labelpad=15, fontsize=11)\n","\n","    # Annotate cells with count and percentage\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            count = cm[i, j]\n","\n","            # Handle percentage calculation for classes with 0 samples\n","            if row_sums[i, 0] > 0:\n","                percentage = cm_pct[i, j] * 100\n","                text = f\"{count}\\n{percentage:.1f}%\"\n","            else:\n","                text = f\"{count}\\n(N/A)\"  # Class has no test samples\n","\n","            # Determine text color based on cell intensity\n","            cell_value = cm_pct[i, j]\n","            text_color = determine_text_color_casme2_deit(cell_value, threshold=0.4)\n","\n","            ax.text(j, i, text, ha=\"center\", va=\"center\",\n","                   color=text_color, fontsize=9, fontweight='bold')\n","\n","    # Configure axes with micro-expression class names\n","    ax.set_xticks(np.arange(len(class_names)))\n","    ax.set_yticks(np.arange(len(class_names)))\n","    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n","    ax.set_yticklabels(class_names, fontsize=10)\n","    ax.set_xlabel(\"Predicted Label\", fontsize=12, fontweight='bold')\n","    ax.set_ylabel(\"True Label\", fontsize=12, fontweight='bold')\n","\n","    # Add note about missing classes and DeiT architecture\n","    missing_classes = meta.get('missing_classes', [])\n","    note_lines = []\n","    if missing_classes:\n","        note_lines.append(f\"Missing classes: {', '.join(missing_classes)}\")\n","\n","    # DeiT-specific architecture note\n","    distillation_text = \"With Distillation Token\" if distillation_token else \"No Distillation Token\"\n","    note_lines.append(f\"DeiT-{deit_variant.capitalize()} | {distillation_text}\")\n","\n","    if note_lines:\n","        note_text = \"\\n\".join(note_lines)\n","        ax.text(0.02, 0.98, note_text, transform=ax.transAxes, fontsize=9,\n","                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n","\n","    # Create comprehensive title for DeiT micro-expression research\n","    title = f\"CASME II DeiT ({deit_variant.capitalize()}) Micro-Expression Recognition\\n\"\n","    title += f\"Acc: {accuracy:.4f}  |  Macro F1: {macro_f1:.4f}  |  Weighted F1: {weighted_f1:.4f}  |  Balanced Acc: {balanced_acc:.4f}\"\n","    ax.set_title(title, fontsize=12, pad=25, fontweight='bold')\n","\n","    # Adjust layout and save\n","    plt.tight_layout()\n","    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n","    plt.close(fig)\n","\n","    print(f\"DeiT confusion matrix saved to: {os.path.basename(output_path)}\")\n","\n","    return {\n","        'accuracy': accuracy,\n","        'macro_f1': macro_f1,\n","        'weighted_f1': weighted_f1,\n","        'balanced_accuracy': balanced_acc,\n","        'missing_classes': missing_classes,\n","        'deit_variant': deit_variant,\n","        'distillation_token': distillation_token\n","    }\n","\n","def create_per_class_performance_chart_casme2_deit(data, output_path):\n","    \"\"\"Create per-class performance visualization for CASME II DeiT\"\"\"\n","    per_class = data['per_class_performance']\n","    class_names = data['evaluation_metadata']['class_names']\n","    training_info = data.get('training_information', {})\n","    deit_variant = training_info.get('deit_variant', 'unknown')\n","    distillation_token = training_info.get('distillation_token', False)\n","\n","    # Extract metrics for each class\n","    classes = []\n","    f1_scores = []\n","    precisions = []\n","    recalls = []\n","    supports = []\n","    in_test_flags = []\n","\n","    for class_name in class_names:\n","        class_data = per_class[class_name]\n","        classes.append(class_name)\n","        f1_scores.append(class_data['f1_score'])\n","        precisions.append(class_data['precision'])\n","        recalls.append(class_data['recall'])\n","        supports.append(class_data['support'])\n","        in_test_flags.append(class_data['in_test_set'])\n","\n","    # Create grouped bar chart\n","    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n","\n","    x = np.arange(len(classes))\n","    width = 0.25\n","\n","    # Top plot: F1, Precision, Recall\n","    bars1 = ax1.bar(x - width, f1_scores, width, label='F1 Score', alpha=0.8, color='steelblue')\n","    bars2 = ax1.bar(x, precisions, width, label='Precision', alpha=0.8, color='orange')\n","    bars3 = ax1.bar(x + width, recalls, width, label='Recall', alpha=0.8, color='green')\n","\n","    ax1.set_xlabel('Emotion Classes', fontweight='bold')\n","    ax1.set_ylabel('Score', fontweight='bold')\n","\n","    # DeiT-specific title\n","    distillation_text = \"with Distillation Token\" if distillation_token else \"without Distillation Token\"\n","    title = f'CASME II DeiT ({deit_variant.capitalize()}) Per-Class Performance - {distillation_text}'\n","    ax1.set_title(title, fontweight='bold', pad=20)\n","\n","    ax1.set_xticks(x)\n","    ax1.set_xticklabels(classes, rotation=45, ha='right')\n","    ax1.legend()\n","    ax1.grid(axis='y', alpha=0.3)\n","    ax1.set_ylim(0, 1.0)\n","\n","    # Add value labels on bars\n","    for bars in [bars1, bars2, bars3]:\n","        for bar, in_test in zip(bars, in_test_flags):\n","            height = bar.get_height()\n","            if in_test:\n","                ax1.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n","                           xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n","            else:\n","                # Mark missing classes\n","                ax1.annotate('N/A', xy=(bar.get_x() + bar.get_width() / 2, height),\n","                           xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n","                           fontsize=8, color='red', fontweight='bold')\n","\n","    # Bottom plot: Support (sample count)\n","    bars4 = ax2.bar(x, supports, color='purple', alpha=0.7)\n","    ax2.set_xlabel('Emotion Classes', fontweight='bold')\n","    ax2.set_ylabel('Number of Test Samples', fontweight='bold')\n","    ax2.set_title('CASME II Test Set Class Distribution (DeiT)', fontweight='bold')\n","    ax2.set_xticks(x)\n","    ax2.set_xticklabels(classes, rotation=45, ha='right')\n","    ax2.grid(axis='y', alpha=0.3)\n","\n","    # Add value labels on support bars\n","    for bar, support in zip(bars4, supports):\n","        height = bar.get_height()\n","        ax2.annotate(f'{int(support)}', xy=(bar.get_x() + bar.get_width() / 2, height),\n","                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=10)\n","\n","    # Add architecture note with DeiT-specific information\n","    distillation_info = \"Teacher-Student Knowledge Transfer\" if distillation_token else \"Standard Vision Transformer\"\n","    fig.text(0.02, 0.02, f\"Architecture: DeiT-{deit_variant.capitalize()} | {distillation_info}\",\n","             fontsize=9, style='italic', alpha=0.7)\n","\n","    plt.tight_layout()\n","    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n","    plt.close(fig)\n","\n","    print(f\"DeiT per-class performance chart saved to: {os.path.basename(output_path)}\")\n","\n","def generate_performance_summary_casme2_deit(evaluation_data, wrong_predictions_data=None):\n","    \"\"\"Generate comprehensive performance summary for CASME II DeiT\"\"\"\n","\n","    print(\"\\n\" + \"=\" * 65)\n","    print(\"CASME II DEIT TRANSFORMER MICRO-EXPRESSION RECOGNITION PERFORMANCE SUMMARY\")\n","    print(\"=\" * 65)\n","\n","    # Overall performance\n","    overall = evaluation_data['overall_performance']\n","    meta = evaluation_data['evaluation_metadata']\n","    training_info = evaluation_data.get('training_information', {})\n","    deit_variant = training_info.get('deit_variant', 'unknown')\n","    distillation_token = training_info.get('distillation_token', False)\n","\n","    print(f\"Dataset: {meta['dataset']}\")\n","    print(f\"Test samples: {meta['test_samples']}\")\n","    print(f\"Model: {meta['model_type']}\")\n","    print(f\"Architecture: DeiT-{deit_variant.capitalize()} with {'Distillation Token' if distillation_token else 'Standard Processing'}\")\n","    print(f\"Evaluation date: {meta['evaluation_timestamp']}\")\n","\n","    print(f\"\\nOverall Performance:\")\n","    print(f\"  Accuracy:         {overall['accuracy']:.4f}\")\n","    print(f\"  Macro Precision:  {overall['macro_precision']:.4f}\")\n","    print(f\"  Macro Recall:     {overall['macro_recall']:.4f}\")\n","    print(f\"  Macro F1:         {overall['macro_f1']:.4f}\")\n","    print(f\"  Macro AUC:        {overall['macro_auc']:.4f}\")\n","\n","    # Per-class performance\n","    print(f\"\\nPer-Class Performance:\")\n","    per_class = evaluation_data['per_class_performance']\n","\n","    print(f\"{'Class':<12} {'F1':<8} {'Precision':<10} {'Recall':<8} {'AUC':<8} {'Support':<8} {'In Test'}\")\n","    print(\"-\" * 65)\n","\n","    for class_name, metrics in per_class.items():\n","        in_test = \"Yes\" if metrics['in_test_set'] else \"No\"\n","        print(f\"{class_name:<12} {metrics['f1_score']:<8.4f} {metrics['precision']:<10.4f} \"\n","              f\"{metrics['recall']:<8.4f} {metrics['auc']:<8.4f} {metrics['support']:<8} {in_test}\")\n","\n","    # Training vs test performance\n","    if 'training_information' in evaluation_data:\n","        training = evaluation_data['training_information']\n","        print(f\"\\nTraining vs Test Comparison:\")\n","        print(f\"  Training Val F1:  {training['best_val_f1']:.4f}\")\n","        print(f\"  Test F1:          {overall['macro_f1']:.4f}\")\n","        print(f\"  Performance Gap:  {training['best_val_f1'] - overall['macro_f1']:+.4f}\")\n","        print(f\"  Best Epoch:       {training['best_epoch']}\")\n","        print(f\"  DeiT Variant:     {training['deit_variant']}\")\n","\n","    # Class imbalance analysis\n","    missing_classes = meta.get('missing_classes', [])\n","    available_classes = meta.get('available_classes', [])\n","\n","    print(f\"\\nClass Availability Analysis:\")\n","    print(f\"  Available classes: {len(available_classes)}/7\")\n","    print(f\"  Missing classes: {missing_classes if missing_classes else 'None'}\")\n","\n","    # Architecture-specific information\n","    print(f\"\\nDeiT Architecture Details:\")\n","    print(f\"  Variant: {deit_variant}\")\n","    print(f\"  Distillation Token: {'Enabled' if distillation_token else 'Disabled'}\")\n","    if distillation_token:\n","        print(f\"  Knowledge Transfer: CNN Teacher -> DeiT Student\")\n","        print(f\"  Token Processing: CLS + Distillation + Patch Tokens\")\n","        print(f\"  Training Strategy: Data-Efficient Learning\")\n","    else:\n","        print(f\"  Token Processing: Standard CLS + Patch Tokens\")\n","        print(f\"  Training Strategy: Standard Vision Transformer\")\n","\n","    # Wrong predictions summary if available\n","    if wrong_predictions_data:\n","        wrong_meta = wrong_predictions_data['analysis_metadata']\n","        print(f\"\\nError Analysis:\")\n","        print(f\"  Total errors: {wrong_meta['total_wrong_predictions']}/{wrong_meta['total_samples']}\")\n","        print(f\"  Error rate: {wrong_meta['overall_error_rate']:.2f}%\")\n","\n","        # Top confusion patterns\n","        patterns = wrong_predictions_data.get('confusion_patterns', {})\n","        if patterns:\n","            print(f\"\\nTop Confusion Patterns:\")\n","            sorted_patterns = sorted(patterns.items(), key=lambda x: x[1], reverse=True)[:3]\n","            for pattern, count in sorted_patterns:\n","                print(f\"  {pattern}: {count} cases\")\n","\n","    print(f\"\\nInference Performance:\")\n","    inference = evaluation_data['inference_performance']\n","    print(f\"  Total time: {inference['total_time_seconds']:.2f}s\")\n","    print(f\"  Speed: {inference['average_time_ms_per_sample']:.1f} ms/sample\")\n","\n","    # Distillation-specific insights\n","    if distillation_token:\n","        print(f\"\\nDistillation Token Analysis:\")\n","        print(f\"  Teacher-Student Knowledge Transfer: Active\")\n","        print(f\"  Dual-Head Classification: CLS + Distillation tokens\")\n","        print(f\"  Data Efficiency: Enhanced through distillation\")\n","\n","# Find DeiT evaluation JSON files\n","json_files = find_evaluation_json_files_casme2_deit(RESULTS_ROOT)\n","\n","if not json_files:\n","    print(f\"ERROR: No DeiT evaluation JSON files found in {RESULTS_ROOT}\")\n","    print(\"Make sure Cell 3 (DeiT evaluation) has been executed first!\")\n","else:\n","    print(f\"Found {len(json_files)} DeiT evaluation file(s)\")\n","\n","# Create output directory\n","output_dir = f\"{RESULTS_ROOT}/confusion_matrix_analysis\"\n","Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","# Process DeiT evaluation results\n","results_summary = {}\n","generated_files = []\n","\n","if 'main' in json_files:\n","    # Load main evaluation data\n","    eval_data = load_evaluation_results_casme2_deit(json_files['main'])\n","\n","    # Load wrong predictions data if available\n","    wrong_data = None\n","    if 'wrong_predictions' in json_files:\n","        wrong_data = load_evaluation_results_casme2_deit(json_files['wrong_predictions'])\n","\n","    if eval_data is not None:\n","        try:\n","            # Analyze missing classes for DeiT\n","            class_analysis = analyze_missing_classes_casme2_deit(eval_data)\n","\n","            # Generate DeiT confusion matrix\n","            cm_output_path = os.path.join(output_dir, \"confusion_matrix_CASME2_DeiT_Direct.png\")\n","            metrics = create_confusion_matrix_plot_casme2_deit(eval_data, cm_output_path)\n","            generated_files.append(cm_output_path)\n","\n","            # Generate DeiT per-class performance chart\n","            perf_output_path = os.path.join(output_dir, \"per_class_performance_CASME2_DeiT_Direct.png\")\n","            create_per_class_performance_chart_casme2_deit(eval_data, perf_output_path)\n","            generated_files.append(perf_output_path)\n","\n","            results_summary['casme2_deit'] = metrics\n","            results_summary['casme2_deit']['class_analysis'] = class_analysis\n","\n","            print(f\"SUCCESS: DeiT visualization files generated successfully\")\n","\n","        except Exception as e:\n","            print(f\"ERROR: Failed to generate DeiT visualizations: {str(e)}\")\n","            import traceback\n","            traceback.print_exc()\n","\n","        # Generate comprehensive DeiT summary\n","        generate_performance_summary_casme2_deit(eval_data, wrong_data)\n","\n","    else:\n","        print(\"ERROR: Could not load DeiT evaluation data\")\n","else:\n","    print(\"ERROR: No main DeiT evaluation results found\")\n","\n","# Final summary\n","if generated_files:\n","    print(f\"\\n\" + \"=\" * 65)\n","    print(\"CASME II DEIT TRANSFORMER CONFUSION MATRIX GENERATION COMPLETED\")\n","    print(\"=\" * 65)\n","\n","    print(f\"Generated visualization files:\")\n","    for file_path in generated_files:\n","        filename = os.path.basename(file_path)\n","        print(f\"  {filename}\")\n","\n","    if 'casme2_deit' in results_summary:\n","        casme2_deit = results_summary['casme2_deit']\n","        print(f\"\\nFinal Performance Summary:\")\n","        print(f\"  Architecture:      DeiT-{casme2_deit['deit_variant'].capitalize()}\")\n","        print(f\"  Distillation:      {'Enabled' if casme2_deit['distillation_token'] else 'Disabled'}\")\n","        print(f\"  Accuracy:          {casme2_deit['accuracy']:.4f}\")\n","        print(f\"  Macro F1:          {casme2_deit['macro_f1']:.4f}\")\n","        print(f\"  Weighted F1:       {casme2_deit['weighted_f1']:.4f}\")\n","        print(f\"  Balanced Acc:      {casme2_deit['balanced_accuracy']:.4f}\")\n","\n","        if 'class_analysis' in casme2_deit:\n","            analysis = casme2_deit['class_analysis']\n","            print(f\"  Available classes: {len(analysis['available'])}/{analysis['total_classes']}\")\n","            print(f\"  Missing classes:   {len(analysis['missing'])}\")\n","\n","    print(f\"\\nFiles saved in: {output_dir}\")\n","    print(f\"Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","\n","else:\n","    print(f\"\\nERROR: No DeiT visualizations were generated\")\n","    print(\"Please check:\")\n","    print(\"1. Cell 3 DeiT evaluation results exist\")\n","    print(\"2. JSON file structure is correct\")\n","    print(\"3. No file permission issues\")\n","\n","print(\"\\nCell 4 completed - CASME II DeiT confusion matrix analysis generated\")\n","print(\"Ready for multi-architecture comparative analysis (ViT vs Swin vs EfficientViT vs DeiT)\")"],"metadata":{"cellView":"form","id":"mD6xto_OwhYp","executionInfo":{"status":"ok","timestamp":1758874121680,"user_tz":-420,"elapsed":2947,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"c2aeceb9-051e-459e-f9f3-90792af05a82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CASME II DeiT Direct Baseline Confusion Matrix Generation\n","=================================================================\n","Found CASME II DeiT evaluation file: casme2_deit_direct_evaluation_results.json\n","Found DeiT wrong predictions file: casme2_deit_direct_wrong_predictions.json\n","Found 2 DeiT evaluation file(s)\n","Successfully loaded DeiT evaluation results from: casme2_deit_direct_evaluation_results.json\n","Successfully loaded DeiT evaluation results from: casme2_deit_direct_wrong_predictions.json\n","DeiT Analysis:\n","  Variant: base\n","  Distillation Token: False\n","  Available in test: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness']\n","  Missing from test: ['fear']\n","Processing DeiT confusion matrix for CASME II classes: ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness', 'fear']\n","DeiT variant: base\n","Distillation token: False\n","Confusion matrix shape: (7, 7)\n","Calculated metrics - Macro F1: 0.2554, Weighted F1: 0.3719, Balanced Acc: 0.5721, Accuracy: 0.3929\n","DeiT confusion matrix saved to: confusion_matrix_CASME2_DeiT_Direct.png\n","DeiT per-class performance chart saved to: per_class_performance_CASME2_DeiT_Direct.png\n","SUCCESS: DeiT visualization files generated successfully\n","\n","=================================================================\n","CASME II DEIT TRANSFORMER MICRO-EXPRESSION RECOGNITION PERFORMANCE SUMMARY\n","=================================================================\n","Dataset: CASME_II\n","Test samples: 28\n","Model: DeiT_CASME2_Direct_Baseline\n","Architecture: DeiT-Base with Standard Processing\n","Evaluation date: 20250926_080838\n","\n","Overall Performance:\n","  Accuracy:         0.3929\n","  Macro Precision:  0.2426\n","  Macro Recall:     0.2758\n","  Macro F1:         0.2554\n","  Macro AUC:        0.6157\n","\n","Per-Class Performance:\n","Class        F1       Precision  Recall   AUC      Support  In Test\n","-----------------------------------------------------------------\n","others       0.5263   0.5556     0.5000   0.7222   10       Yes\n","disgust      0.4706   0.4000     0.5714   0.6735   7        Yes\n","happiness    0.2500   0.2500     0.2500   0.5625   4        Yes\n","repression   0.2857   0.2500     0.3333   0.8800   3        Yes\n","surprise     0.0000   0.0000     0.0000   0.5600   3        Yes\n","sadness      0.0000   0.0000     0.0000   0.2963   1        Yes\n","fear         0.0000   0.0000     0.0000   0.0000   0        No\n","\n","Training vs Test Comparison:\n","  Training Val F1:  0.3030\n","  Test F1:          0.2554\n","  Performance Gap:  +0.0476\n","  Best Epoch:       7\n","  DeiT Variant:     base\n","\n","Class Availability Analysis:\n","  Available classes: 6/7\n","  Missing classes: ['fear']\n","\n","DeiT Architecture Details:\n","  Variant: base\n","  Distillation Token: Disabled\n","  Token Processing: Standard CLS + Patch Tokens\n","  Training Strategy: Standard Vision Transformer\n","\n","Error Analysis:\n","  Total errors: 17/28\n","  Error rate: 60.71%\n","\n","Top Confusion Patterns:\n","  others_to_disgust: 3 cases\n","  disgust_to_others: 3 cases\n","  happiness_to_repression: 2 cases\n","\n","Inference Performance:\n","  Total time: 1.06s\n","  Speed: 38.0 ms/sample\n","\n","=================================================================\n","CASME II DEIT TRANSFORMER CONFUSION MATRIX GENERATION COMPLETED\n","=================================================================\n","Generated visualization files:\n","  confusion_matrix_CASME2_DeiT_Direct.png\n","  per_class_performance_CASME2_DeiT_Direct.png\n","\n","Final Performance Summary:\n","  Architecture:      DeiT-Base\n","  Distillation:      Disabled\n","  Accuracy:          0.3929\n","  Macro F1:          0.2554\n","  Weighted F1:       0.3719\n","  Balanced Acc:      0.5721\n","  Available classes: 6/7\n","  Missing classes:   1\n","\n","Files saved in: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/results/02_04_deit_casme2-af/confusion_matrix_analysis\n","Analysis completed at: 2025-09-26 08:08:41\n","\n","Cell 4 completed - CASME II DeiT confusion matrix analysis generated\n","Ready for multi-architecture comparative analysis (ViT vs Swin vs EfficientViT vs DeiT)\n"]}]}]}