{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOOVTx84GN6lqx98N4AxmXa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"y-eeHBpWLJLj","executionInfo":{"status":"ok","timestamp":1763866179058,"user_tz":-420,"elapsed":32829,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"8904f728-71f9-4850-de39-4f83ff37fd84"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","BOOTSTRAP CONFIDENCE INTERVALS FOR VIT-PATCH32 AF\n","Statistical Validation via Resampling Methods\n","======================================================================\n","\n","[STEP 1] Mounting Google Drive and configuring environment...\n","Mounted at /content/drive\n","Project root: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\n","Loading from: casme2_vit_direct_evaluation_results.json (Apex-Only Test Set)\n","Results output: bootstrap_ci_results/\n","Evaluation results file verified: exists\n","\n","[STEP 2] Loading ViT evaluation results from existing JSON...\n","Evaluation results loaded successfully\n","  Model: ViT-patch32\n","  Phase: AF (Apex Frame)\n","  Test samples: 28\n","  Original Macro F1: 0.4235\n","  Original Accuracy: 0.5357\n","  Available classes: 6\n","  Missing classes: ['fear']\n","\n","[STEP 3] Reconstructing predictions from confusion matrix...\n","Predictions reconstructed successfully\n","  Total samples: 28\n","  Unique true labels: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n","  Unique predictions: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n","\n","[STEP 4] Verifying reconstructed predictions...\n","Reconstructed metrics:\n","  Accuracy: 0.5357\n","  Macro Precision: 0.5046\n","  Macro Recall: 0.4202\n","  Macro F1: 0.4235\n","\n","Verification check:\n","  Expected F1: 0.4235\n","  Calculated F1: 0.4235\n","  Difference: 0.000000\n","  Status: VERIFIED - Metrics match reported results perfectly\n","\n","Expected Accuracy: 0.5357\n","Calculated Accuracy: 0.5357\n","Difference: 0.000000\n","\n","Per-class F1 scores (verification):\n","  others [present]: F1=0.6364 (expected: 0.6364), Support=10\n","  disgust [present]: F1=0.5000 (expected: 0.5000), Support=7\n","  happiness [present]: F1=0.3333 (expected: 0.3333), Support=4\n","  repression [present]: F1=0.5714 (expected: 0.5714), Support=3\n","  surprise [present]: F1=0.5000 (expected: 0.5000), Support=3\n","  sadness [present]: F1=0.0000 (expected: 0.0000), Support=1\n","  fear [missing]: F1=0.0000 (expected: 0.0000), Support=0\n","\n","[STEP 5] Preparing comprehensive metadata...\n","\n","Test set distribution:\n","  others: 10 samples (35.7%)\n","  disgust: 7 samples (25.0%)\n","  happiness: 4 samples (14.3%)\n","  repression: 3 samples (10.7%)\n","  surprise: 3 samples (10.7%)\n","  sadness: 1 samples (3.6%)\n","  fear: 0 samples (0.0%)\n","\n","[STEP 6] Saving predictions for bootstrap analysis...\n","Predictions saved to JSON: vit_patch32_af_predictions.json\n","Predictions saved to pickle: vit_patch32_af_predictions.pkl\n","  JSON file size: 4.3 KB\n","  Pickle file size: 2.4 KB\n","\n","======================================================================\n","CELL 1 COMPLETED: PREDICTIONS LOADED AND VERIFIED\n","======================================================================\n","\n","Summary:\n","  Model: ViT-patch32 AF (Peak Single-Frame)\n","  Test dataset: Apex-Only (Phase 1, v1)\n","  Test samples: 28\n","  Macro F1: 0.4235\n","  Accuracy: 0.5357\n","  Verification: PASSED\n","\n","Output files:\n","  1. vit_patch32_af_predictions.json\n","  2. vit_patch32_af_predictions.pkl\n","\n","Next step:\n","  Run Cell 2 to perform bootstrap confidence interval analysis\n","  Expected bootstrap CI for F1 = 0.4235 with n=28 samples\n","\n","======================================================================\n"]}],"source":["# @title Cell 1: Bootstrap CI Configuration - Load ViT AF Evaluation Results\n","\n","# File: 10_2_Bootstrap_CI_ViT_AF_Cell1.py\n","# Location: experiments/10_2_Bootstrap_CI_ViT_AF.ipynb\n","# Purpose: Load ViT-patch32 AF predictions from existing evaluation results for bootstrap CI\n","\n","import os\n","import json\n","import pickle\n","import numpy as np\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from google.colab import drive\n","\n","print(\"=\" * 70)\n","print(\"BOOTSTRAP CONFIDENCE INTERVALS FOR VIT-PATCH32 AF\")\n","print(\"Statistical Validation via Resampling Methods\")\n","print(\"=\" * 70)\n","\n","# =====================================================\n","# SECTION 1: ENVIRONMENT CONFIGURATION\n","# =====================================================\n","\n","print(\"\\n[STEP 1] Mounting Google Drive and configuring environment...\")\n","drive.mount('/content/drive')\n","\n","# Project structure configuration\n","PROJECT_ROOT = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","EXPERIMENT_ID = \"run_02_patch32_FL\"\n","\n","# Path to existing evaluation results (AF = apex-only test set)\n","EVALUATION_RESULTS_PATH = f\"{PROJECT_ROOT}/results/02_01_vit_casme2-af/{EXPERIMENT_ID}/evaluation_results/casme2_vit_direct_evaluation_results.json\"\n","RESULTS_ROOT = f\"{PROJECT_ROOT}/results/bootstrap_ci_results\"\n","\n","# Create results directory\n","os.makedirs(RESULTS_ROOT, exist_ok=True)\n","\n","print(f\"Project root: {PROJECT_ROOT}\")\n","print(f\"Loading from: casme2_vit_direct_evaluation_results.json (Apex-Only Test Set)\")\n","print(f\"Results output: bootstrap_ci_results/\")\n","\n","# Verify evaluation results file exists\n","if not os.path.exists(EVALUATION_RESULTS_PATH):\n","    raise FileNotFoundError(f\"Evaluation results not found: {EVALUATION_RESULTS_PATH}\")\n","print(\"Evaluation results file verified: exists\")\n","\n","# CASME II configuration\n","CASME2_CLASSES = ['others', 'disgust', 'happiness', 'repression', 'surprise', 'sadness', 'fear']\n","CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CASME2_CLASSES)}\n","NUM_CLASSES = 7\n","\n","# =====================================================\n","# SECTION 2: LOAD EVALUATION RESULTS\n","# =====================================================\n","\n","print(\"\\n[STEP 2] Loading ViT evaluation results from existing JSON...\")\n","\n","with open(EVALUATION_RESULTS_PATH, 'r') as f:\n","    eval_results = json.load(f)\n","\n","# Extract metadata\n","eval_metadata = eval_results['evaluation_metadata']\n","overall_perf = eval_results['overall_performance']\n","confusion_matrix = np.array(eval_results['confusion_matrix'])\n","\n","print(f\"Evaluation results loaded successfully\")\n","print(f\"  Model: ViT-patch32\")\n","print(f\"  Phase: AF (Apex Frame)\")\n","print(f\"  Test samples: {eval_metadata['test_samples']}\")\n","print(f\"  Original Macro F1: {overall_perf['macro_f1']:.4f}\")\n","print(f\"  Original Accuracy: {overall_perf['accuracy']:.4f}\")\n","\n","# Identify available classes\n","available_classes = eval_metadata['available_classes']\n","missing_classes = eval_metadata['missing_classes']\n","\n","print(f\"  Available classes: {len(available_classes)}\")\n","print(f\"  Missing classes: {missing_classes}\")\n","\n","# =====================================================\n","# SECTION 3: RECONSTRUCT PREDICTIONS FROM CONFUSION MATRIX\n","# =====================================================\n","\n","print(\"\\n[STEP 3] Reconstructing predictions from confusion matrix...\")\n","\n","def reconstruct_predictions_from_confusion_matrix(cm, class_names):\n","    \"\"\"\n","    Reconstruct y_true and y_pred arrays from confusion matrix\n","\n","    Args:\n","        cm: Confusion matrix (true labels × predicted labels)\n","        class_names: List of class names\n","\n","    Returns:\n","        y_true, y_pred: Arrays of true and predicted labels\n","    \"\"\"\n","    y_true = []\n","    y_pred = []\n","\n","    # For each true class (rows)\n","    for true_idx in range(len(class_names)):\n","        # For each predicted class (columns)\n","        for pred_idx in range(len(class_names)):\n","            count = int(cm[true_idx, pred_idx])\n","            # Add 'count' samples with this true→pred mapping\n","            y_true.extend([true_idx] * count)\n","            y_pred.extend([pred_idx] * count)\n","\n","    return np.array(y_true), np.array(y_pred)\n","\n","# Reconstruct predictions\n","y_true, y_pred = reconstruct_predictions_from_confusion_matrix(confusion_matrix, CASME2_CLASSES)\n","\n","print(f\"Predictions reconstructed successfully\")\n","print(f\"  Total samples: {len(y_true)}\")\n","print(f\"  Unique true labels: {sorted(np.unique(y_true))}\")\n","print(f\"  Unique predictions: {sorted(np.unique(y_pred))}\")\n","\n","# =====================================================\n","# SECTION 4: VERIFY RECONSTRUCTED PREDICTIONS\n","# =====================================================\n","\n","print(\"\\n[STEP 4] Verifying reconstructed predictions...\")\n","\n","from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n","\n","# Calculate metrics on reconstructed predictions\n","test_accuracy = accuracy_score(y_true, y_pred)\n","\n","# Identify classes present in test set\n","unique_test_labels = sorted(np.unique(y_true))\n","\n","# Macro metrics - ONLY for classes present in test set\n","precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","    y_true, y_pred,\n","    average='macro',\n","    zero_division=0,\n","    labels=unique_test_labels\n",")\n","\n","print(\"Reconstructed metrics:\")\n","print(f\"  Accuracy: {test_accuracy:.4f}\")\n","print(f\"  Macro Precision: {precision_macro:.4f}\")\n","print(f\"  Macro Recall: {recall_macro:.4f}\")\n","print(f\"  Macro F1: {f1_macro:.4f}\")\n","\n","# Verification against original results\n","EXPECTED_F1 = overall_perf['macro_f1']\n","EXPECTED_ACC = overall_perf['accuracy']\n","\n","f1_diff = abs(f1_macro - EXPECTED_F1)\n","acc_diff = abs(test_accuracy - EXPECTED_ACC)\n","\n","print(\"\\nVerification check:\")\n","print(f\"  Expected F1: {EXPECTED_F1:.4f}\")\n","print(f\"  Calculated F1: {f1_macro:.4f}\")\n","print(f\"  Difference: {f1_diff:.6f}\")\n","\n","if f1_diff < 0.0001:\n","    print(\"  Status: VERIFIED - Metrics match reported results perfectly\")\n","elif f1_diff < 0.001:\n","    print(\"  Status: VERIFIED - Metrics match reported results (minor rounding)\")\n","else:\n","    print(f\"  Warning: Metrics differ by {f1_diff:.6f}\")\n","\n","print(f\"\\nExpected Accuracy: {EXPECTED_ACC:.4f}\")\n","print(f\"Calculated Accuracy: {test_accuracy:.4f}\")\n","print(f\"Difference: {acc_diff:.6f}\")\n","\n","# Per-class verification\n","per_class_perf = eval_results['per_class_performance']\n","\n","# Calculate per-class F1 properly\n","precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n","    y_true, y_pred,\n","    average=None,\n","    zero_division=0,\n","    labels=list(range(NUM_CLASSES))\n",")\n","\n","print(\"\\nPer-class F1 scores (verification):\")\n","for i, class_name in enumerate(CASME2_CLASSES):\n","    in_test = i in unique_test_labels\n","    status = \"present\" if in_test else \"missing\"\n","\n","    calculated_f1 = f1_per_class[i]\n","    expected_f1 = per_class_perf[class_name]['f1_score']\n","    support = int(support_per_class[i])\n","\n","    print(f\"  {class_name} [{status}]: F1={calculated_f1:.4f} (expected: {expected_f1:.4f}), Support={support}\")\n","\n","# =====================================================\n","# SECTION 5: PREPARE METADATA\n","# =====================================================\n","\n","print(\"\\n[STEP 5] Preparing comprehensive metadata...\")\n","\n","# Class distribution\n","test_dist = {}\n","for i, class_name in enumerate(CASME2_CLASSES):\n","    count = int(np.sum(y_true == i))\n","    test_dist[class_name] = count\n","\n","print(\"\\nTest set distribution:\")\n","for class_name in CASME2_CLASSES:\n","    count = test_dist[class_name]\n","    percentage = (count / len(y_true) * 100) if len(y_true) > 0 else 0\n","    print(f\"  {class_name}: {count} samples ({percentage:.1f}%)\")\n","\n","# =====================================================\n","# SECTION 6: SAVE PREDICTIONS FOR BOOTSTRAP\n","# =====================================================\n","\n","print(\"\\n[STEP 6] Saving predictions for bootstrap analysis...\")\n","\n","# Prepare data structure for bootstrap\n","bootstrap_data = {\n","    'metadata': {\n","        'model': 'ViT-patch32',\n","        'methodology': 'M1 (Raw Images)',\n","        'phase': 'AF (Apex Frame)',\n","        'experiment_id': EXPERIMENT_ID,\n","        'test_dataset': 'data_split_v1',\n","        'test_dataset_description': 'Phase 1 Apex-Only (Peak Single-Frame)',\n","        'test_samples': int(len(y_true)),\n","        'num_classes': NUM_CLASSES,\n","        'class_names': CASME2_CLASSES,\n","        'available_classes': available_classes,\n","        'missing_classes': missing_classes,\n","        'data_source': 'reconstructed_from_evaluation_results',\n","        'evaluation_timestamp': eval_metadata['evaluation_timestamp'],\n","        'bootstrap_timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    },\n","    'predictions': {\n","        'y_true': y_true.tolist(),\n","        'y_pred': y_pred.tolist(),\n","        'reconstruction_method': 'confusion_matrix',\n","        'original_confusion_matrix': confusion_matrix.tolist()\n","    },\n","    'metrics': {\n","        'accuracy': float(test_accuracy),\n","        'macro_precision': float(precision_macro),\n","        'macro_recall': float(recall_macro),\n","        'macro_f1': float(f1_macro),\n","        'macro_calculation_note': 'Macro metrics calculated only for classes present in test set',\n","        'class_distribution': test_dist,\n","        'original_metrics': overall_perf\n","    },\n","    'training_info': eval_results['training_information']\n","}\n","\n","# Save as JSON\n","json_path = f\"{RESULTS_ROOT}/vit_patch32_af_predictions.json\"\n","with open(json_path, 'w') as f:\n","    json.dump(bootstrap_data, f, indent=2)\n","\n","print(f\"Predictions saved to JSON: {os.path.basename(json_path)}\")\n","\n","# Save as pickle for fast loading in Cell 2\n","pickle_path = f\"{RESULTS_ROOT}/vit_patch32_af_predictions.pkl\"\n","with open(pickle_path, 'wb') as f:\n","    pickle.dump(bootstrap_data, f)\n","\n","print(f\"Predictions saved to pickle: {os.path.basename(pickle_path)}\")\n","\n","# Verification\n","file_size_json = os.path.getsize(json_path) / 1024\n","file_size_pkl = os.path.getsize(pickle_path) / 1024\n","print(f\"  JSON file size: {file_size_json:.1f} KB\")\n","print(f\"  Pickle file size: {file_size_pkl:.1f} KB\")\n","\n","# =====================================================\n","# SECTION 7: SUMMARY AND NEXT STEPS\n","# =====================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CELL 1 COMPLETED: PREDICTIONS LOADED AND VERIFIED\")\n","print(\"=\" * 70)\n","\n","print(\"\\nSummary:\")\n","print(f\"  Model: ViT-patch32 AF (Peak Single-Frame)\")\n","print(f\"  Test dataset: Apex-Only (Phase 1, v1)\")\n","print(f\"  Test samples: {len(y_true)}\")\n","print(f\"  Macro F1: {f1_macro:.4f}\")\n","print(f\"  Accuracy: {test_accuracy:.4f}\")\n","print(f\"  Verification: PASSED\")\n","\n","print(\"\\nOutput files:\")\n","print(f\"  1. {os.path.basename(json_path)}\")\n","print(f\"  2. {os.path.basename(pickle_path)}\")\n","\n","print(\"\\nNext step:\")\n","print(\"  Run Cell 2 to perform bootstrap confidence interval analysis\")\n","print(\"  Expected bootstrap CI for F1 = 0.4235 with n=28 samples\")\n","\n","print(\"\\n\" + \"=\" * 70)"]},{"cell_type":"code","source":["# @title Cell 2: Bootstrap Confidence Interval Analysis\n","\n","# File: 10_2_Bootstrap_CI_ViT_AF_Cell2.py\n","# Location: experiments/10_2_Bootstrap_CI_ViT_AF.ipynb\n","# Purpose: Calculate bootstrap confidence intervals for ViT-patch32 AF macro F1 score\n","\n","import os\n","import json\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, precision_recall_fscore_support\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"=\" * 70)\n","print(\"BOOTSTRAP CONFIDENCE INTERVAL ANALYSIS\")\n","print(\"Resampling-Based Statistical Validation - ViT-patch32 AF\")\n","print(\"=\" * 70)\n","\n","# =====================================================\n","# SECTION 1: CONFIGURATION AND DATA LOADING\n","# =====================================================\n","\n","print(\"\\n[STEP 1] Loading predictions from Cell 1...\")\n","\n","# Path configuration\n","PROJECT_ROOT = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","RESULTS_ROOT = f\"{PROJECT_ROOT}/results/bootstrap_ci_results\"\n","PREDICTIONS_PATH = f\"{RESULTS_ROOT}/vit_patch32_af_predictions.pkl\"\n","\n","# Verify predictions file exists\n","if not os.path.exists(PREDICTIONS_PATH):\n","    raise FileNotFoundError(f\"Predictions file not found: {PREDICTIONS_PATH}\")\n","\n","# Load predictions from Cell 1\n","with open(PREDICTIONS_PATH, 'rb') as f:\n","    bootstrap_data = pickle.load(f)\n","\n","# Extract data\n","y_true = np.array(bootstrap_data['predictions']['y_true'])\n","y_pred = np.array(bootstrap_data['predictions']['y_pred'])\n","metadata = bootstrap_data['metadata']\n","original_metrics = bootstrap_data['metrics']\n","\n","print(f\"Predictions loaded successfully\")\n","print(f\"  Model: {metadata['model']}\")\n","print(f\"  Phase: {metadata['phase']}\")\n","print(f\"  Test samples: {len(y_true)}\")\n","print(f\"  Original Macro F1: {original_metrics['macro_f1']:.4f}\")\n","\n","# Identify available classes (exclude classes with zero support)\n","unique_labels = sorted(np.unique(y_true))\n","available_classes = metadata['available_classes']\n","missing_classes = metadata['missing_classes']\n","\n","print(f\"  Available classes: {len(available_classes)}\")\n","print(f\"  Missing classes: {missing_classes}\")\n","\n","# =====================================================\n","# SECTION 2: BOOTSTRAP FUNCTION IMPLEMENTATION\n","# =====================================================\n","\n","print(\"\\n[STEP 2] Implementing bootstrap resampling function...\")\n","\n","def bootstrap_confidence_interval(y_true, y_pred, n_iterations=1000, confidence=0.95, seed=42):\n","    \"\"\"\n","    Calculate bootstrap confidence intervals for macro F1 score\n","\n","    Bootstrap resampling methodology:\n","    1. Resample test set with replacement (same size as original)\n","    2. Calculate macro F1 on resampled data (only for available classes)\n","    3. Repeat n_iterations times\n","    4. Calculate percentile-based confidence intervals\n","\n","    Args:\n","        y_true: Ground truth labels\n","        y_pred: Model predictions\n","        n_iterations: Number of bootstrap iterations (default: 1000)\n","        confidence: Confidence level (default: 0.95 for 95% CI)\n","        seed: Random seed for reproducibility\n","\n","    Returns:\n","        dict: Bootstrap results with CI bounds, mean, std, and distribution\n","    \"\"\"\n","    np.random.seed(seed)\n","\n","    n_samples = len(y_true)\n","    bootstrap_scores = []\n","\n","    # Identify available classes in original data\n","    unique_labels = sorted(np.unique(y_true))\n","\n","    print(f\"Bootstrap configuration:\")\n","    print(f\"  Iterations: {n_iterations}\")\n","    print(f\"  Confidence level: {confidence * 100:.0f}%\")\n","    print(f\"  Sample size: {n_samples}\")\n","    print(f\"  Random seed: {seed}\")\n","    print(f\"  Metric: Macro F1 (available classes only)\")\n","\n","    # Bootstrap iterations\n","    for i in tqdm(range(n_iterations), desc=\"Bootstrap resampling\"):\n","        # Resample with replacement\n","        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n","        y_true_boot = y_true[indices]\n","        y_pred_boot = y_pred[indices]\n","\n","        # Identify available classes in this bootstrap sample\n","        # (may differ from original if some classes not sampled)\n","        unique_boot = sorted(np.unique(y_true_boot))\n","\n","        # Calculate macro F1 only for available classes\n","        if len(unique_boot) > 0:\n","            _, _, f1_boot, _ = precision_recall_fscore_support(\n","                y_true_boot, y_pred_boot,\n","                average='macro',\n","                labels=unique_boot,\n","                zero_division=0\n","            )\n","            bootstrap_scores.append(f1_boot)\n","        else:\n","            # Edge case: empty bootstrap sample (extremely rare)\n","            bootstrap_scores.append(0.0)\n","\n","    bootstrap_scores = np.array(bootstrap_scores)\n","\n","    # Calculate confidence interval using percentile method\n","    alpha = (1 - confidence) / 2\n","    lower_percentile = alpha * 100\n","    upper_percentile = (1 - alpha) * 100\n","\n","    ci_lower = np.percentile(bootstrap_scores, lower_percentile)\n","    ci_upper = np.percentile(bootstrap_scores, upper_percentile)\n","    ci_mean = np.mean(bootstrap_scores)\n","    ci_std = np.std(bootstrap_scores)\n","    ci_median = np.median(bootstrap_scores)\n","\n","    results = {\n","        'confidence_interval': {\n","            'lower': float(ci_lower),\n","            'upper': float(ci_upper),\n","            'confidence_level': confidence\n","        },\n","        'statistics': {\n","            'mean': float(ci_mean),\n","            'median': float(ci_median),\n","            'std': float(ci_std),\n","            'min': float(np.min(bootstrap_scores)),\n","            'max': float(np.max(bootstrap_scores))\n","        },\n","        'bootstrap_distribution': bootstrap_scores.tolist(),\n","        'parameters': {\n","            'n_iterations': n_iterations,\n","            'n_samples': n_samples,\n","            'seed': seed\n","        }\n","    }\n","\n","    return results\n","\n","print(\"Bootstrap function implemented\")\n","print(\"  Method: Percentile-based confidence intervals\")\n","print(\"  Resampling: With replacement, preserving sample size\")\n","\n","# =====================================================\n","# SECTION 3: RUN BOOTSTRAP ANALYSIS\n","# =====================================================\n","\n","print(\"\\n[STEP 3] Running bootstrap analysis...\")\n","print(\"This may take 10-20 seconds for 1000 iterations\")\n","\n","# Run bootstrap with standard parameters\n","bootstrap_results = bootstrap_confidence_interval(\n","    y_true=y_true,\n","    y_pred=y_pred,\n","    n_iterations=1000,\n","    confidence=0.95,\n","    seed=42\n",")\n","\n","# Extract results\n","ci_lower = bootstrap_results['confidence_interval']['lower']\n","ci_upper = bootstrap_results['confidence_interval']['upper']\n","ci_mean = bootstrap_results['statistics']['mean']\n","ci_std = bootstrap_results['statistics']['std']\n","ci_median = bootstrap_results['statistics']['median']\n","\n","print(\"\\nBootstrap analysis completed\")\n","print(f\"  Bootstrap mean F1: {ci_mean:.4f}\")\n","print(f\"  Bootstrap std: {ci_std:.4f}\")\n","print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n","print(f\"  CI width: {ci_upper - ci_lower:.4f}\")\n","\n","# Compare with original metric\n","original_f1 = original_metrics['macro_f1']\n","bias = ci_mean - original_f1\n","\n","print(f\"\\nComparison with original:\")\n","print(f\"  Original F1: {original_f1:.4f}\")\n","print(f\"  Bootstrap mean: {ci_mean:.4f}\")\n","print(f\"  Bias: {bias:+.6f}\")\n","\n","if abs(bias) < 0.01:\n","    print(f\"  Assessment: Low bias, bootstrap distribution is centered\")\n","else:\n","    print(f\"  Assessment: Moderate bias detected\")\n","\n","# =====================================================\n","# SECTION 4: STATISTICAL INTERPRETATION\n","# =====================================================\n","\n","print(\"\\n[STEP 4] Statistical interpretation...\")\n","\n","# Calculate key statistics\n","ci_width = ci_upper - ci_lower\n","relative_ci_width = (ci_width / original_f1) * 100\n","margin_of_error = ci_width / 2\n","\n","print(\"Confidence interval analysis:\")\n","print(f\"  Point estimate (original): {original_f1:.4f}\")\n","print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n","print(f\"  Margin of error: ±{margin_of_error:.4f}\")\n","print(f\"  Relative CI width: {relative_ci_width:.1f}% of point estimate\")\n","\n","# Stability assessment\n","if ci_width < 0.10:\n","    stability = \"High stability\"\n","    interpretation = \"Narrow confidence interval indicates robust performance\"\n","elif ci_width < 0.15:\n","    stability = \"Moderate stability\"\n","    interpretation = \"Reasonable confidence interval for small test set\"\n","else:\n","    stability = \"Low stability\"\n","    interpretation = \"Wide confidence interval reflects test set size limitations\"\n","\n","print(f\"\\nStability assessment: {stability}\")\n","print(f\"  {interpretation}\")\n","\n","# Statistical significance heuristics\n","lower_bound_threshold = 0.35\n","if ci_lower > lower_bound_threshold:\n","    print(f\"\\nPerformance reliability:\")\n","    print(f\"  Lower bound ({ci_lower:.4f}) exceeds {lower_bound_threshold:.2f} threshold\")\n","    print(f\"  Conclusion: Consistently above baseline with 95% confidence\")\n","else:\n","    print(f\"\\nPerformance reliability:\")\n","    print(f\"  Lower bound ({ci_lower:.4f}) near or below {lower_bound_threshold:.2f} threshold\")\n","    print(f\"  Conclusion: Performance variability due to small test set\")\n","\n","# =====================================================\n","# SECTION 5: VISUALIZATION\n","# =====================================================\n","\n","print(\"\\n[STEP 5] Creating distribution visualization...\")\n","\n","# Set style\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 6)\n","plt.rcParams['font.size'] = 11\n","\n","# Create figure with two subplots\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n","\n","# Subplot 1: Bootstrap distribution histogram\n","bootstrap_distribution = np.array(bootstrap_results['bootstrap_distribution'])\n","\n","ax1.hist(bootstrap_distribution, bins=40, color='steelblue', alpha=0.7, edgecolor='black')\n","ax1.axvline(original_f1, color='red', linestyle='--', linewidth=2, label=f'Original F1: {original_f1:.4f}')\n","ax1.axvline(ci_lower, color='green', linestyle='--', linewidth=1.5, label=f'95% CI Lower: {ci_lower:.4f}')\n","ax1.axvline(ci_upper, color='green', linestyle='--', linewidth=1.5, label=f'95% CI Upper: {ci_upper:.4f}')\n","ax1.axvline(ci_mean, color='orange', linestyle='-', linewidth=2, label=f'Bootstrap Mean: {ci_mean:.4f}')\n","\n","ax1.set_xlabel('Macro F1 Score', fontsize=12, fontweight='bold')\n","ax1.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n","ax1.set_title('Bootstrap Distribution of Macro F1 Score\\nViT-patch32 AF (n=1000)',\n","              fontsize=13, fontweight='bold', pad=15)\n","ax1.legend(loc='upper left', fontsize=10, frameon=True, shadow=True)\n","ax1.grid(True, alpha=0.3)\n","\n","# Subplot 2: Box plot with confidence interval\n","box_data = [bootstrap_distribution]\n","bp = ax2.boxplot(box_data, vert=True, patch_artist=True, widths=0.5,\n","                 boxprops=dict(facecolor='lightblue', alpha=0.7),\n","                 medianprops=dict(color='red', linewidth=2),\n","                 whiskerprops=dict(color='black', linewidth=1.5),\n","                 capprops=dict(color='black', linewidth=1.5))\n","\n","ax2.axhline(original_f1, color='red', linestyle='--', linewidth=2, label=f'Original F1: {original_f1:.4f}')\n","ax2.axhline(ci_lower, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='95% CI Bounds')\n","ax2.axhline(ci_upper, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n","\n","ax2.set_ylabel('Macro F1 Score', fontsize=12, fontweight='bold')\n","ax2.set_title('Bootstrap Distribution Summary\\nwith 95% Confidence Interval',\n","              fontsize=13, fontweight='bold', pad=15)\n","ax2.set_xticks([1])\n","ax2.set_xticklabels(['Bootstrap Samples'], fontsize=11)\n","ax2.legend(loc='lower right', fontsize=10, frameon=True, shadow=True)\n","ax2.grid(True, alpha=0.3, axis='y')\n","\n","plt.tight_layout()\n","\n","# Save figure\n","plot_path = f\"{RESULTS_ROOT}/bootstrap_distribution_vit_patch32_af.png\"\n","plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n","print(f\"Distribution plot saved: {os.path.basename(plot_path)}\")\n","print(f\"  Resolution: 300 DPI (publication quality)\")\n","print(f\"  Location: {plot_path}\")\n","\n","# Close figure to free memory\n","plt.close()\n","\n","# =====================================================\n","# SECTION 6: SAVE RESULTS\n","# =====================================================\n","\n","print(\"\\n[STEP 6] Saving bootstrap results...\")\n","\n","# Prepare comprehensive results\n","final_results = {\n","    'model_information': {\n","        'model': metadata['model'],\n","        'methodology': metadata['methodology'],\n","        'phase': metadata['phase'],\n","        'experiment_id': metadata.get('experiment_id', 'run_02_patch32_FL'),\n","        'test_dataset': metadata['test_dataset'],\n","        'test_dataset_description': metadata['test_dataset_description']\n","    },\n","    'test_set_information': {\n","        'total_samples': len(y_true),\n","        'available_classes': available_classes,\n","        'missing_classes': missing_classes,\n","        'class_distribution': original_metrics.get('class_distribution', {})\n","    },\n","    'original_metrics': {\n","        'macro_f1': original_metrics['macro_f1'],\n","        'accuracy': original_metrics['accuracy'],\n","        'macro_precision': original_metrics['macro_precision'],\n","        'macro_recall': original_metrics['macro_recall']\n","    },\n","    'bootstrap_results': bootstrap_results,\n","    'interpretation': {\n","        'stability': stability,\n","        'ci_width': float(ci_width),\n","        'relative_ci_width_percent': float(relative_ci_width),\n","        'margin_of_error': float(margin_of_error),\n","        'bias': float(bias),\n","        'interpretation_text': interpretation\n","    },\n","    'paper_ready_text': {\n","        'inline_citation': f\"macro F1 of {original_f1:.4f} (95% CI: [{ci_lower:.4f}, {ci_upper:.4f}])\",\n","        'table_entry': f\"{original_f1:.4f} [{ci_lower:.4f}, {ci_upper:.4f}]\",\n","        'methods_text': f\"Bootstrap confidence intervals (1000 iterations) were calculated to assess statistical reliability of performance metrics on the {len(y_true)}-sample test set.\"\n","    },\n","    'analysis_metadata': {\n","        'analysis_timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n","        'bootstrap_method': 'percentile',\n","        'confidence_level': 0.95,\n","        'n_iterations': 1000,\n","        'random_seed': 42\n","    }\n","}\n","\n","# Save as JSON\n","results_path = f\"{RESULTS_ROOT}/bootstrap_ci_results_vit_patch32_af.json\"\n","with open(results_path, 'w') as f:\n","    json.dump(final_results, f, indent=2)\n","\n","print(f\"Bootstrap results saved: {os.path.basename(results_path)}\")\n","\n","# Save summary statistics as CSV for easy viewing\n","summary_df = pd.DataFrame({\n","    'Metric': ['Original F1', 'Bootstrap Mean', 'Bootstrap Median', 'Bootstrap Std',\n","               'CI Lower (95%)', 'CI Upper (95%)', 'CI Width', 'Margin of Error'],\n","    'Value': [original_f1, ci_mean, ci_median, ci_std,\n","              ci_lower, ci_upper, ci_width, margin_of_error]\n","})\n","\n","csv_path = f\"{RESULTS_ROOT}/bootstrap_summary_vit_patch32_af.csv\"\n","summary_df.to_csv(csv_path, index=False, float_format='%.4f')\n","print(f\"Summary statistics saved: {os.path.basename(csv_path)}\")\n","\n","file_size_json = os.path.getsize(results_path) / 1024\n","print(f\"  JSON file size: {file_size_json:.1f} KB\")\n","\n","# =====================================================\n","# SECTION 7: PAPER-READY OUTPUT\n","# =====================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"PAPER-READY RESULTS\")\n","print(\"=\" * 70)\n","\n","print(\"\\n1. INLINE CITATION (for Abstract/Results):\")\n","print(\"-\" * 70)\n","print(f\"ViT-patch32 achieved a {final_results['paper_ready_text']['inline_citation']} on\")\n","print(f\"the apex-only test set (n={len(y_true)}), demonstrating peak single-frame\")\n","print(f\"performance with statistical validation.\")\n","\n","print(\"\\n2. TABLE III UPDATE (Main Results):\")\n","print(\"-\" * 70)\n","print(f\"Phase    Model        M1 F1 (95% CI)\")\n","print(f\"AF       ViT-p32      {final_results['paper_ready_text']['table_entry']}\")\n","\n","print(\"\\n3. METHODS SECTION TEXT:\")\n","print(\"-\" * 70)\n","print(f\"{final_results['paper_ready_text']['methods_text']}\")\n","\n","print(\"\\n4. STATISTICAL DETAILS:\")\n","print(\"-\" * 70)\n","print(f\"Bootstrap resampling (n=1000 iterations) yielded a mean F1 of {ci_mean:.4f}\")\n","print(f\"(SD={ci_std:.4f}) with 95% confidence interval [{ci_lower:.4f}, {ci_upper:.4f}].\")\n","print(f\"The confidence interval (width={ci_width:.4f}, {relative_ci_width:.1f}% of point\")\n","print(f\"estimate) indicates {stability.lower()} with the 28-sample apex-only test set.\")\n","\n","# =====================================================\n","# SECTION 8: SUMMARY\n","# =====================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"BOOTSTRAP ANALYSIS COMPLETED - ViT-patch32 AF\")\n","print(\"=\" * 70)\n","\n","print(\"\\nKey findings:\")\n","print(f\"  Original macro F1: {original_f1:.4f}\")\n","print(f\"  95% Confidence Interval: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n","print(f\"  Margin of error: ±{margin_of_error:.4f}\")\n","print(f\"  Stability: {stability}\")\n","\n","print(\"\\nOutput files:\")\n","print(f\"  1. {os.path.basename(results_path)}\")\n","print(f\"  2. {os.path.basename(csv_path)}\")\n","print(f\"  3. {os.path.basename(plot_path)}\")\n","\n","print(\"\\nRecommendation for camera-ready paper:\")\n","print(f\"  Update Table III with: {original_f1:.4f} ({ci_lower:.4f}-{ci_upper:.4f})\")\n","print(f\"  Both PoolFormer MFS and ViT AF now have statistical validation\")\n","print(f\"  Add comprehensive Methods text about bootstrap validation\")\n","\n","print(\"\\n\" + \"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"flaC1DyAOpH7","executionInfo":{"status":"ok","timestamp":1763866183107,"user_tz":-420,"elapsed":4046,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"23f68912-95e9-47f4-dd62-6badadedbf56"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","BOOTSTRAP CONFIDENCE INTERVAL ANALYSIS\n","Resampling-Based Statistical Validation - ViT-patch32 AF\n","======================================================================\n","\n","[STEP 1] Loading predictions from Cell 1...\n","Predictions loaded successfully\n","  Model: ViT-patch32\n","  Phase: AF (Apex Frame)\n","  Test samples: 28\n","  Original Macro F1: 0.4235\n","  Available classes: 6\n","  Missing classes: ['fear']\n","\n","[STEP 2] Implementing bootstrap resampling function...\n","Bootstrap function implemented\n","  Method: Percentile-based confidence intervals\n","  Resampling: With replacement, preserving sample size\n","\n","[STEP 3] Running bootstrap analysis...\n","This may take 10-20 seconds for 1000 iterations\n","Bootstrap configuration:\n","  Iterations: 1000\n","  Confidence level: 95%\n","  Sample size: 28\n","  Random seed: 42\n","  Metric: Macro F1 (available classes only)\n"]},{"output_type":"stream","name":"stderr","text":["Bootstrap resampling: 100%|██████████| 1000/1000 [00:02<00:00, 449.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Bootstrap analysis completed\n","  Bootstrap mean F1: 0.4220\n","  Bootstrap std: 0.1197\n","  95% CI: [0.2209, 0.6825]\n","  CI width: 0.4616\n","\n","Comparison with original:\n","  Original F1: 0.4235\n","  Bootstrap mean: 0.4220\n","  Bias: -0.001480\n","  Assessment: Low bias, bootstrap distribution is centered\n","\n","[STEP 4] Statistical interpretation...\n","Confidence interval analysis:\n","  Point estimate (original): 0.4235\n","  95% CI: [0.2209, 0.6825]\n","  Margin of error: ±0.2308\n","  Relative CI width: 109.0% of point estimate\n","\n","Stability assessment: Low stability\n","  Wide confidence interval reflects test set size limitations\n","\n","Performance reliability:\n","  Lower bound (0.2209) near or below 0.35 threshold\n","  Conclusion: Performance variability due to small test set\n","\n","[STEP 5] Creating distribution visualization...\n","Distribution plot saved: bootstrap_distribution_vit_patch32_af.png\n","  Resolution: 300 DPI (publication quality)\n","  Location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/results/bootstrap_ci_results/bootstrap_distribution_vit_patch32_af.png\n","\n","[STEP 6] Saving bootstrap results...\n","Bootstrap results saved: bootstrap_ci_results_vit_patch32_af.json\n","Summary statistics saved: bootstrap_summary_vit_patch32_af.csv\n","  JSON file size: 27.8 KB\n","\n","======================================================================\n","PAPER-READY RESULTS\n","======================================================================\n","\n","1. INLINE CITATION (for Abstract/Results):\n","----------------------------------------------------------------------\n","ViT-patch32 achieved a macro F1 of 0.4235 (95% CI: [0.2209, 0.6825]) on\n","the apex-only test set (n=28), demonstrating peak single-frame\n","performance with statistical validation.\n","\n","2. TABLE III UPDATE (Main Results):\n","----------------------------------------------------------------------\n","Phase    Model        M1 F1 (95% CI)\n","AF       ViT-p32      0.4235 [0.2209, 0.6825]\n","\n","3. METHODS SECTION TEXT:\n","----------------------------------------------------------------------\n","Bootstrap confidence intervals (1000 iterations) were calculated to assess statistical reliability of performance metrics on the 28-sample test set.\n","\n","4. STATISTICAL DETAILS:\n","----------------------------------------------------------------------\n","Bootstrap resampling (n=1000 iterations) yielded a mean F1 of 0.4220\n","(SD=0.1197) with 95% confidence interval [0.2209, 0.6825].\n","The confidence interval (width=0.4616, 109.0% of point\n","estimate) indicates low stability with the 28-sample apex-only test set.\n","\n","======================================================================\n","BOOTSTRAP ANALYSIS COMPLETED - ViT-patch32 AF\n","======================================================================\n","\n","Key findings:\n","  Original macro F1: 0.4235\n","  95% Confidence Interval: [0.2209, 0.6825]\n","  Margin of error: ±0.2308\n","  Stability: Low stability\n","\n","Output files:\n","  1. bootstrap_ci_results_vit_patch32_af.json\n","  2. bootstrap_summary_vit_patch32_af.csv\n","  3. bootstrap_distribution_vit_patch32_af.png\n","\n","Recommendation for camera-ready paper:\n","  Update Table III with: 0.4235 (0.2209-0.6825)\n","  Both PoolFormer MFS and ViT AF now have statistical validation\n","  Add comprehensive Methods text about bootstrap validation\n","\n","======================================================================\n"]}]}]}