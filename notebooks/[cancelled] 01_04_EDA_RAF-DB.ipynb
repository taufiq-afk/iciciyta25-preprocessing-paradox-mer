{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRrbY1mb3EH1MPdFcL8gVG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"l9lvn4991rrc","executionInfo":{"status":"ok","timestamp":1759728238753,"user_tz":-420,"elapsed":563053,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"5864001c-7b65-4d4f-8aa6-ef66c93dd6f7","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","RAF-DB BALANCED DATASET EXTRACTION\n","======================================================================\n","\n","[1] Mounting Google Drive...\n","Mounted at /content/drive\n","    Google Drive mounted successfully\n","\n","[2] Path Configuration\n","    ZIP file location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/raw/RAF-DB_balanced.zip\n","    Extract destination: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_raf\n","    ZIP file verified (Size: 124.0 MB)\n","\n","[3] Cleanup Previous Extractions\n","    No existing directory found\n","    Created fresh extraction directory\n","\n","[4] Analyzing ZIP Structure\n","    Total files in ZIP: 41692\n","    Root directories: ['test', 'train', 'val']\n","    Split folders detected: ['test', 'train', 'val']\n","    Class structure:\n","      test: 7 classes - ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","      train: 7 classes - ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","      val: 7 classes - ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","\n","[5] Extracting ZIP Contents\n","    Progress: 4170/41692 (10%) | Rate: 79.8 files/sec | ETA: 470.0s\n","    Progress: 8339/41692 (20%) | Rate: 80.1 files/sec | ETA: 416.4s\n","    Progress: 12508/41692 (30%) | Rate: 79.4 files/sec | ETA: 367.7s\n","    Progress: 16677/41692 (40%) | Rate: 79.2 files/sec | ETA: 315.6s\n","    Progress: 20846/41692 (50%) | Rate: 78.9 files/sec | ETA: 264.1s\n","    Progress: 25016/41692 (60%) | Rate: 78.6 files/sec | ETA: 212.1s\n","    Progress: 29185/41692 (70%) | Rate: 78.4 files/sec | ETA: 159.5s\n","    Progress: 33354/41692 (80%) | Rate: 78.3 files/sec | ETA: 106.5s\n","    Progress: 37523/41692 (90%) | Rate: 78.3 files/sec | ETA: 53.3s\n","    Progress: 41692/41692 (100%) | Rate: 78.6 files/sec | ETA: 0.0s\n","\n","    Extraction completed:\n","      Files extracted: 41692/41692\n","      Errors: 0\n","      Time: 530.56s (78.6 files/sec)\n","\n","[6] Verifying Extraction Results\n","    Waiting for Google Drive sync (3 seconds)...\n","    Extracted structure:\n","      test/: 4165 files, 7 classes\n","      train/: 30023 files, 7 classes\n","      val/: 7504 files, 7 classes\n","\n","======================================================================\n","EXTRACTION SUMMARY\n","======================================================================\n","Status: SUCCESS\n","Files processed: 41692/41692\n","Files verified in directory: 41692\n","Error rate: 0.00%\n","Extraction time: 530.6 seconds\n","Output location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/processed_raf\n","\n","Ready for Cell 2: Structure validation and metadata generation\n","======================================================================\n"]}],"source":["# @title Cell 1: RAF-DB ZIP Extraction\n","\n","# File: 01_04_EDA_RAF-DB.ipynb - Cell 1\n","# Location: RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/notebooks/\n","# Purpose: Robust RAF-DB Balanced dataset ZIP extraction with validation\n","\n","import os\n","import zipfile\n","import time\n","from google.colab import drive\n","\n","# Mount Google Drive\n","print(\"=\" * 70)\n","print(\"RAF-DB BALANCED DATASET EXTRACTION\")\n","print(\"=\" * 70)\n","print(\"\\n[1] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"    Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","raw_path = f\"{base_path}/datasets/raw\"\n","processed_path = f\"{base_path}/datasets/processed_raf\"\n","zip_file_path = f\"{raw_path}/RAF-DB_balanced.zip\"\n","\n","print(f\"\\n[2] Path Configuration\")\n","print(f\"    ZIP file location: {zip_file_path}\")\n","print(f\"    Extract destination: {processed_path}\")\n","\n","# Verify ZIP file existence\n","if not os.path.exists(zip_file_path):\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"ERROR: RAF-DB_balanced.zip not found\")\n","    print(\"Please ensure ZIP file is uploaded to datasets/raw/ directory\")\n","    print(\"=\" * 70)\n","    raise FileNotFoundError(\"ZIP file not found\")\n","\n","zip_size_mb = round(os.path.getsize(zip_file_path) / (1024 * 1024), 2)\n","print(f\"    ZIP file verified (Size: {zip_size_mb} MB)\")\n","\n","# Cleanup previous extraction attempts\n","print(f\"\\n[3] Cleanup Previous Extractions\")\n","if os.path.exists(processed_path):\n","    import shutil\n","    shutil.rmtree(processed_path)\n","    print(f\"    Removed existing directory: processed_raf/\")\n","else:\n","    print(f\"    No existing directory found\")\n","\n","# Create fresh extraction directory\n","os.makedirs(processed_path, exist_ok=True)\n","print(f\"    Created fresh extraction directory\")\n","\n","# Analyze ZIP structure\n","print(f\"\\n[4] Analyzing ZIP Structure\")\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        file_list = zip_ref.namelist()\n","        total_files = len(file_list)\n","\n","        # Analyze directory structure\n","        directories = set()\n","        split_folders = set()\n","        class_folders = {}\n","\n","        for file_path in file_list:\n","            parts = file_path.split('/')\n","            if len(parts) > 1:\n","                directories.add(parts[0])\n","                # Check for split folders (train/val/test)\n","                if len(parts) > 1 and parts[0] in ['train', 'val', 'test']:\n","                    split_folders.add(parts[0])\n","                    if len(parts) > 2:\n","                        class_name = parts[1]\n","                        if class_name and not class_name.startswith('.'):\n","                            if parts[0] not in class_folders:\n","                                class_folders[parts[0]] = set()\n","                            class_folders[parts[0]].add(class_name)\n","\n","        print(f\"    Total files in ZIP: {total_files}\")\n","        print(f\"    Root directories: {sorted(list(directories))}\")\n","        print(f\"    Split folders detected: {sorted(list(split_folders))}\")\n","\n","        if class_folders:\n","            print(f\"    Class structure:\")\n","            for split in sorted(class_folders.keys()):\n","                classes = sorted(list(class_folders[split]))\n","                print(f\"      {split}: {len(classes)} classes - {classes}\")\n","\n","except Exception as e:\n","    print(f\"\\n    ERROR analyzing ZIP: {str(e)}\")\n","    raise\n","\n","# Robust extraction with progress tracking\n","print(f\"\\n[5] Extracting ZIP Contents\")\n","start_time = time.time()\n","\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        extracted_count = 0\n","        error_count = 0\n","        last_progress = 0\n","\n","        for file_info in zip_ref.infolist():\n","            try:\n","                # Extract to processed_raf directory\n","                zip_ref.extract(file_info, processed_path)\n","                extracted_count += 1\n","\n","                # Progress tracking every 10%\n","                progress = int((extracted_count / total_files) * 100)\n","                if progress >= last_progress + 10:\n","                    elapsed = time.time() - start_time\n","                    rate = extracted_count / elapsed if elapsed > 0 else 0\n","                    remaining = total_files - extracted_count\n","                    eta = remaining / rate if rate > 0 else 0\n","\n","                    print(f\"    Progress: {extracted_count}/{total_files} ({progress}%) | \"\n","                          f\"Rate: {rate:.1f} files/sec | ETA: {eta:.1f}s\")\n","                    last_progress = progress\n","\n","            except Exception as file_error:\n","                error_count += 1\n","                if error_count <= 3:\n","                    print(f\"    Warning: Error extracting {file_info.filename[:50]}...\")\n","\n","        extraction_time = time.time() - start_time\n","        print(f\"\\n    Extraction completed:\")\n","        print(f\"      Files extracted: {extracted_count}/{total_files}\")\n","        print(f\"      Errors: {error_count}\")\n","        print(f\"      Time: {extraction_time:.2f}s ({extracted_count/extraction_time:.1f} files/sec)\")\n","\n","except Exception as e:\n","    print(f\"\\n    EXTRACTION FAILED: {str(e)}\")\n","    raise\n","\n","# Wait for Google Drive sync\n","print(f\"\\n[6] Verifying Extraction Results\")\n","print(f\"    Waiting for Google Drive sync (3 seconds)...\")\n","time.sleep(3)\n","\n","# Verify extraction structure\n","extracted_items = []\n","total_extracted_files = 0\n","\n","for item in os.listdir(processed_path):\n","    item_path = os.path.join(processed_path, item)\n","    if os.path.isdir(item_path):\n","        extracted_items.append(item)\n","\n","print(f\"    Extracted structure:\")\n","for item in sorted(extracted_items):\n","    item_path = os.path.join(processed_path, item)\n","\n","    # Count files in split folder\n","    split_file_count = 0\n","    split_class_count = 0\n","\n","    if os.path.exists(item_path):\n","        for root, dirs, files in os.walk(item_path):\n","            split_file_count += len(files)\n","            # Count class directories\n","            if root == item_path:\n","                split_class_count = len([d for d in dirs if not d.startswith('.')])\n","\n","        total_extracted_files += split_file_count\n","        print(f\"      {item}/: {split_file_count} files, {split_class_count} classes\")\n","\n","# Final status summary\n","extraction_success = (extracted_count > 0 and\n","                     error_count < (total_files * 0.1) and\n","                     total_extracted_files > 0)\n","\n","print(f\"\\n\" + \"=\" * 70)\n","print(\"EXTRACTION SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"Status: {'SUCCESS' if extraction_success else 'PARTIAL/FAILED'}\")\n","print(f\"Files processed: {extracted_count}/{total_files}\")\n","print(f\"Files verified in directory: {total_extracted_files}\")\n","print(f\"Error rate: {(error_count/total_files)*100:.2f}%\" if total_files > 0 else \"N/A\")\n","print(f\"Extraction time: {extraction_time:.1f} seconds\")\n","print(f\"Output location: {processed_path}\")\n","\n","if extraction_success:\n","    print(f\"\\nReady for Cell 2: Structure validation and metadata generation\")\n","else:\n","    print(f\"\\nWarning: Partial extraction detected - review errors before proceeding\")\n","\n","print(\"=\" * 70)"]},{"cell_type":"code","source":["# @title Cell 2: RAF-DB Validation & Metadata Generation\n","\n","# File: 01_04_EDA_RAF-DB.ipynb - Cell 2\n","# Location: RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/notebooks/\n","# Purpose: RAF-DB extraction validation and metadata CSV generation\n","\n","import os\n","import pandas as pd\n","from PIL import Image\n","import random\n","from pathlib import Path\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","processed_path = f\"{base_path}/datasets/processed_raf\"\n","metadata_path = f\"{base_path}/datasets/metadata\"\n","\n","print(\"=\" * 70)\n","print(\"RAF-DB VALIDATION & METADATA GENERATION\")\n","print(\"=\" * 70)\n","\n","# Expected structure\n","expected_splits = ['train', 'val', 'test']\n","expected_classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","\n","# Step 1: Directory Structure Validation\n","print(\"\\n[1] Directory Structure Validation\")\n","\n","structure_valid = True\n","split_summary = {}\n","\n","for split in expected_splits:\n","    split_path = os.path.join(processed_path, split)\n","\n","    if not os.path.exists(split_path):\n","        print(f\"    ERROR: Missing split directory: {split}/\")\n","        structure_valid = False\n","        continue\n","\n","    split_summary[split] = {}\n","    found_classes = os.listdir(split_path)\n","    found_classes = [c for c in found_classes if not c.startswith('.')]\n","\n","    for class_name in expected_classes:\n","        class_path = os.path.join(split_path, class_name)\n","\n","        if not os.path.exists(class_path):\n","            print(f\"    WARNING: Missing class {split}/{class_name}/\")\n","            split_summary[split][class_name] = 0\n","        else:\n","            files = [f for f in os.listdir(class_path) if not f.startswith('.')]\n","            split_summary[split][class_name] = len(files)\n","\n","if structure_valid:\n","    print(f\"    Structure validation: PASSED\")\n","    print(f\"    Splits found: {len(expected_splits)} ({', '.join(expected_splits)})\")\n","    print(f\"    Classes found: {len(expected_classes)} ({', '.join(expected_classes)})\")\n","else:\n","    print(f\"    Structure validation: FAILED\")\n","\n","# Print initial counts\n","print(f\"\\n    Initial file counts:\")\n","for split in expected_splits:\n","    total = sum(split_summary[split].values())\n","    print(f\"      {split}: {total} files across {len(split_summary[split])} classes\")\n","\n","# Step 2: Filename Pattern Analysis\n","print(f\"\\n[2] Filename Pattern Analysis\")\n","\n","sample_filenames = {}\n","for split in expected_splits:\n","    sample_filenames[split] = {}\n","    for class_name in expected_classes:\n","        class_path = os.path.join(processed_path, split, class_name)\n","        if os.path.exists(class_path):\n","            files = [f for f in os.listdir(class_path) if not f.startswith('.')]\n","            # Get first 3 samples\n","            samples = files[:3] if len(files) >= 3 else files\n","            sample_filenames[split][class_name] = samples\n","\n","# Print samples from train split only (to keep output clean)\n","print(f\"    Sample filenames from train split:\")\n","for class_name in expected_classes:\n","    if class_name in sample_filenames['train']:\n","        samples = sample_filenames['train'][class_name]\n","        if samples:\n","            print(f\"      {class_name}: {samples[0]}\")\n","\n","# Assess pattern\n","print(f\"\\n    Pattern assessment:\")\n","all_samples = []\n","for split in sample_filenames:\n","    for class_name in sample_filenames[split]:\n","        all_samples.extend(sample_filenames[split][class_name])\n","\n","if all_samples:\n","    # Check for common patterns\n","    has_split_prefix = any(split in fname for fname in all_samples for split in expected_splits)\n","    has_numbers = any(any(char.isdigit() for char in fname) for fname in all_samples)\n","    extensions = set([os.path.splitext(f)[1] for f in all_samples])\n","\n","    print(f\"      Contains split prefix: {has_split_prefix}\")\n","    print(f\"      Contains numeric sequences: {has_numbers}\")\n","    print(f\"      File extensions: {extensions}\")\n","    print(f\"      Pattern classification: Irregular (mixed formats detected)\")\n","\n","# Step 3: Image Integrity Validation\n","print(f\"\\n[3] Image Integrity Validation\")\n","\n","# Sample 50 random images for validation (efficient approach)\n","validation_sample_size = 50\n","all_image_paths = []\n","\n","for split in expected_splits:\n","    for class_name in expected_classes:\n","        class_path = os.path.join(processed_path, split, class_name)\n","        if os.path.exists(class_path):\n","            files = [os.path.join(class_path, f) for f in os.listdir(class_path)\n","                    if not f.startswith('.') and f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","            all_image_paths.extend(files)\n","\n","if len(all_image_paths) > validation_sample_size:\n","    sample_paths = random.sample(all_image_paths, validation_sample_size)\n","else:\n","    sample_paths = all_image_paths\n","\n","print(f\"    Validating {len(sample_paths)} random samples...\")\n","\n","resolutions = {}\n","color_modes = {}\n","corrupted_count = 0\n","validated_count = 0\n","\n","for img_path in sample_paths:\n","    try:\n","        with Image.open(img_path) as img:\n","            resolution = f\"{img.size[0]}x{img.size[1]}\"\n","            mode = img.mode\n","\n","            resolutions[resolution] = resolutions.get(resolution, 0) + 1\n","            color_modes[mode] = color_modes.get(mode, 0) + 1\n","            validated_count += 1\n","\n","    except Exception as e:\n","        corrupted_count += 1\n","\n","# Print validation results\n","print(f\"    Validation results:\")\n","print(f\"      Successfully validated: {validated_count}/{len(sample_paths)}\")\n","print(f\"      Corrupted files: {corrupted_count}\")\n","\n","if resolutions:\n","    print(f\"      Resolution distribution:\")\n","    for res, count in sorted(resolutions.items(), key=lambda x: x[1], reverse=True):\n","        percentage = (count/validated_count)*100\n","        print(f\"        {res}: {count} images ({percentage:.1f}%)\")\n","\n","if color_modes:\n","    print(f\"      Color mode distribution:\")\n","    for mode, count in sorted(color_modes.items(), key=lambda x: x[1], reverse=True):\n","        percentage = (count/validated_count)*100\n","        print(f\"        {mode}: {count} images ({percentage:.1f}%)\")\n","\n","# Step 4: Generate Metadata CSV\n","print(f\"\\n[4] Generating Metadata CSV\")\n","\n","metadata_records = []\n","total_processed = 0\n","\n","for split in expected_splits:\n","    for class_name in expected_classes:\n","        class_path = os.path.join(processed_path, split, class_name)\n","\n","        if os.path.exists(class_path):\n","            files = [f for f in os.listdir(class_path) if not f.startswith('.')]\n","\n","            for filename in files:\n","                # Create relative filepath from base research directory\n","                relative_path = f\"datasets/processed_raf/{split}/{class_name}/{filename}\"\n","\n","                metadata_records.append({\n","                    'filepath': relative_path,\n","                    'emotion_label': class_name,\n","                    'split': split\n","                })\n","                total_processed += 1\n","\n","# Create DataFrame and save\n","df_metadata = pd.DataFrame(metadata_records)\n","\n","# Create metadata directory if not exists\n","os.makedirs(metadata_path, exist_ok=True)\n","\n","# Save CSV\n","csv_path = os.path.join(metadata_path, \"rafdb_metadata.csv\")\n","df_metadata.to_csv(csv_path, index=False)\n","\n","print(f\"    Total images processed: {total_processed}\")\n","print(f\"    Metadata records created: {len(metadata_records)}\")\n","print(f\"    CSV saved: datasets/metadata/rafdb_metadata.csv\")\n","\n","# Step 5: Distribution Summary\n","print(f\"\\n[5] Distribution Summary\")\n","\n","# Create distribution table\n","distribution_data = []\n","\n","for class_name in expected_classes:\n","    row = {'Emotion': class_name}\n","    total = 0\n","\n","    for split in expected_splits:\n","        count = len(df_metadata[(df_metadata['emotion_label'] == class_name) &\n","                                (df_metadata['split'] == split)])\n","        row[split.capitalize()] = count\n","        total += count\n","\n","    row['Total'] = total\n","\n","    # Calculate percentage of total dataset\n","    row['Percentage'] = f\"{(total/len(df_metadata))*100:.2f}%\"\n","\n","    distribution_data.append(row)\n","\n","# Add totals row\n","totals_row = {'Emotion': 'TOTAL'}\n","for split in expected_splits:\n","    totals_row[split.capitalize()] = len(df_metadata[df_metadata['split'] == split])\n","totals_row['Total'] = len(df_metadata)\n","totals_row['Percentage'] = \"100.00%\"\n","distribution_data.append(totals_row)\n","\n","df_distribution = pd.DataFrame(distribution_data)\n","\n","print(\"\\n    Class Distribution Table:\")\n","print(df_distribution.to_string(index=False))\n","\n","# Balance analysis\n","print(f\"\\n    Balance Analysis:\")\n","class_counts = df_metadata['emotion_label'].value_counts()\n","max_count = class_counts.max()\n","min_count = class_counts.min()\n","imbalance_ratio = max_count / min_count if min_count > 0 else 0\n","\n","print(f\"      Most frequent class: {class_counts.idxmax()} ({max_count} samples)\")\n","print(f\"      Least frequent class: {class_counts.idxmin()} ({min_count} samples)\")\n","print(f\"      Imbalance ratio: {imbalance_ratio:.2f}:1\")\n","\n","if imbalance_ratio > 3:\n","    print(f\"      Status: HIGHLY IMBALANCED (consider augmentation or weighting)\")\n","elif imbalance_ratio > 2:\n","    print(f\"      Status: MODERATELY IMBALANCED (monitor during training)\")\n","else:\n","    print(f\"      Status: RELATIVELY BALANCED\")\n","\n","# Final Summary\n","print(f\"\\n\" + \"=\" * 70)\n","print(\"VALIDATION & METADATA SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"Structure: {'VALID' if structure_valid else 'INVALID'}\")\n","print(f\"Total images: {len(df_metadata)}\")\n","print(f\"Splits: Train={len(df_metadata[df_metadata['split']=='train'])}, \"\n","      f\"Val={len(df_metadata[df_metadata['split']=='val'])}, \"\n","      f\"Test={len(df_metadata[df_metadata['split']=='test'])}\")\n","print(f\"Classes: {len(expected_classes)} emotion categories\")\n","print(f\"Image integrity: {validated_count}/{len(sample_paths)} samples validated\")\n","print(f\"Metadata CSV: {csv_path}\")\n","print(f\"\\nReady for Cell 3: Distribution visualization\")\n","print(\"=\" * 70)"],"metadata":{"id":"7c-zt0SRKiK2","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"executionInfo":{"status":"ok","timestamp":1759753289020,"user_tz":-420,"elapsed":91937,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"3e3688cf-151f-4d01-85b0-afb4f9af7032"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","======================================================================\n","RAF-DB VALIDATION & METADATA GENERATION\n","======================================================================\n","\n","[1] Directory Structure Validation\n","    Structure validation: PASSED\n","    Splits found: 3 (train, val, test)\n","    Classes found: 7 (angry, disgust, fear, happy, neutral, sad, surprise)\n","\n","    Initial file counts:\n","      train: 30023 files across 7 classes\n","      val: 7504 files across 7 classes\n","      test: 4165 files across 7 classes\n","\n","[2] Filename Pattern Analysis\n","    Sample filenames from train split:\n","      angry: aug_881535.png\n","      disgust: aug_888266.png\n","      fear: aug_822167.png\n","      happy: train_06001_aligned.jpg\n","      neutral: train_10861_aligned.jpg\n","      sad: train_03671_aligned.jpg\n","      surprise: aug_975984.png\n","\n","    Pattern assessment:\n","      Contains split prefix: True\n","      Contains numeric sequences: True\n","      File extensions: {'.jpg', '.png'}\n","      Pattern classification: Irregular (mixed formats detected)\n","\n","[3] Image Integrity Validation\n","    Validating 50 random samples...\n","    Validation results:\n","      Successfully validated: 50/50\n","      Corrupted files: 0\n","      Resolution distribution:\n","        75x75: 50 images (100.0%)\n","      Color mode distribution:\n","        L: 50 images (100.0%)\n","\n","[4] Generating Metadata CSV\n","    Total images processed: 41692\n","    Metadata records created: 41692\n","    CSV saved: datasets/metadata/rafdb_metadata.csv\n","\n","[5] Distribution Summary\n","\n","    Class Distribution Table:\n"," Emotion  Train  Val  Test  Total Percentage\n","   angry   4289 1072   595   5956     14.29%\n"," disgust   4289 1072   595   5956     14.29%\n","    fear   4289 1072   595   5956     14.29%\n","   happy   4289 1072   595   5956     14.29%\n"," neutral   4289 1072   595   5956     14.29%\n","     sad   4289 1072   595   5956     14.29%\n","surprise   4289 1072   595   5956     14.29%\n","   TOTAL  30023 7504  4165  41692    100.00%\n","\n","    Balance Analysis:\n","      Most frequent class: angry (5956 samples)\n","      Least frequent class: angry (5956 samples)\n","      Imbalance ratio: 1.00:1\n","      Status: RELATIVELY BALANCED\n","\n","======================================================================\n","VALIDATION & METADATA SUMMARY\n","======================================================================\n","Structure: VALID\n","Total images: 41692\n","Splits: Train=30023, Val=7504, Test=4165\n","Classes: 7 emotion categories\n","Image integrity: 50/50 samples validated\n","Metadata CSV: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/metadata/rafdb_metadata.csv\n","\n","Ready for Cell 3: Distribution visualization\n","======================================================================\n"]}]},{"cell_type":"code","source":["# @title Cell 3: RAF-DB Distribution Visualization\n","\n","# File: 01_04_EDA_RAF-DB.ipynb - Cell 3\n","# Location: RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/notebooks/\n","# Purpose: Generate professional visualizations for RAF-DB balanced dataset\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Professional visualization setup\n","plt.style.use('default')\n","plt.rcParams.update({\n","    'font.family': 'DejaVu Sans',\n","    'font.size': 12,\n","    'axes.titlesize': 16,\n","    'axes.labelsize': 14,\n","    'xtick.labelsize': 12,\n","    'ytick.labelsize': 12,\n","    'legend.fontsize': 11,\n","    'figure.titlesize': 18,\n","    'axes.spines.top': False,\n","    'axes.spines.right': False,\n","    'axes.grid': False,\n","    'figure.facecolor': 'white',\n","    'axes.facecolor': 'white'\n","})\n","\n","def convert_to_serializable(obj):\n","    \"\"\"Convert numpy/pandas types to native Python types for JSON serialization\"\"\"\n","    if isinstance(obj, dict):\n","        return {key: convert_to_serializable(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_serializable(item) for item in obj]\n","    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif pd.isna(obj):\n","        return None\n","    else:\n","        return obj\n","\n","# Color palettes\n","SPLIT_COLORS = {\n","    'train': '#ff7f0e',\n","    'val': '#d62728',\n","    'test': '#2ca02c'\n","}\n","\n","EMOTION_COLORS = {\n","    'angry': '#d62728',\n","    'disgust': '#8c564b',\n","    'fear': '#e377c2',\n","    'happy': '#2ca02c',\n","    'neutral': '#7f7f7f',\n","    'sad': '#17becf',\n","    'surprise': '#ff7f0e'\n","}\n","\n","print(\"=\" * 80)\n","print(\"RAF-DB BALANCED DATASET VISUALIZATION\")\n","print(\"=\" * 80)\n","\n","print(\"\\n[1] Environment setup and drive mounting...\")\n","drive.mount('/content/drive')\n","print(\"    Google Drive mounted successfully\")\n","\n","# Define paths\n","base_path = \"/content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project\"\n","metadata_csv_path = f\"{base_path}/datasets/metadata/rafdb_metadata.csv\"\n","visualization_path = f\"{base_path}/datasets/visualization/04_raf-db\"\n","\n","os.makedirs(visualization_path, exist_ok=True)\n","print(f\"    Output directory created: {visualization_path}\")\n","\n","print(\"\\n[2] Loading RAF-DB metadata...\")\n","\n","try:\n","    df_metadata = pd.read_csv(metadata_csv_path)\n","    print(f\"    Metadata loaded: {len(df_metadata)} images\")\n","    print(f\"    Columns: {list(df_metadata.columns)}\")\n","except Exception as e:\n","    print(f\"    ERROR loading metadata: {str(e)}\")\n","    exit()\n","\n","print(\"\\n[3] Analyzing distribution...\")\n","\n","# Get unique emotions and splits\n","all_emotions = sorted(df_metadata['emotion_label'].unique())\n","all_splits = ['train', 'val', 'test']\n","\n","print(f\"    Emotion classes: {len(all_emotions)}\")\n","print(f\"    Classes: {all_emotions}\")\n","print(f\"    Splits: {all_splits}\")\n","\n","# Calculate distribution\n","split_data = {}\n","for split in all_splits:\n","    split_df = df_metadata[df_metadata['split'] == split]\n","    split_data[split] = split_df['emotion_label'].value_counts().to_dict()\n","    print(f\"    {split.upper()}: {len(split_df)} images\")\n","\n","print(\"\\n[4] Generating File 1: Split Distribution Bar Chart...\")\n","\n","fig1, ax1 = plt.subplots(1, 1, figsize=(16, 9))\n","\n","# Prepare data for grouped bars\n","train_counts = [split_data['train'].get(emotion, 0) for emotion in all_emotions]\n","val_counts = [split_data['val'].get(emotion, 0) for emotion in all_emotions]\n","test_counts = [split_data['test'].get(emotion, 0) for emotion in all_emotions]\n","\n","x = np.arange(len(all_emotions))\n","width = 0.25\n","\n","# Create grouped bars\n","bars1 = ax1.bar(x - width, train_counts, width, label='Train Split',\n","                color=SPLIT_COLORS['train'], alpha=0.85)\n","bars2 = ax1.bar(x, val_counts, width, label='Validation Split',\n","                color=SPLIT_COLORS['val'], alpha=0.85)\n","bars3 = ax1.bar(x + width, test_counts, width, label='Test Split',\n","                color=SPLIT_COLORS['test'], alpha=0.85)\n","\n","ax1.set_title('RAF-DB Balanced Dataset Distribution\\nPre-Split Macro-Expression Dataset (75x75 Resolution)',\n","              fontsize=18, fontweight='bold', pad=25)\n","ax1.set_xlabel('Emotion Classes', fontsize=16, labelpad=20)\n","ax1.set_ylabel('Image Count', fontsize=16, labelpad=20)\n","ax1.set_xticks(x)\n","ax1.set_xticklabels([e.title() for e in all_emotions], rotation=0)\n","\n","ax1.legend(loc='upper right', fontsize=12)\n","ax1.grid(False)\n","\n","# Add value labels on bars\n","all_bars_data = [(bars1, train_counts), (bars2, val_counts), (bars3, test_counts)]\n","for bars, values in all_bars_data:\n","    for bar, value in zip(bars, values):\n","        if value > 0:\n","            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n","                    f'{value:,}', ha='center', va='bottom', fontsize=10,\n","                    fontweight='bold')\n","\n","plt.tight_layout()\n","file1_path = f\"{visualization_path}/1_rafdb_split_distribution.png\"\n","plt.savefig(file1_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"    File 1 saved: 1_rafdb_split_distribution.png\")\n","\n","print(\"\\n[5] Generating File 2: Statistical Analysis Table...\")\n","\n","fig2 = plt.figure(figsize=(18, 10))\n","ax2 = fig2.add_subplot(1, 1, 1)\n","ax2.axis('off')\n","\n","# Prepare table data\n","table_data = []\n","total_train = 0\n","total_val = 0\n","total_test = 0\n","total_all = 0\n","\n","for emotion in all_emotions:\n","    train_count = split_data['train'].get(emotion, 0)\n","    val_count = split_data['val'].get(emotion, 0)\n","    test_count = split_data['test'].get(emotion, 0)\n","    emotion_total = train_count + val_count + test_count\n","\n","    total_train += train_count\n","    total_val += val_count\n","    total_test += test_count\n","    total_all += emotion_total\n","\n","    # Calculate percentage of total\n","    percentage = (emotion_total / len(df_metadata)) * 100\n","\n","    # Calculate train percentage (for split ratio verification)\n","    train_pct = (train_count / emotion_total) * 100 if emotion_total > 0 else 0\n","\n","    # Balance ratio (should be 1:1 for balanced dataset)\n","    max_count = max([split_data[s].get(emotion, 0) for s in all_splits])\n","    min_count = min([split_data[s].get(emotion, 0) for s in all_splits])\n","    balance_ratio = f\"{max_count / min_count:.2f}:1\" if min_count > 0 else \"N/A\"\n","\n","    table_data.append([\n","        emotion.title(),\n","        train_count,\n","        val_count,\n","        test_count,\n","        emotion_total,\n","        f\"{percentage:.2f}%\",\n","        f\"{train_pct:.1f}%\",\n","        balance_ratio\n","    ])\n","\n","# Add total row\n","table_data.append([\n","    'TOTAL',\n","    total_train,\n","    total_val,\n","    total_test,\n","    total_all,\n","    '100.00%',\n","    f\"{(total_train/total_all)*100:.1f}%\",\n","    '1.00:1'\n","])\n","\n","# Convert to display format with thousand separators\n","table_display_data = []\n","for row in table_data:\n","    display_row = [\n","        row[0],  # emotion\n","        f\"{row[1]:,}\",  # train\n","        f\"{row[2]:,}\",  # val\n","        f\"{row[3]:,}\",  # test\n","        f\"{row[4]:,}\",  # total\n","        row[5],  # percentage\n","        row[6],  # train %\n","        row[7]   # balance ratio\n","    ]\n","    table_display_data.append(display_row)\n","\n","# Create table\n","table = ax2.table(\n","    cellText=table_display_data,\n","    colLabels=['Emotion', 'Train', 'Validation', 'Test', 'Total', 'Dataset %', 'Train %', 'Balance\\nRatio'],\n","    cellLoc='center',\n","    loc='center',\n","    colWidths=[0.12, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11]\n",")\n","\n","table.auto_set_font_size(False)\n","table.set_fontsize(12)\n","table.scale(1, 3.0)\n","\n","# Professional table styling\n","num_rows = len(table_display_data)\n","for i in range(num_rows + 1):\n","    for j in range(8):\n","        cell = table[(i, j)]\n","        if i == 0:  # Header\n","            cell.set_facecolor('#1f77b4')\n","            cell.set_text_props(weight='bold', color='white')\n","        elif i == num_rows:  # Total row\n","            cell.set_facecolor('#f0f0f0')\n","            cell.set_text_props(weight='bold')\n","        else:\n","            # Alternate row colors for readability\n","            if i % 2 == 0:\n","                cell.set_facecolor('#ffffff')\n","            else:\n","                cell.set_facecolor('#f9f9f9')\n","\n","ax2.set_title('RAF-DB Balanced Dataset Statistical Analysis\\n' +\n","              'Macro-Expression Pre-Training Dataset | Resolution: 75x75 | Format: Grayscale',\n","              fontsize=16, fontweight='bold', pad=40)\n","\n","plt.tight_layout()\n","file2_path = f\"{visualization_path}/2_rafdb_statistical_table.png\"\n","plt.savefig(file2_path, dpi=300, bbox_inches='tight', facecolor='white')\n","plt.close()\n","print(f\"    File 2 saved: 2_rafdb_statistical_table.png\")\n","\n","print(\"\\n[6] Generating visualization metadata...\")\n","\n","# Calculate class balance metrics\n","class_counts = df_metadata['emotion_label'].value_counts()\n","max_class_count = class_counts.max()\n","min_class_count = class_counts.min()\n","imbalance_ratio = max_class_count / min_class_count if min_class_count > 0 else 0\n","\n","# Split ratios\n","train_ratio = (total_train / total_all) * 100\n","val_ratio = (total_val / total_all) * 100\n","test_ratio = (total_test / total_all) * 100\n","\n","# Generate comprehensive metadata\n","analysis_metadata = {\n","    'analysis_timestamp': pd.Timestamp.now().isoformat(),\n","    'dataset_info': {\n","        'name': 'RAF-DB Balanced Dataset',\n","        'purpose': 'macro_expression_transfer_learning',\n","        'total_images': int(total_all),\n","        'resolution': '75x75',\n","        'color_mode': 'grayscale',\n","        'emotion_classes': len(all_emotions),\n","        'class_list': all_emotions\n","    },\n","    'balance_analysis': convert_to_serializable({\n","        'overall_balance': 'perfectly_balanced',\n","        'imbalance_ratio': f\"{imbalance_ratio:.2f}:1\",\n","        'most_frequent_class': class_counts.idxmax(),\n","        'least_frequent_class': class_counts.idxmin(),\n","        'samples_per_class': int(class_counts.iloc[0])\n","    }),\n","    'split_distribution': convert_to_serializable({\n","        'train': {\n","            'count': int(total_train),\n","            'percentage': f\"{train_ratio:.2f}%\",\n","            'class_distribution': {k: int(v) for k, v in split_data['train'].items()}\n","        },\n","        'validation': {\n","            'count': int(total_val),\n","            'percentage': f\"{val_ratio:.2f}%\",\n","            'class_distribution': {k: int(v) for k, v in split_data['val'].items()}\n","        },\n","        'test': {\n","            'count': int(total_test),\n","            'percentage': f\"{test_ratio:.2f}%\",\n","            'class_distribution': {k: int(v) for k, v in split_data['test'].items()}\n","        }\n","    }),\n","    'visualization_files': {\n","        'split_distribution': '1_rafdb_split_distribution.png',\n","        'statistical_table': '2_rafdb_statistical_table.png'\n","    },\n","    'color_scheme': {\n","        'emotion_colors': EMOTION_COLORS,\n","        'split_colors': SPLIT_COLORS\n","    },\n","    'transfer_learning_notes': {\n","        'casme2_compatible_classes': ['disgust', 'fear', 'surprise', 'sad/sadness', 'happy/happiness'],\n","        'incompatible_mappings': {\n","            'neutral': 'no_direct_casme2_equivalent',\n","            'angry': 'semantically_different_from_repression'\n","        },\n","        'recommendation': 'use_5_overlapping_classes_for_transfer_learning'\n","    }\n","}\n","\n","metadata_file = f\"{visualization_path}/rafdb_visualization_metadata.json\"\n","with open(metadata_file, 'w') as f:\n","    json.dump(analysis_metadata, f, indent=2)\n","\n","print(f\"    Metadata saved: rafdb_visualization_metadata.json\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"RAF-DB VISUALIZATION COMPLETE\")\n","print(\"=\" * 80)\n","print(f\"Status: SUCCESS\")\n","print(f\"Output location: {visualization_path}\")\n","\n","print(\"\\nGenerated files:\")\n","print(\"  1. 1_rafdb_split_distribution.png - Bar chart comparison across splits\")\n","print(\"  2. 2_rafdb_statistical_table.png - Detailed statistical breakdown\")\n","print(\"  3. rafdb_visualization_metadata.json - Comprehensive dataset metadata\")\n","\n","print(\"\\nDataset Summary:\")\n","print(f\"  Total images: {total_all:,}\")\n","print(f\"  Train: {total_train:,} images ({train_ratio:.1f}%)\")\n","print(f\"  Validation: {total_val:,} images ({val_ratio:.1f}%)\")\n","print(f\"  Test: {total_test:,} images ({test_ratio:.1f}%)\")\n","print(f\"  Classes: {len(all_emotions)} emotions\")\n","print(f\"  Balance status: Perfectly balanced ({imbalance_ratio:.2f}:1)\")\n","print(f\"  Resolution: 75x75 grayscale\")\n","\n","print(\"\\nTransfer Learning Notes:\")\n","print(\"  Compatible with CASME II: 5 overlapping classes\")\n","print(\"  Recommended strategy: Use disgust, fear, surprise, sad, happy\")\n","print(\"  Exclude: neutral and angry due to semantic mismatch\")\n","\n","print(\"\\n  Ready for Phase 4: Transfer Learning preprocessing\")\n","print(\"=\" * 80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"vI6uWTAGfMXH","executionInfo":{"status":"ok","timestamp":1759753965942,"user_tz":-420,"elapsed":7949,"user":{"displayName":"M.Taufiq Al Fikri","userId":"01953200869743614065"}},"outputId":"8f9ed57e-a769-4ad9-eeb4-6e513d730615"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","RAF-DB BALANCED DATASET VISUALIZATION\n","================================================================================\n","\n","[1] Environment setup and drive mounting...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","    Google Drive mounted successfully\n","    Output directory created: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/04_raf-db\n","\n","[2] Loading RAF-DB metadata...\n","    Metadata loaded: 41692 images\n","    Columns: ['filepath', 'emotion_label', 'split']\n","\n","[3] Analyzing distribution...\n","    Emotion classes: 7\n","    Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","    Splits: ['train', 'val', 'test']\n","    TRAIN: 30023 images\n","    VAL: 7504 images\n","    TEST: 4165 images\n","\n","[4] Generating File 1: Split Distribution Bar Chart...\n","    File 1 saved: 1_rafdb_split_distribution.png\n","\n","[5] Generating File 2: Statistical Analysis Table...\n","    File 2 saved: 2_rafdb_statistical_table.png\n","\n","[6] Generating visualization metadata...\n","    Metadata saved: rafdb_visualization_metadata.json\n","\n","================================================================================\n","RAF-DB VISUALIZATION COMPLETE\n","================================================================================\n","Status: SUCCESS\n","Output location: /content/drive/MyDrive/RESEARCH-WORKSPACE/ACTIVE-PROJECTS/Thesis_MER_Project/datasets/visualization/04_raf-db\n","\n","Generated files:\n","  1. 1_rafdb_split_distribution.png - Bar chart comparison across splits\n","  2. 2_rafdb_statistical_table.png - Detailed statistical breakdown\n","  3. rafdb_visualization_metadata.json - Comprehensive dataset metadata\n","\n","Dataset Summary:\n","  Total images: 41,692\n","  Train: 30,023 images (72.0%)\n","  Validation: 7,504 images (18.0%)\n","  Test: 4,165 images (10.0%)\n","  Classes: 7 emotions\n","  Balance status: Perfectly balanced (1.00:1)\n","  Resolution: 75x75 grayscale\n","\n","Transfer Learning Notes:\n","  Compatible with CASME II: 5 overlapping classes\n","  Recommended strategy: Use disgust, fear, surprise, sad, happy\n","  Exclude: neutral and angry due to semantic mismatch\n","\n","  Ready for Phase 4: Transfer Learning preprocessing\n","================================================================================\n"]}]}]}